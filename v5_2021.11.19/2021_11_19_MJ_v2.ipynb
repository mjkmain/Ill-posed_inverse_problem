{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6nP75H4DiluS"
   },
   "source": [
    "# 이해를 위한 정리\n",
    "\n",
    "* $AQ = F$\n",
    "* $Q = A^{-1}F$\n",
    "* $A^TAQ = A^TF  \\to Q = (A^TA)^{-1}A^TF$\n",
    "* $\\alpha Q_\\alpha + A^TAQ_\\alpha = A^TF \\to Q_\\alpha = (\\alpha I + A^TA)^{-1} A^TF$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " ## $Q_\\alpha = (\\alpha I + A^TA)^{-1} A^TF$\n",
    "\n",
    " or\n",
    "\n",
    " ## $Q_n = \\frac{F_n}{\\alpha e^{n^2T} + e^{-n^2T}}, \\quad\\quad n = 1, 2, \\cdots , N$\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "invA = np.diag(1/(alpha*np.exp((np.arange(1, N+1))**2*T)+np.exp(-(np.arange(1, N+1))**2*T)))\n",
    "hatQ = invA@F\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtyAoVp059M6"
   },
   "source": [
    "# Generate Data \n",
    "\n",
    "\n",
    "*   generate_Q\n",
    "*   sol_act\n",
    "*   noise_data\n",
    "*   sol_Tik\n",
    "*   result_gen_data\n",
    "*   result_Lcurve\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "f459TdI-52dT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "T = 1\n",
    "delta = 0.01\n",
    "N = 10\n",
    "M = 50000\n",
    "tau = 1\n",
    "min_al = -20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qzywCujn5793"
   },
   "outputs": [],
   "source": [
    "def generate_Q(N,  M, tau):\n",
    "    ii = 0\n",
    "    tore = tau*np.sqrt(2/np.pi)\n",
    "    Q = []\n",
    "    while ii < M:\n",
    "        tempQ = 2*tore*np.random.rand(N) - tore\n",
    "        tempQ = np.array(tempQ)\n",
    "        if np.linalg.norm(tempQ) <= tore:\n",
    "            Q = np.append(Q, tempQ)\n",
    "            ii += 1\n",
    "    return (Q.reshape(-1, N))\n",
    "\n",
    "def sol_act(Q, T):\n",
    "    A = np.diag(np.exp(-(np.arange(1, N+1))**2*T))\n",
    "    F = A@Q.T #A = NxN, Q = MxN, Q.T = NxM , F = NxM\n",
    "    return F\n",
    "\n",
    "def noise_data(F, delta):\n",
    "    e = 2*np.random.rand(len(F[:,0]), len(F[0])) - 1\n",
    "    N = len(F[:])\n",
    "    for m in range(len(F[0])):\n",
    "        norm = np.linalg.norm(F[:,m])\n",
    "        e[:, m] = e[:, 0]*norm*delta\n",
    "    nF = F+e\n",
    "    return nF\n",
    "\n",
    "def sol_Tik(alpha, T, F):\n",
    "    invA = np.diag(1/(alpha*np.exp((np.arange(1, N+1))**2*T)+np.exp(-(np.arange(1, N+1))**2*T))) # A = NxN\n",
    "    hatQ = invA@F \n",
    "    return hatQ\n",
    "\n",
    "def result_gen_data(Q, F, nF, N, M, tau, delta):\n",
    "    #Q = generate_Q(N, M, tau)\n",
    "    #T = 1\n",
    "    #F = sol_act(Q, T)\n",
    "    #nF = noise_data(F, delta)\n",
    "    np.savetxt('Q.txt', Q.T, fmt='%8f', delimiter = ',', header='')\n",
    "    np.savetxt('F.txt', F, fmt='%8f', delimiter = ',', header='')\n",
    "    np.savetxt('nF.txt', nF, fmt='%8f', delimiter = ',', header='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ajr9blR56SX6",
    "outputId": "8539a0de-8c5b-43fa-b7b2-9dce510122f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.75709864e-02, -7.23804864e-02,  1.50323921e-02, ...,\n",
       "         8.36931006e-02,  6.17601047e-02, -2.56411939e-02],\n",
       "       [-3.22308238e-03, -2.84937513e-03, -1.11542604e-03, ...,\n",
       "         4.63299638e-04, -9.05587203e-03, -6.68176868e-03],\n",
       "       [-5.33751626e-05,  3.23409553e-06, -5.45812913e-05, ...,\n",
       "         4.93432324e-05, -7.19757645e-06,  6.64669851e-06],\n",
       "       ...,\n",
       "       [-1.82411933e-29,  4.14275150e-29,  6.61816817e-29, ...,\n",
       "        -9.49534791e-30, -6.16840956e-29, -5.50367759e-29],\n",
       "       [-1.22724684e-36, -8.19415474e-37,  9.22483990e-37, ...,\n",
       "         3.47526993e-37, -1.02279953e-37, -1.25097770e-36],\n",
       "       [ 3.52207175e-45, -7.91788353e-45, -9.79990118e-45, ...,\n",
       "         1.16079822e-44,  7.67933728e-45,  1.60739102e-44]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = generate_Q(N, M, tau = 1)\n",
    "F = sol_act(Q, T)\n",
    "nF = noise_data(F, delta)\n",
    "result_gen_data(Q, F, nF, N, M, tau = 1, delta = 0.01)\n",
    "F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTYxfdpuM67t"
   },
   "source": [
    "## v[i]$\\bullet$v[i+k] 사용하여 cos 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bSwSTsIlQMgW"
   },
   "outputs": [],
   "source": [
    "def find_best_idx(log_x2, log_y2):\n",
    "    O = np.column_stack((log_x2, log_y2))\n",
    "    v = []\n",
    "    k = 10\n",
    "    for i in range(len(O) - 1 - k):\n",
    "        v.append(O[i+k]-O[i])\n",
    "    v\n",
    "\n",
    "    cos = []\n",
    "\n",
    "    for i in range(len(v)-1-k):\n",
    "        v1_norm = np.linalg.norm(v[i])\n",
    "        v2_norm = np.linalg.norm(v[i+k])\n",
    "        v_cos = np.dot(v[i], v[i+k])/(v1_norm*v2_norm)\n",
    "        cos.append(v_cos)\n",
    "    a = np.argmin(cos) + k\n",
    "    return a   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3UG_gfJRXHyR",
    "outputId": "812fd4fa-7a52-47c1-d8d0-f17a9d228fa4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 50000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Qym6LRUM6S0q"
   },
   "outputs": [],
   "source": [
    "def each_data_bestAlpha(Q, F, nF, N, M, tau, delta, min_al):\n",
    "    #get data\n",
    "    alpha_target = []\n",
    "    x2_arr = []\n",
    "    for i in range(M):\n",
    "        \n",
    "\n",
    "        Q_i = Q[i, :]\n",
    "        F_i = F[:, i]\n",
    "        nF_i = nF[:, i]\n",
    "\n",
    "        #T = 1\n",
    "        #F = sol_act(Q_i, T)\n",
    "        #nF = noise_data(F, delta)\n",
    "\n",
    "\n",
    "        al = np.linspace(0, min_al, 100)\n",
    "        q1 = []\n",
    "        q2 = []\n",
    "        for ii in range(len(al)):\n",
    "            q1.append(sol_Tik(10**al[ii], T, F_i))\n",
    "            q2.append(sol_Tik(10**al[ii], T, nF_i))\n",
    "        q1 = np.array(q1) \n",
    "        q2 = np.array(q2)\n",
    "\n",
    "        n = np.arange(1, N+1)\n",
    "        A = np.diag(np.exp(-n**2*T))\n",
    "\n",
    "        x1 = []\n",
    "        x2 = []\n",
    "        y1 = []\n",
    "        y2 = []\n",
    "\n",
    "        for i in range(len(al)):\n",
    "            x1.append(np.linalg.norm(A@q1[i]-F_i))\n",
    "            y1.append(np.linalg.norm(q1[i]))\n",
    "            x2.append(np.linalg.norm(A@q2[i]-nF_i))\n",
    "            y2.append(np.linalg.norm(q2[i]))\n",
    "\n",
    "        x1 = np.flip(np.array(x1)) \n",
    "        y1 = np.flip(np.array(y1)) \n",
    "        x2 = np.flip(np.array(x2)) \n",
    "        y2 = np.flip(np.array(y2))\n",
    "\n",
    "        log_x2 = np.log10(x2)\n",
    "        log_y2 = np.log10(y2)\n",
    "        a = find_best_idx(log_x2, log_y2)\n",
    "        alpha = 10**al[a]\n",
    "        alpha\n",
    "        alpha_target.append(alpha)\n",
    "    np.savetxt('alpha_target.txt', alpha_target, fmt='%8f', delimiter = ',', header='')\n",
    "        \n",
    "        #x2_arr.append(x2[a])\n",
    "    return alpha_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "wC2YcpV-6lPL"
   },
   "outputs": [],
   "source": [
    "alpha_target = each_data_bestAlpha(Q, F, nF, N, M, tau, delta, -20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "v5PIDcKNcg77"
   },
   "outputs": [],
   "source": [
    "def plot_Lcurve(Q, F, nF, N, M, tau, delta, min_al):\n",
    "    # Q, F, nF : 1 data\n",
    "    al = np.linspace(0, min_al, 200)\n",
    "    q1 = []\n",
    "    q2 = []\n",
    "    for ii in range(len(al)):\n",
    "        q1.append(sol_Tik(10**al[ii], T, F))\n",
    "        q2.append(sol_Tik(10**al[ii], T, nF))\n",
    "    q1 = np.array(q1) \n",
    "    q2 = np.array(q2)\n",
    "    \n",
    "    n = np.arange(1, N+1)\n",
    "    A = np.diag(np.exp(-n**2*T))\n",
    "    \n",
    "    x1 = []\n",
    "    x2 = []\n",
    "    y1 = []\n",
    "    y2 = []\n",
    "\n",
    "    for i in range(len(al)):\n",
    "        x1.append(np.linalg.norm(A@q1[i]-F))\n",
    "        y1.append(np.linalg.norm(q1[i]))\n",
    "        x2.append(np.linalg.norm(A@q2[i]-nF))\n",
    "        y2.append(np.linalg.norm(q2[i]))\n",
    "    \n",
    "    fig = plt.figure(figsize = (10,10))\n",
    "    fig.add_subplot(2, 1, 1)\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"log\")\n",
    "    #plt.xlabel(\"$\\||Aq-F\\||$\")\n",
    "    plt.plot(x1, y1)\n",
    "    plt.title(\"without noise\")\n",
    "\n",
    "    \n",
    "    fig.add_subplot(2, 1, 2)\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.plot(x2, y2)\n",
    "    plt.title(\"with noise\")     \n",
    "\n",
    "    \n",
    "    plt.savefig('L-curve1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 611
    },
    "id": "E9HnxcDcdGWW",
    "outputId": "e4b9b0e3-744e-4255-d93c-c8e683c19043"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k = 2\n",
    "plot_Lcurve(Q[k, :], F[:, k], nF[:, k], N, M, tau, delta, min_al)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrSjfJSM6u8q"
   },
   "source": [
    "* make hat Q with best alpha of each data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4G78S8Id7By6"
   },
   "outputs": [],
   "source": [
    "hatQ_arr = []\n",
    "for i in range(M):\n",
    "    hatQ_arr.append(sol_Tik(alpha_target[i], T, F[:, i]))\n",
    "    \n",
    "hatQ = np.array(hatQ_arr)\n",
    "np.savetxt('hatQ.txt', hatQ.T, fmt='%8f', delimiter = ',', header='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Ev3P8uWXXa8P"
   },
   "outputs": [],
   "source": [
    "arr = []\n",
    "for i in range(M):\n",
    "    arr.append(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "CE_ORsOJncVq"
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "#column name에 data가 들어가있기 때문에 \"names = arr\" 로 처리해 줍니다. arr은 1 ~ len(F)의 숫자가 담겨있습니다.\n",
    "dataF = pd.read_csv('C:/Users/Administrator/F.txt', sep = ',', names = arr)\n",
    "dataQ = pd.read_csv('C:/Users/Administrator/Q.txt', sep = ',', names = arr)\n",
    "#dataQ = pd.read_csv('C:/Users/Administrator/hatQ.txt', sep = ',', names = arr)\n",
    "data_nF = pd.read_csv('C:/Users/Administrator/nF.txt', sep = ',', names = arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "3yM_LH3qPFQd"
   },
   "outputs": [],
   "source": [
    "def make_arr(A):\n",
    "    arA = []\n",
    "    for j in range(len(A.iloc[0, :])):\n",
    "        arA1 = []\n",
    "        for i in range(len(A.iloc[:,0])):\n",
    "            tmpA = A.iloc[:,j][i]\n",
    "            arA1.append(tmpA)\n",
    "        arA.append(arA1)\n",
    "    return arA\n",
    "\n",
    "#make array\n",
    "arrF = make_arr(dataF)\n",
    "dataF = np.array(arrF)\n",
    "\n",
    "arrQ = make_arr(dataQ)\n",
    "dataQ = np.array(arrQ)\n",
    "\n",
    "arr_nF = make_arr(data_nF)\n",
    "data_nF = np.array(arr_nF)\n",
    "\n",
    "alpha_target = np.array(alpha_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iaFCQA-SojWq",
    "outputId": "4f56519d-2743-4ed1-e60c-edde3305a1b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitted Q : (30000, 10), (10000, 10), (10000, 10)\n",
      "splitted F : (30000, 10), (10000, 10), (10000, 10)\n",
      "splitted nF : (30000, 10), (10000, 10), (10000, 10)\n",
      "\n",
      "splitted QF : (30000, 20), (10000, 20), (10000, 20)\n",
      "splitted QnF : (30000, 20), (10000, 20), (10000, 20)\n",
      "\n",
      "splitted alpha : (30000,), (10000,), (10000,)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "train_size = math.floor(len(dataF)*0.6) # train : 60%\n",
    "val_size = math.floor(len(dataF)*0.2) #val : 20%\n",
    "test_size = math.floor(len(dataF)*0.2) #test : 20%\n",
    "#generate F_data, F_val, F_test\n",
    "F_data = dataF[:train_size, :]\n",
    "F_val = dataF[train_size:(val_size + train_size), :]\n",
    "F_test = dataF[(val_size + train_size):(val_size + train_size + test_size), :]\n",
    "\n",
    "#generate Q_data, Q_val, Q_test\n",
    "Q_data = dataQ[:train_size, :]\n",
    "Q_val = dataQ[train_size:(val_size + train_size), :]\n",
    "Q_test = dataQ[(val_size + train_size):(val_size + train_size + test_size), :]\n",
    "\n",
    "#generate nF_data, nF_val, nF_test\n",
    "nF_data = data_nF[:train_size, :]\n",
    "nF_val = data_nF[train_size:(val_size + train_size), :]\n",
    "nF_test = data_nF[(val_size + train_size):(val_size + train_size + test_size), :]\n",
    "\n",
    "#Q+F\n",
    "QF_data = np.concatenate((Q_data, F_data), axis = 1)\n",
    "QF_val = np.concatenate((Q_val, F_val), axis = 1)\n",
    "QF_test = np.concatenate((Q_test, F_test), axis = 1)\n",
    "\n",
    "#Q+nF\n",
    "QnF_data = np.concatenate((Q_data, nF_data), axis = 1)\n",
    "QnF_val = np.concatenate((Q_val, nF_val), axis = 1)\n",
    "QnF_test = np.concatenate((Q_test, nF_test), axis = 1)\n",
    "\n",
    "#alpha_target\n",
    "alpha_target_data = alpha_target[:train_size]\n",
    "alpha_target_val = alpha_target[train_size:(val_size + train_size)]\n",
    "alpha_target_test = alpha_target[(val_size + train_size):(val_size + train_size + test_size)]\n",
    "\n",
    "print(f'splitted Q : {Q_data.shape}, {Q_test.shape}, {Q_val.shape}')\n",
    "print(f'splitted F : {F_data.shape}, {F_test.shape}, {F_val.shape}')\n",
    "print(f'splitted nF : {nF_data.shape}, {nF_test.shape}, {nF_val.shape}\\n')\n",
    "\n",
    "print(f'splitted QF : {QF_data.shape}, {QF_test.shape}, {QF_val.shape}')\n",
    "print(f'splitted QnF : {QnF_data.shape}, {QnF_test.shape}, {QnF_val.shape}\\n')\n",
    "print(f'splitted alpha : {alpha_target_data.shape}, {alpha_target_test.shape}, {alpha_target_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "lYFPm85VU_8m"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.Sequential() #Sequential\n",
    "\n",
    "model.add(keras.layers.Dense(input_dim = 2*N, units = 10, activation= \"tanh\",kernel_initializer =\"HeNormal\" )) \n",
    "model.add(keras.layers.Dense(20, activation= \"tanh\")) \n",
    "model.add(keras.layers.Dense(50, activation= \"tanh\"))  \n",
    "model.add(keras.layers.Dense(100, activation= \"tanh\")) \n",
    "model.add(keras.layers.Dense(120, activation= \"tanh\")) \n",
    "model.add(keras.layers.Dense(50, activation= \"tanh\"))\n",
    "model.add(keras.layers.Dense(1, activation= \"tanh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ktp8oE6nYauf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.EarlyStopping at 0x2bbe120f0a0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    F_train = tf.constant(F_data)\n",
    "    Q_train = tf.constant(Q_data)\n",
    "    nF_train = tf.constant(nF_data)\n",
    "    QF_train = tf.constant(QF_data)\n",
    "    alpha_target_train = tf.constant(alpha_target_data)\n",
    "    \n",
    "tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=0, verbose=0,\n",
    "    mode='auto', baseline=None, restore_best_weights=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "tUW16hZZYecK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "938/938 [==============================] - 1s 590us/step - loss: 1.1203e-04 - accuracy: 0.0000e+00 - val_loss: 8.3331e-07 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "938/938 [==============================] - 0s 503us/step - loss: 4.2557e-06 - accuracy: 0.0000e+00 - val_loss: 6.0062e-06 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "938/938 [==============================] - 0s 504us/step - loss: 4.0107e-06 - accuracy: 0.0000e+00 - val_loss: 1.0683e-05 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/500\n",
      "938/938 [==============================] - 0s 504us/step - loss: 4.7108e-06 - accuracy: 0.0000e+00 - val_loss: 4.6003e-08 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/500\n",
      "938/938 [==============================] - 0s 504us/step - loss: 8.8583e-07 - accuracy: 0.0000e+00 - val_loss: 1.8349e-07 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/500\n",
      "938/938 [==============================] - 0s 505us/step - loss: 1.3397e-06 - accuracy: 0.0000e+00 - val_loss: 1.4045e-08 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/500\n",
      "938/938 [==============================] - 0s 526us/step - loss: 1.9409e-07 - accuracy: 0.0000e+00 - val_loss: 1.6652e-08 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/500\n",
      "938/938 [==============================] - 0s 518us/step - loss: 3.9201e-07 - accuracy: 0.0000e+00 - val_loss: 1.1603e-07 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/500\n",
      "938/938 [==============================] - 0s 502us/step - loss: 3.1315e-07 - accuracy: 0.0000e+00 - val_loss: 3.4824e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/500\n",
      "938/938 [==============================] - 0s 503us/step - loss: 1.7208e-07 - accuracy: 0.0000e+00 - val_loss: 2.0475e-07 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/500\n",
      "938/938 [==============================] - 0s 504us/step - loss: 1.2559e-07 - accuracy: 0.0000e+00 - val_loss: 2.2335e-08 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/500\n",
      "938/938 [==============================] - 0s 506us/step - loss: 9.6813e-08 - accuracy: 0.0000e+00 - val_loss: 6.1582e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/500\n",
      "938/938 [==============================] - 0s 505us/step - loss: 6.5021e-08 - accuracy: 0.0000e+00 - val_loss: 6.4230e-07 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/500\n",
      "938/938 [==============================] - 0s 514us/step - loss: 3.6014e-06 - accuracy: 0.0000e+00 - val_loss: 7.8614e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/500\n",
      "938/938 [==============================] - 0s 503us/step - loss: 8.3832e-10 - accuracy: 0.0000e+00 - val_loss: 8.1278e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/500\n",
      "938/938 [==============================] - 0s 505us/step - loss: 3.4403e-08 - accuracy: 0.0000e+00 - val_loss: 3.9069e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/500\n",
      "938/938 [==============================] - 0s 502us/step - loss: 9.3707e-09 - accuracy: 0.0000e+00 - val_loss: 3.8133e-08 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/500\n",
      "938/938 [==============================] - 0s 515us/step - loss: 6.0862e-08 - accuracy: 0.0000e+00 - val_loss: 9.9878e-07 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/500\n",
      "938/938 [==============================] - 0s 510us/step - loss: 5.2455e-08 - accuracy: 0.0000e+00 - val_loss: 8.0589e-08 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/500\n",
      "938/938 [==============================] - 0s 517us/step - loss: 4.0591e-08 - accuracy: 0.0000e+00 - val_loss: 7.9588e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/500\n",
      "938/938 [==============================] - 0s 509us/step - loss: 3.3019e-08 - accuracy: 0.0000e+00 - val_loss: 7.8605e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/500\n",
      "938/938 [==============================] - 0s 505us/step - loss: 2.5798e-06 - accuracy: 0.0000e+00 - val_loss: 9.4404e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/500\n",
      "938/938 [==============================] - 0s 504us/step - loss: 1.0775e-10 - accuracy: 0.0000e+00 - val_loss: 1.8560e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/500\n",
      "938/938 [==============================] - 0s 505us/step - loss: 1.8549e-10 - accuracy: 0.0000e+00 - val_loss: 9.6190e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/500\n",
      "938/938 [==============================] - 0s 504us/step - loss: 7.6627e-09 - accuracy: 0.0000e+00 - val_loss: 5.1141e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/500\n",
      "938/938 [==============================] - 0s 507us/step - loss: 1.3224e-08 - accuracy: 0.0000e+00 - val_loss: 7.8299e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/500\n",
      "938/938 [==============================] - 0s 512us/step - loss: 3.4073e-08 - accuracy: 0.0000e+00 - val_loss: 5.3399e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/500\n",
      "938/938 [==============================] - 0s 509us/step - loss: 4.6806e-08 - accuracy: 0.0000e+00 - val_loss: 5.2096e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/500\n",
      "938/938 [==============================] - 0s 505us/step - loss: 1.8043e-09 - accuracy: 0.0000e+00 - val_loss: 2.3121e-08 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/500\n",
      "938/938 [==============================] - 0s 504us/step - loss: 1.4479e-08 - accuracy: 0.0000e+00 - val_loss: 3.0923e-08 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/500\n",
      "938/938 [==============================] - 0s 505us/step - loss: 1.4024e-08 - accuracy: 0.0000e+00 - val_loss: 2.2407e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/500\n",
      "938/938 [==============================] - 0s 507us/step - loss: 1.1571e-08 - accuracy: 0.0000e+00 - val_loss: 1.1873e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/500\n",
      "938/938 [==============================] - 0s 510us/step - loss: 8.5945e-09 - accuracy: 0.0000e+00 - val_loss: 5.8312e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/500\n",
      "938/938 [==============================] - 0s 505us/step - loss: 6.0519e-09 - accuracy: 0.0000e+00 - val_loss: 1.1595e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/500\n",
      "938/938 [==============================] - 0s 512us/step - loss: 5.0948e-09 - accuracy: 0.0000e+00 - val_loss: 1.0674e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/500\n",
      "938/938 [==============================] - 0s 501us/step - loss: 3.9133e-09 - accuracy: 0.0000e+00 - val_loss: 5.0954e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/500\n",
      "938/938 [==============================] - 0s 502us/step - loss: 3.0633e-09 - accuracy: 0.0000e+00 - val_loss: 8.3618e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/500\n",
      "938/938 [==============================] - 0s 508us/step - loss: 2.2311e-09 - accuracy: 0.0000e+00 - val_loss: 1.2323e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/500\n",
      "938/938 [==============================] - 0s 503us/step - loss: 1.9681e-09 - accuracy: 0.0000e+00 - val_loss: 5.8213e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/500\n",
      "938/938 [==============================] - 0s 513us/step - loss: 1.7426e-09 - accuracy: 0.0000e+00 - val_loss: 1.1443e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/500\n",
      "938/938 [==============================] - 0s 507us/step - loss: 1.2193e-09 - accuracy: 0.0000e+00 - val_loss: 8.5618e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/500\n",
      "938/938 [==============================] - 0s 505us/step - loss: 1.1403e-09 - accuracy: 0.0000e+00 - val_loss: 5.4092e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/500\n",
      "938/938 [==============================] - 0s 504us/step - loss: 7.2900e-10 - accuracy: 0.0000e+00 - val_loss: 3.0785e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/500\n",
      "938/938 [==============================] - 0s 503us/step - loss: 1.1275e-09 - accuracy: 0.0000e+00 - val_loss: 4.4233e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/500\n",
      "938/938 [==============================] - 0s 504us/step - loss: 6.1317e-10 - accuracy: 0.0000e+00 - val_loss: 5.5871e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/500\n",
      "938/938 [==============================] - 0s 515us/step - loss: 9.4022e-10 - accuracy: 0.0000e+00 - val_loss: 4.3654e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/500\n",
      "938/938 [==============================] - 0s 507us/step - loss: 7.4554e-10 - accuracy: 0.0000e+00 - val_loss: 1.1510e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/500\n",
      "938/938 [==============================] - 0s 502us/step - loss: 9.7586e-10 - accuracy: 0.0000e+00 - val_loss: 5.2088e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/500\n",
      "938/938 [==============================] - 0s 502us/step - loss: 8.5075e-10 - accuracy: 0.0000e+00 - val_loss: 1.5317e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/500\n",
      "938/938 [==============================] - 0s 504us/step - loss: 7.8612e-10 - accuracy: 0.0000e+00 - val_loss: 5.8639e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/500\n",
      "938/938 [==============================] - 0s 504us/step - loss: 1.0408e-09 - accuracy: 0.0000e+00 - val_loss: 4.3341e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/500\n",
      "938/938 [==============================] - 0s 504us/step - loss: 8.8298e-10 - accuracy: 0.0000e+00 - val_loss: 4.9191e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/500\n",
      "938/938 [==============================] - 0s 510us/step - loss: 7.7041e-10 - accuracy: 0.0000e+00 - val_loss: 5.0572e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/500\n",
      "938/938 [==============================] - 0s 502us/step - loss: 9.7383e-10 - accuracy: 0.0000e+00 - val_loss: 4.3481e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/500\n",
      "938/938 [==============================] - 0s 504us/step - loss: 6.9152e-10 - accuracy: 0.0000e+00 - val_loss: 1.2131e-08 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/500\n",
      "938/938 [==============================] - 0s 505us/step - loss: 9.3449e-10 - accuracy: 0.0000e+00 - val_loss: 6.3862e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/500\n",
      "938/938 [==============================] - 0s 506us/step - loss: 8.1161e-10 - accuracy: 0.0000e+00 - val_loss: 1.2306e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/500\n",
      "938/938 [==============================] - 0s 503us/step - loss: 1.0002e-09 - accuracy: 0.0000e+00 - val_loss: 1.5640e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/500\n",
      "938/938 [==============================] - 0s 514us/step - loss: 6.6787e-10 - accuracy: 0.0000e+00 - val_loss: 1.2713e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/500\n",
      "938/938 [==============================] - 0s 531us/step - loss: 8.7218e-10 - accuracy: 0.0000e+00 - val_loss: 7.9798e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/500\n",
      "938/938 [==============================] - 1s 535us/step - loss: 8.9149e-10 - accuracy: 0.0000e+00 - val_loss: 5.6727e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/500\n",
      "938/938 [==============================] - 1s 550us/step - loss: 9.6873e-10 - accuracy: 0.0000e+00 - val_loss: 4.7374e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/500\n",
      "938/938 [==============================] - 0s 515us/step - loss: 7.4287e-10 - accuracy: 0.0000e+00 - val_loss: 4.3132e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/500\n",
      "938/938 [==============================] - 0s 527us/step - loss: 1.0064e-09 - accuracy: 0.0000e+00 - val_loss: 7.1264e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/500\n",
      "938/938 [==============================] - 0s 517us/step - loss: 7.3475e-10 - accuracy: 0.0000e+00 - val_loss: 5.8624e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/500\n",
      "938/938 [==============================] - 0s 508us/step - loss: 7.7408e-10 - accuracy: 0.0000e+00 - val_loss: 7.2129e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/500\n",
      "938/938 [==============================] - 0s 513us/step - loss: 8.2335e-10 - accuracy: 0.0000e+00 - val_loss: 4.3554e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/500\n",
      "938/938 [==============================] - 0s 501us/step - loss: 8.8375e-10 - accuracy: 0.0000e+00 - val_loss: 3.2898e-08 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/500\n",
      "938/938 [==============================] - 0s 498us/step - loss: 1.4207e-09 - accuracy: 0.0000e+00 - val_loss: 1.1751e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/500\n",
      "938/938 [==============================] - 0s 497us/step - loss: 7.6545e-10 - accuracy: 0.0000e+00 - val_loss: 1.7121e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/500\n",
      "938/938 [==============================] - 0s 497us/step - loss: 6.4336e-10 - accuracy: 0.0000e+00 - val_loss: 2.9830e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/500\n",
      "938/938 [==============================] - 0s 500us/step - loss: 8.5248e-10 - accuracy: 0.0000e+00 - val_loss: 3.2149e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/500\n",
      "938/938 [==============================] - 0s 494us/step - loss: 7.7787e-10 - accuracy: 0.0000e+00 - val_loss: 4.9104e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/500\n",
      "938/938 [==============================] - 0s 500us/step - loss: 8.7189e-10 - accuracy: 0.0000e+00 - val_loss: 7.6952e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/500\n",
      "938/938 [==============================] - 0s 493us/step - loss: 8.4422e-10 - accuracy: 0.0000e+00 - val_loss: 4.5854e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/500\n",
      "938/938 [==============================] - 0s 491us/step - loss: 8.9024e-10 - accuracy: 0.0000e+00 - val_loss: 4.5132e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/500\n",
      "938/938 [==============================] - 0s 494us/step - loss: 9.3344e-10 - accuracy: 0.0000e+00 - val_loss: 6.4946e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/500\n",
      "938/938 [==============================] - 0s 495us/step - loss: 9.0707e-10 - accuracy: 0.0000e+00 - val_loss: 4.9640e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/500\n",
      "938/938 [==============================] - 0s 498us/step - loss: 9.4459e-10 - accuracy: 0.0000e+00 - val_loss: 1.5847e-08 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/500\n",
      "938/938 [==============================] - 0s 496us/step - loss: 6.4126e-10 - accuracy: 0.0000e+00 - val_loss: 2.0053e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/500\n",
      "938/938 [==============================] - 0s 497us/step - loss: 1.1810e-09 - accuracy: 0.0000e+00 - val_loss: 5.6340e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/500\n",
      "938/938 [==============================] - 0s 495us/step - loss: 7.6271e-10 - accuracy: 0.0000e+00 - val_loss: 4.2722e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/500\n",
      "938/938 [==============================] - 0s 494us/step - loss: 6.9071e-10 - accuracy: 0.0000e+00 - val_loss: 4.3747e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/500\n",
      "938/938 [==============================] - 0s 495us/step - loss: 8.5484e-10 - accuracy: 0.0000e+00 - val_loss: 2.1638e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/500\n",
      "938/938 [==============================] - 0s 483us/step - loss: 8.2884e-10 - accuracy: 0.0000e+00 - val_loss: 1.1421e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/500\n",
      "938/938 [==============================] - 0s 475us/step - loss: 9.0380e-10 - accuracy: 0.0000e+00 - val_loss: 1.5195e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/500\n",
      "938/938 [==============================] - 0s 476us/step - loss: 8.9482e-10 - accuracy: 0.0000e+00 - val_loss: 1.5485e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/500\n",
      "938/938 [==============================] - 0s 480us/step - loss: 7.9420e-10 - accuracy: 0.0000e+00 - val_loss: 9.9528e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/500\n",
      "938/938 [==============================] - 0s 475us/step - loss: 8.4093e-10 - accuracy: 0.0000e+00 - val_loss: 5.1096e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/500\n",
      "938/938 [==============================] - 0s 473us/step - loss: 8.5807e-10 - accuracy: 0.0000e+00 - val_loss: 5.2946e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/500\n",
      "938/938 [==============================] - 0s 472us/step - loss: 9.5486e-10 - accuracy: 0.0000e+00 - val_loss: 6.2610e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/500\n",
      "938/938 [==============================] - 0s 482us/step - loss: 7.2302e-10 - accuracy: 0.0000e+00 - val_loss: 3.7541e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/500\n",
      "938/938 [==============================] - 0s 473us/step - loss: 9.4721e-10 - accuracy: 0.0000e+00 - val_loss: 1.4232e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/500\n",
      "938/938 [==============================] - 0s 475us/step - loss: 7.4752e-10 - accuracy: 0.0000e+00 - val_loss: 5.0767e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/500\n",
      "938/938 [==============================] - 0s 480us/step - loss: 8.8544e-10 - accuracy: 0.0000e+00 - val_loss: 2.1219e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/500\n",
      "938/938 [==============================] - 0s 475us/step - loss: 8.3864e-10 - accuracy: 0.0000e+00 - val_loss: 4.4571e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/500\n",
      "938/938 [==============================] - 0s 471us/step - loss: 1.0923e-09 - accuracy: 0.0000e+00 - val_loss: 6.9137e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/500\n",
      "938/938 [==============================] - 0s 476us/step - loss: 5.4157e-10 - accuracy: 0.0000e+00 - val_loss: 1.0437e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/500\n",
      "938/938 [==============================] - 0s 482us/step - loss: 1.0343e-09 - accuracy: 0.0000e+00 - val_loss: 1.4752e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/500\n",
      "938/938 [==============================] - 0s 478us/step - loss: 7.7790e-10 - accuracy: 0.0000e+00 - val_loss: 5.3707e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/500\n",
      "938/938 [==============================] - 0s 477us/step - loss: 9.2721e-10 - accuracy: 0.0000e+00 - val_loss: 1.9716e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/500\n",
      "938/938 [==============================] - 0s 477us/step - loss: 1.0649e-09 - accuracy: 0.0000e+00 - val_loss: 4.3978e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/500\n",
      "938/938 [==============================] - 0s 473us/step - loss: 5.0658e-10 - accuracy: 0.0000e+00 - val_loss: 1.6047e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/500\n",
      "938/938 [==============================] - 0s 476us/step - loss: 8.9136e-10 - accuracy: 0.0000e+00 - val_loss: 2.6838e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/500\n",
      "938/938 [==============================] - 0s 476us/step - loss: 8.0987e-10 - accuracy: 0.0000e+00 - val_loss: 8.6638e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/500\n",
      "938/938 [==============================] - 0s 481us/step - loss: 8.7823e-10 - accuracy: 0.0000e+00 - val_loss: 2.5353e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/500\n",
      "938/938 [==============================] - 0s 472us/step - loss: 8.0625e-10 - accuracy: 0.0000e+00 - val_loss: 4.3277e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/500\n",
      "938/938 [==============================] - 0s 478us/step - loss: 8.3481e-10 - accuracy: 0.0000e+00 - val_loss: 4.5083e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/500\n",
      "938/938 [==============================] - 0s 475us/step - loss: 9.0713e-10 - accuracy: 0.0000e+00 - val_loss: 5.4710e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/500\n",
      "938/938 [==============================] - 0s 473us/step - loss: 8.1331e-10 - accuracy: 0.0000e+00 - val_loss: 5.4855e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/500\n",
      "938/938 [==============================] - 0s 476us/step - loss: 8.3963e-10 - accuracy: 0.0000e+00 - val_loss: 1.6655e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/500\n",
      "938/938 [==============================] - 0s 477us/step - loss: 7.9981e-10 - accuracy: 0.0000e+00 - val_loss: 7.2205e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/500\n",
      "938/938 [==============================] - 0s 481us/step - loss: 9.0386e-10 - accuracy: 0.0000e+00 - val_loss: 6.1755e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/500\n",
      "938/938 [==============================] - 0s 473us/step - loss: 9.6042e-10 - accuracy: 0.0000e+00 - val_loss: 5.7650e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/500\n",
      "938/938 [==============================] - 0s 472us/step - loss: 8.6004e-10 - accuracy: 0.0000e+00 - val_loss: 6.0654e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/500\n",
      "938/938 [==============================] - 0s 472us/step - loss: 5.9301e-10 - accuracy: 0.0000e+00 - val_loss: 8.8286e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/500\n",
      "938/938 [==============================] - 0s 472us/step - loss: 8.3585e-10 - accuracy: 0.0000e+00 - val_loss: 2.2885e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/500\n",
      "938/938 [==============================] - 0s 473us/step - loss: 9.3504e-10 - accuracy: 0.0000e+00 - val_loss: 4.6027e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/500\n",
      "938/938 [==============================] - 0s 477us/step - loss: 8.2727e-10 - accuracy: 0.0000e+00 - val_loss: 2.2080e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/500\n",
      "938/938 [==============================] - 0s 484us/step - loss: 8.8483e-10 - accuracy: 0.0000e+00 - val_loss: 9.7000e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/500\n",
      "938/938 [==============================] - 0s 477us/step - loss: 8.2975e-10 - accuracy: 0.0000e+00 - val_loss: 4.5995e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/500\n",
      "938/938 [==============================] - 0s 479us/step - loss: 9.6631e-10 - accuracy: 0.0000e+00 - val_loss: 4.4332e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/500\n",
      "938/938 [==============================] - 0s 477us/step - loss: 7.2528e-10 - accuracy: 0.0000e+00 - val_loss: 7.3178e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/500\n",
      "938/938 [==============================] - 0s 478us/step - loss: 8.7327e-10 - accuracy: 0.0000e+00 - val_loss: 2.5833e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/500\n",
      "938/938 [==============================] - 0s 479us/step - loss: 1.0037e-09 - accuracy: 0.0000e+00 - val_loss: 1.9410e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/500\n",
      "938/938 [==============================] - 0s 476us/step - loss: 8.8041e-10 - accuracy: 0.0000e+00 - val_loss: 2.0817e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/500\n",
      "938/938 [==============================] - 0s 481us/step - loss: 6.5504e-10 - accuracy: 0.0000e+00 - val_loss: 8.4671e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/500\n",
      "938/938 [==============================] - 0s 478us/step - loss: 8.8166e-10 - accuracy: 0.0000e+00 - val_loss: 1.2037e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/500\n",
      "938/938 [==============================] - 0s 477us/step - loss: 8.0461e-10 - accuracy: 0.0000e+00 - val_loss: 8.9371e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/500\n",
      "938/938 [==============================] - 0s 477us/step - loss: 1.1609e-09 - accuracy: 0.0000e+00 - val_loss: 7.1020e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/500\n",
      "938/938 [==============================] - 0s 475us/step - loss: 5.4731e-10 - accuracy: 0.0000e+00 - val_loss: 2.4858e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/500\n",
      "938/938 [==============================] - 0s 477us/step - loss: 9.4686e-10 - accuracy: 0.0000e+00 - val_loss: 2.3874e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/500\n",
      "938/938 [==============================] - 0s 486us/step - loss: 9.3032e-10 - accuracy: 0.0000e+00 - val_loss: 4.3556e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/500\n",
      "938/938 [==============================] - 0s 480us/step - loss: 6.6317e-10 - accuracy: 0.0000e+00 - val_loss: 2.3819e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/500\n",
      "938/938 [==============================] - 0s 477us/step - loss: 8.0720e-10 - accuracy: 0.0000e+00 - val_loss: 3.2812e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/500\n",
      "938/938 [==============================] - 0s 475us/step - loss: 1.0786e-09 - accuracy: 0.0000e+00 - val_loss: 4.4906e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/500\n",
      "938/938 [==============================] - 0s 476us/step - loss: 7.9953e-10 - accuracy: 0.0000e+00 - val_loss: 4.2502e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/500\n",
      "938/938 [==============================] - 0s 479us/step - loss: 7.3891e-10 - accuracy: 0.0000e+00 - val_loss: 1.1727e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/500\n",
      "938/938 [==============================] - 0s 478us/step - loss: 1.0192e-09 - accuracy: 0.0000e+00 - val_loss: 4.5355e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/500\n",
      "938/938 [==============================] - 0s 482us/step - loss: 7.0884e-10 - accuracy: 0.0000e+00 - val_loss: 6.6331e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/500\n",
      "938/938 [==============================] - 0s 475us/step - loss: 8.8508e-10 - accuracy: 0.0000e+00 - val_loss: 4.5511e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/500\n",
      "938/938 [==============================] - 0s 475us/step - loss: 8.1736e-10 - accuracy: 0.0000e+00 - val_loss: 1.6630e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/500\n",
      "938/938 [==============================] - 0s 473us/step - loss: 9.3019e-10 - accuracy: 0.0000e+00 - val_loss: 4.3286e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/500\n",
      "938/938 [==============================] - 0s 476us/step - loss: 8.7268e-10 - accuracy: 0.0000e+00 - val_loss: 1.5057e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/500\n",
      "938/938 [==============================] - 0s 475us/step - loss: 7.1325e-10 - accuracy: 0.0000e+00 - val_loss: 5.7763e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/500\n",
      "938/938 [==============================] - 0s 473us/step - loss: 8.4544e-10 - accuracy: 0.0000e+00 - val_loss: 9.4556e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/500\n",
      "938/938 [==============================] - 0s 480us/step - loss: 1.1212e-09 - accuracy: 0.0000e+00 - val_loss: 1.0354e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/500\n",
      "938/938 [==============================] - 0s 475us/step - loss: 7.5821e-10 - accuracy: 0.0000e+00 - val_loss: 1.8357e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/500\n",
      "938/938 [==============================] - 0s 473us/step - loss: 7.4062e-10 - accuracy: 0.0000e+00 - val_loss: 4.3029e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/500\n",
      "938/938 [==============================] - 0s 473us/step - loss: 1.0144e-09 - accuracy: 0.0000e+00 - val_loss: 1.1330e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/500\n",
      "938/938 [==============================] - 0s 475us/step - loss: 9.7081e-10 - accuracy: 0.0000e+00 - val_loss: 5.0691e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/500\n",
      "938/938 [==============================] - 0s 477us/step - loss: 5.9702e-10 - accuracy: 0.0000e+00 - val_loss: 6.0855e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/500\n",
      "938/938 [==============================] - 0s 473us/step - loss: 8.2980e-10 - accuracy: 0.0000e+00 - val_loss: 1.5582e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/500\n",
      "938/938 [==============================] - 0s 482us/step - loss: 8.8553e-10 - accuracy: 0.0000e+00 - val_loss: 5.9812e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/500\n",
      "938/938 [==============================] - 0s 475us/step - loss: 8.7972e-10 - accuracy: 0.0000e+00 - val_loss: 1.4203e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/500\n",
      "938/938 [==============================] - 0s 473us/step - loss: 9.1525e-10 - accuracy: 0.0000e+00 - val_loss: 4.7125e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/500\n",
      "938/938 [==============================] - 0s 475us/step - loss: 7.0584e-10 - accuracy: 0.0000e+00 - val_loss: 1.0569e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/500\n",
      "938/938 [==============================] - 0s 475us/step - loss: 1.1427e-09 - accuracy: 0.0000e+00 - val_loss: 1.6961e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/500\n",
      "938/938 [==============================] - 0s 471us/step - loss: 6.8630e-10 - accuracy: 0.0000e+00 - val_loss: 4.5732e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/500\n",
      "938/938 [==============================] - 0s 472us/step - loss: 9.6139e-10 - accuracy: 0.0000e+00 - val_loss: 4.7687e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/500\n",
      "938/938 [==============================] - 0s 496us/step - loss: 7.3307e-10 - accuracy: 0.0000e+00 - val_loss: 1.5726e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/500\n",
      "938/938 [==============================] - 0s 501us/step - loss: 9.4503e-10 - accuracy: 0.0000e+00 - val_loss: 4.3733e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/500\n",
      "938/938 [==============================] - 0s 497us/step - loss: 6.3353e-10 - accuracy: 0.0000e+00 - val_loss: 2.1229e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/500\n",
      "938/938 [==============================] - 0s 492us/step - loss: 8.4389e-10 - accuracy: 0.0000e+00 - val_loss: 4.9366e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/500\n",
      "938/938 [==============================] - 0s 487us/step - loss: 8.3733e-10 - accuracy: 0.0000e+00 - val_loss: 1.2570e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/500\n",
      "938/938 [==============================] - 0s 496us/step - loss: 8.2988e-10 - accuracy: 0.0000e+00 - val_loss: 2.4676e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/500\n",
      "938/938 [==============================] - 0s 489us/step - loss: 8.4117e-10 - accuracy: 0.0000e+00 - val_loss: 6.5365e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/500\n",
      "938/938 [==============================] - 1s 540us/step - loss: 8.3175e-10 - accuracy: 0.0000e+00 - val_loss: 6.3473e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/500\n",
      "938/938 [==============================] - 0s 495us/step - loss: 8.3146e-10 - accuracy: 0.0000e+00 - val_loss: 3.9973e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/500\n",
      "938/938 [==============================] - 0s 492us/step - loss: 8.9361e-10 - accuracy: 0.0000e+00 - val_loss: 5.5633e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/500\n",
      "938/938 [==============================] - 0s 485us/step - loss: 8.3705e-10 - accuracy: 0.0000e+00 - val_loss: 4.8846e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/500\n",
      "938/938 [==============================] - 0s 473us/step - loss: 1.2961e-09 - accuracy: 0.0000e+00 - val_loss: 8.9633e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/500\n",
      "938/938 [==============================] - 0s 491us/step - loss: 7.6077e-10 - accuracy: 0.0000e+00 - val_loss: 4.2779e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/500\n",
      "938/938 [==============================] - 0s 503us/step - loss: 9.1578e-10 - accuracy: 0.0000e+00 - val_loss: 4.6291e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/500\n",
      "938/938 [==============================] - 0s 484us/step - loss: 5.6217e-10 - accuracy: 0.0000e+00 - val_loss: 1.5400e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/500\n",
      "938/938 [==============================] - 0s 485us/step - loss: 8.5231e-10 - accuracy: 0.0000e+00 - val_loss: 1.7676e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/500\n",
      "938/938 [==============================] - 0s 492us/step - loss: 1.0981e-09 - accuracy: 0.0000e+00 - val_loss: 6.1835e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/500\n",
      "938/938 [==============================] - 0s 479us/step - loss: 8.7257e-10 - accuracy: 0.0000e+00 - val_loss: 4.2676e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/500\n",
      "938/938 [==============================] - 0s 476us/step - loss: 6.4184e-10 - accuracy: 0.0000e+00 - val_loss: 7.8226e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/500\n",
      "938/938 [==============================] - 0s 483us/step - loss: 7.7583e-10 - accuracy: 0.0000e+00 - val_loss: 1.6540e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/500\n",
      "938/938 [==============================] - 0s 485us/step - loss: 8.8470e-10 - accuracy: 0.0000e+00 - val_loss: 1.2930e-08 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/500\n",
      "938/938 [==============================] - 0s 471us/step - loss: 1.0864e-09 - accuracy: 0.0000e+00 - val_loss: 2.2750e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/500\n",
      "938/938 [==============================] - 0s 481us/step - loss: 7.5343e-10 - accuracy: 0.0000e+00 - val_loss: 4.4352e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/500\n",
      "938/938 [==============================] - 0s 488us/step - loss: 6.5328e-10 - accuracy: 0.0000e+00 - val_loss: 1.7381e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/500\n",
      "938/938 [==============================] - 0s 512us/step - loss: 8.4311e-10 - accuracy: 0.0000e+00 - val_loss: 1.8560e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/500\n",
      "938/938 [==============================] - 0s 473us/step - loss: 8.6505e-10 - accuracy: 0.0000e+00 - val_loss: 1.9503e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/500\n",
      "938/938 [==============================] - 0s 472us/step - loss: 8.3463e-10 - accuracy: 0.0000e+00 - val_loss: 1.2979e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/500\n",
      "938/938 [==============================] - 0s 496us/step - loss: 1.0135e-09 - accuracy: 0.0000e+00 - val_loss: 4.9656e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/500\n",
      "938/938 [==============================] - 0s 483us/step - loss: 5.9838e-10 - accuracy: 0.0000e+00 - val_loss: 3.7239e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/500\n",
      "938/938 [==============================] - 0s 483us/step - loss: 8.3038e-10 - accuracy: 0.0000e+00 - val_loss: 4.4465e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/500\n",
      "938/938 [==============================] - 0s 482us/step - loss: 9.2962e-10 - accuracy: 0.0000e+00 - val_loss: 3.8296e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/500\n",
      "938/938 [==============================] - 0s 497us/step - loss: 9.5251e-10 - accuracy: 0.0000e+00 - val_loss: 4.3089e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/500\n",
      "938/938 [==============================] - 0s 482us/step - loss: 7.2523e-10 - accuracy: 0.0000e+00 - val_loss: 5.4008e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/500\n",
      "938/938 [==============================] - 0s 479us/step - loss: 8.6975e-10 - accuracy: 0.0000e+00 - val_loss: 4.7397e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/500\n",
      "938/938 [==============================] - 0s 482us/step - loss: 8.7083e-10 - accuracy: 0.0000e+00 - val_loss: 6.5336e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/500\n",
      "938/938 [==============================] - 0s 482us/step - loss: 8.2012e-10 - accuracy: 0.0000e+00 - val_loss: 4.7612e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/500\n",
      "938/938 [==============================] - 0s 479us/step - loss: 7.7289e-10 - accuracy: 0.0000e+00 - val_loss: 9.7176e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/500\n",
      "938/938 [==============================] - 0s 486us/step - loss: 9.0053e-10 - accuracy: 0.0000e+00 - val_loss: 5.2403e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/500\n",
      "938/938 [==============================] - 0s 494us/step - loss: 9.9821e-10 - accuracy: 0.0000e+00 - val_loss: 9.5520e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/500\n",
      "938/938 [==============================] - 0s 489us/step - loss: 6.7396e-10 - accuracy: 0.0000e+00 - val_loss: 1.6025e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/500\n",
      "938/938 [==============================] - 0s 505us/step - loss: 8.9838e-10 - accuracy: 0.0000e+00 - val_loss: 5.3056e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/500\n",
      "938/938 [==============================] - 0s 511us/step - loss: 7.5434e-10 - accuracy: 0.0000e+00 - val_loss: 5.5165e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/500\n",
      "938/938 [==============================] - 0s 489us/step - loss: 8.7738e-10 - accuracy: 0.0000e+00 - val_loss: 2.6436e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/500\n",
      "938/938 [==============================] - 0s 478us/step - loss: 8.3760e-10 - accuracy: 0.0000e+00 - val_loss: 3.6660e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/500\n",
      "938/938 [==============================] - 0s 497us/step - loss: 1.0505e-09 - accuracy: 0.0000e+00 - val_loss: 4.9210e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/500\n",
      "938/938 [==============================] - 0s 497us/step - loss: 7.0657e-10 - accuracy: 0.0000e+00 - val_loss: 2.3199e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/500\n",
      "938/938 [==============================] - 1s 547us/step - loss: 9.9080e-10 - accuracy: 0.0000e+00 - val_loss: 6.2026e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/500\n",
      "938/938 [==============================] - 0s 496us/step - loss: 1.0150e-09 - accuracy: 0.0000e+00 - val_loss: 4.7330e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/500\n",
      "938/938 [==============================] - 0s 480us/step - loss: 5.6875e-10 - accuracy: 0.0000e+00 - val_loss: 8.6232e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/500\n",
      "938/938 [==============================] - 0s 476us/step - loss: 7.9967e-10 - accuracy: 0.0000e+00 - val_loss: 7.1347e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/500\n",
      "938/938 [==============================] - 0s 488us/step - loss: 8.6319e-10 - accuracy: 0.0000e+00 - val_loss: 8.6816e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/500\n",
      "938/938 [==============================] - 0s 497us/step - loss: 8.5327e-10 - accuracy: 0.0000e+00 - val_loss: 1.6702e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/500\n",
      "938/938 [==============================] - 0s 524us/step - loss: 1.2313e-09 - accuracy: 0.0000e+00 - val_loss: 6.7757e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/500\n",
      "938/938 [==============================] - 0s 503us/step - loss: 5.1555e-10 - accuracy: 0.0000e+00 - val_loss: 1.1082e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/500\n",
      "938/938 [==============================] - 0s 498us/step - loss: 8.2414e-10 - accuracy: 0.0000e+00 - val_loss: 4.5264e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/500\n",
      "938/938 [==============================] - 0s 481us/step - loss: 9.2399e-10 - accuracy: 0.0000e+00 - val_loss: 1.6529e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/500\n",
      "938/938 [==============================] - 0s 486us/step - loss: 8.3853e-10 - accuracy: 0.0000e+00 - val_loss: 1.0504e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/500\n",
      "938/938 [==============================] - 0s 492us/step - loss: 1.1214e-09 - accuracy: 0.0000e+00 - val_loss: 8.1419e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/500\n",
      "938/938 [==============================] - 0s 486us/step - loss: 8.8464e-10 - accuracy: 0.0000e+00 - val_loss: 1.1830e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/500\n",
      "938/938 [==============================] - 0s 489us/step - loss: 1.0031e-09 - accuracy: 0.0000e+00 - val_loss: 6.1568e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/500\n",
      "938/938 [==============================] - 1s 541us/step - loss: 4.5515e-10 - accuracy: 0.0000e+00 - val_loss: 2.1039e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/500\n",
      "938/938 [==============================] - 1s 548us/step - loss: 1.0806e-09 - accuracy: 0.0000e+00 - val_loss: 5.9610e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/500\n",
      "938/938 [==============================] - 1s 553us/step - loss: 8.8068e-10 - accuracy: 0.0000e+00 - val_loss: 3.0528e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/500\n",
      "938/938 [==============================] - 0s 530us/step - loss: 7.1780e-10 - accuracy: 0.0000e+00 - val_loss: 5.5212e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/500\n",
      "938/938 [==============================] - 0s 476us/step - loss: 7.7702e-10 - accuracy: 0.0000e+00 - val_loss: 4.8076e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/500\n",
      "938/938 [==============================] - 0s 492us/step - loss: 1.1393e-09 - accuracy: 0.0000e+00 - val_loss: 5.1357e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/500\n",
      "938/938 [==============================] - 0s 503us/step - loss: 6.2818e-10 - accuracy: 0.0000e+00 - val_loss: 6.9636e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/500\n",
      "938/938 [==============================] - 0s 488us/step - loss: 8.6886e-10 - accuracy: 0.0000e+00 - val_loss: 4.2854e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/500\n",
      "938/938 [==============================] - 0s 491us/step - loss: 6.9450e-10 - accuracy: 0.0000e+00 - val_loss: 7.0517e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/500\n",
      "938/938 [==============================] - 0s 501us/step - loss: 1.0062e-09 - accuracy: 0.0000e+00 - val_loss: 4.3656e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/500\n",
      "938/938 [==============================] - 0s 514us/step - loss: 6.4337e-10 - accuracy: 0.0000e+00 - val_loss: 4.5311e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/500\n",
      "938/938 [==============================] - 1s 535us/step - loss: 8.3697e-10 - accuracy: 0.0000e+00 - val_loss: 2.2290e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/500\n",
      "938/938 [==============================] - 0s 500us/step - loss: 9.5596e-10 - accuracy: 0.0000e+00 - val_loss: 1.5352e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/500\n",
      "938/938 [==============================] - 0s 504us/step - loss: 7.9419e-10 - accuracy: 0.0000e+00 - val_loss: 1.4052e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/500\n",
      "938/938 [==============================] - 0s 488us/step - loss: 1.0516e-09 - accuracy: 0.0000e+00 - val_loss: 8.6078e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/500\n",
      "938/938 [==============================] - 0s 480us/step - loss: 6.0887e-10 - accuracy: 0.0000e+00 - val_loss: 8.0656e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/500\n",
      "938/938 [==============================] - 0s 475us/step - loss: 9.0349e-10 - accuracy: 0.0000e+00 - val_loss: 1.1258e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/500\n",
      "938/938 [==============================] - 0s 471us/step - loss: 7.6164e-10 - accuracy: 0.0000e+00 - val_loss: 1.1672e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/500\n",
      "938/938 [==============================] - 0s 473us/step - loss: 8.1821e-10 - accuracy: 0.0000e+00 - val_loss: 1.0855e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/500\n",
      "938/938 [==============================] - 0s 475us/step - loss: 9.1601e-10 - accuracy: 0.0000e+00 - val_loss: 7.4026e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/500\n",
      "938/938 [==============================] - 0s 481us/step - loss: 8.1595e-10 - accuracy: 0.0000e+00 - val_loss: 3.9678e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/500\n",
      "938/938 [==============================] - 0s 477us/step - loss: 9.2288e-10 - accuracy: 0.0000e+00 - val_loss: 9.4434e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/500\n",
      "938/938 [==============================] - 0s 480us/step - loss: 8.9417e-10 - accuracy: 0.0000e+00 - val_loss: 6.3929e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/500\n",
      "938/938 [==============================] - 0s 481us/step - loss: 7.0283e-10 - accuracy: 0.0000e+00 - val_loss: 1.0548e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/500\n",
      "938/938 [==============================] - 0s 476us/step - loss: 1.0463e-09 - accuracy: 0.0000e+00 - val_loss: 3.0051e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/500\n",
      "938/938 [==============================] - 0s 476us/step - loss: 9.9752e-10 - accuracy: 0.0000e+00 - val_loss: 1.7109e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/500\n",
      "938/938 [==============================] - 0s 472us/step - loss: 6.9303e-10 - accuracy: 0.0000e+00 - val_loss: 6.4754e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/500\n",
      "938/938 [==============================] - 0s 487us/step - loss: 6.9331e-10 - accuracy: 0.0000e+00 - val_loss: 4.9693e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/500\n",
      "938/938 [==============================] - 0s 471us/step - loss: 8.5722e-10 - accuracy: 0.0000e+00 - val_loss: 1.0476e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/500\n",
      "938/938 [==============================] - 0s 475us/step - loss: 8.6393e-10 - accuracy: 0.0000e+00 - val_loss: 4.4806e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/500\n",
      "938/938 [==============================] - 0s 477us/step - loss: 8.6066e-10 - accuracy: 0.0000e+00 - val_loss: 5.4533e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/500\n",
      "938/938 [==============================] - 0s 475us/step - loss: 8.2550e-10 - accuracy: 0.0000e+00 - val_loss: 1.2341e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/500\n",
      "938/938 [==============================] - 0s 476us/step - loss: 1.0693e-09 - accuracy: 0.0000e+00 - val_loss: 4.4857e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/500\n",
      "938/938 [==============================] - 0s 477us/step - loss: 6.4362e-10 - accuracy: 0.0000e+00 - val_loss: 1.5736e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/500\n",
      "938/938 [==============================] - 0s 480us/step - loss: 7.6545e-10 - accuracy: 0.0000e+00 - val_loss: 2.8920e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/500\n",
      "938/938 [==============================] - 0s 477us/step - loss: 7.9060e-10 - accuracy: 0.0000e+00 - val_loss: 1.7184e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/500\n",
      "938/938 [==============================] - 0s 477us/step - loss: 8.9703e-10 - accuracy: 0.0000e+00 - val_loss: 4.5286e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/500\n",
      "938/938 [==============================] - 0s 481us/step - loss: 7.5303e-10 - accuracy: 0.0000e+00 - val_loss: 1.0596e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/500\n",
      "938/938 [==============================] - 0s 472us/step - loss: 9.6184e-10 - accuracy: 0.0000e+00 - val_loss: 2.8239e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/500\n",
      "938/938 [==============================] - 0s 472us/step - loss: 7.1374e-10 - accuracy: 0.0000e+00 - val_loss: 4.2586e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/500\n",
      "938/938 [==============================] - 0s 503us/step - loss: 8.6762e-10 - accuracy: 0.0000e+00 - val_loss: 6.9072e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/500\n",
      "938/938 [==============================] - 0s 531us/step - loss: 1.0416e-09 - accuracy: 0.0000e+00 - val_loss: 4.2526e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/500\n",
      "938/938 [==============================] - 0s 506us/step - loss: 7.4316e-10 - accuracy: 0.0000e+00 - val_loss: 3.3430e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/500\n",
      "938/938 [==============================] - 0s 504us/step - loss: 7.3444e-10 - accuracy: 0.0000e+00 - val_loss: 1.8411e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/500\n",
      "938/938 [==============================] - 0s 496us/step - loss: 8.6574e-10 - accuracy: 0.0000e+00 - val_loss: 7.7118e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/500\n",
      "938/938 [==============================] - 0s 484us/step - loss: 8.3256e-10 - accuracy: 0.0000e+00 - val_loss: 1.2379e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/500\n",
      "938/938 [==============================] - 0s 488us/step - loss: 1.1939e-09 - accuracy: 0.0000e+00 - val_loss: 7.2124e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/500\n",
      "938/938 [==============================] - 0s 493us/step - loss: 4.6413e-10 - accuracy: 0.0000e+00 - val_loss: 7.1509e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/500\n",
      "938/938 [==============================] - 0s 486us/step - loss: 1.0527e-09 - accuracy: 0.0000e+00 - val_loss: 2.0362e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/500\n",
      "938/938 [==============================] - 0s 489us/step - loss: 9.0237e-10 - accuracy: 0.0000e+00 - val_loss: 6.8240e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/500\n",
      "938/938 [==============================] - 0s 490us/step - loss: 7.0302e-10 - accuracy: 0.0000e+00 - val_loss: 1.8650e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/500\n",
      "938/938 [==============================] - 0s 484us/step - loss: 9.6643e-10 - accuracy: 0.0000e+00 - val_loss: 4.8607e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/500\n",
      "938/938 [==============================] - 0s 484us/step - loss: 6.4803e-10 - accuracy: 0.0000e+00 - val_loss: 1.3490e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/500\n",
      "938/938 [==============================] - 0s 488us/step - loss: 8.1416e-10 - accuracy: 0.0000e+00 - val_loss: 4.2375e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/500\n",
      "938/938 [==============================] - 0s 490us/step - loss: 8.4373e-10 - accuracy: 0.0000e+00 - val_loss: 6.3333e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/500\n",
      "938/938 [==============================] - 0s 485us/step - loss: 1.0422e-09 - accuracy: 0.0000e+00 - val_loss: 7.9505e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/500\n",
      "938/938 [==============================] - 0s 484us/step - loss: 5.1807e-10 - accuracy: 0.0000e+00 - val_loss: 1.6087e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/500\n",
      "938/938 [==============================] - 0s 492us/step - loss: 8.2741e-10 - accuracy: 0.0000e+00 - val_loss: 5.3201e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/500\n",
      "938/938 [==============================] - 0s 508us/step - loss: 9.2895e-10 - accuracy: 0.0000e+00 - val_loss: 1.3092e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/500\n",
      "938/938 [==============================] - 1s 547us/step - loss: 7.5167e-10 - accuracy: 0.0000e+00 - val_loss: 6.1891e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/500\n",
      "938/938 [==============================] - 0s 520us/step - loss: 1.0222e-09 - accuracy: 0.0000e+00 - val_loss: 4.4280e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/500\n",
      "938/938 [==============================] - 0s 509us/step - loss: 8.3743e-10 - accuracy: 0.0000e+00 - val_loss: 4.4776e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/500\n",
      "938/938 [==============================] - 0s 499us/step - loss: 6.4885e-10 - accuracy: 0.0000e+00 - val_loss: 1.3724e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/500\n",
      "938/938 [==============================] - 0s 506us/step - loss: 8.1129e-10 - accuracy: 0.0000e+00 - val_loss: 1.2804e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/500\n",
      "938/938 [==============================] - 0s 512us/step - loss: 1.1182e-09 - accuracy: 0.0000e+00 - val_loss: 4.2576e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/500\n",
      "938/938 [==============================] - 0s 510us/step - loss: 7.4270e-10 - accuracy: 0.0000e+00 - val_loss: 4.2435e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/500\n",
      "938/938 [==============================] - 0s 505us/step - loss: 7.7475e-10 - accuracy: 0.0000e+00 - val_loss: 1.3361e-08 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/500\n",
      "938/938 [==============================] - 0s 511us/step - loss: 1.1149e-09 - accuracy: 0.0000e+00 - val_loss: 2.2717e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/500\n",
      "938/938 [==============================] - 0s 508us/step - loss: 7.1967e-10 - accuracy: 0.0000e+00 - val_loss: 1.0991e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/500\n",
      "938/938 [==============================] - 0s 512us/step - loss: 8.0931e-10 - accuracy: 0.0000e+00 - val_loss: 1.0936e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/500\n",
      "938/938 [==============================] - 0s 500us/step - loss: 8.4564e-10 - accuracy: 0.0000e+00 - val_loss: 6.0837e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/500\n",
      "938/938 [==============================] - 0s 515us/step - loss: 8.0100e-10 - accuracy: 0.0000e+00 - val_loss: 5.7950e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/500\n",
      "938/938 [==============================] - 0s 518us/step - loss: 8.6772e-10 - accuracy: 0.0000e+00 - val_loss: 4.5741e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/500\n",
      "938/938 [==============================] - 0s 512us/step - loss: 9.8949e-10 - accuracy: 0.0000e+00 - val_loss: 4.5328e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/500\n",
      "938/938 [==============================] - 0s 504us/step - loss: 6.8728e-10 - accuracy: 0.0000e+00 - val_loss: 4.4412e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/500\n",
      "938/938 [==============================] - 1s 542us/step - loss: 9.4080e-10 - accuracy: 0.0000e+00 - val_loss: 1.0205e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/500\n",
      "938/938 [==============================] - 0s 519us/step - loss: 7.3406e-10 - accuracy: 0.0000e+00 - val_loss: 6.4722e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/500\n",
      "938/938 [==============================] - 0s 514us/step - loss: 8.3448e-10 - accuracy: 0.0000e+00 - val_loss: 1.2674e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/500\n",
      "938/938 [==============================] - 0s 493us/step - loss: 8.6015e-10 - accuracy: 0.0000e+00 - val_loss: 6.6756e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/500\n",
      "938/938 [==============================] - 0s 493us/step - loss: 1.0832e-09 - accuracy: 0.0000e+00 - val_loss: 4.5920e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/500\n",
      "938/938 [==============================] - 0s 500us/step - loss: 6.7127e-10 - accuracy: 0.0000e+00 - val_loss: 2.0906e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/500\n",
      "938/938 [==============================] - 0s 497us/step - loss: 9.0268e-10 - accuracy: 0.0000e+00 - val_loss: 4.2971e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/500\n",
      "938/938 [==============================] - 1s 556us/step - loss: 6.6960e-10 - accuracy: 0.0000e+00 - val_loss: 1.4741e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/500\n",
      "938/938 [==============================] - 0s 502us/step - loss: 9.0059e-10 - accuracy: 0.0000e+00 - val_loss: 1.8225e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/500\n",
      "938/938 [==============================] - 0s 509us/step - loss: 1.2169e-09 - accuracy: 0.0000e+00 - val_loss: 4.7255e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/500\n",
      "938/938 [==============================] - 0s 512us/step - loss: 4.3677e-10 - accuracy: 0.0000e+00 - val_loss: 2.0377e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/500\n",
      "938/938 [==============================] - 0s 528us/step - loss: 9.1772e-10 - accuracy: 0.0000e+00 - val_loss: 4.2639e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/500\n",
      "938/938 [==============================] - 0s 524us/step - loss: 8.4850e-10 - accuracy: 0.0000e+00 - val_loss: 1.7561e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/500\n",
      "938/938 [==============================] - 0s 517us/step - loss: 9.4411e-10 - accuracy: 0.0000e+00 - val_loss: 8.2926e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/500\n",
      "938/938 [==============================] - 0s 514us/step - loss: 8.9013e-10 - accuracy: 0.0000e+00 - val_loss: 4.4068e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/500\n",
      "938/938 [==============================] - 0s 527us/step - loss: 6.3356e-10 - accuracy: 0.0000e+00 - val_loss: 1.7325e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/500\n",
      "938/938 [==============================] - 0s 515us/step - loss: 1.0112e-09 - accuracy: 0.0000e+00 - val_loss: 4.3677e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/500\n",
      "938/938 [==============================] - 0s 520us/step - loss: 7.3658e-10 - accuracy: 0.0000e+00 - val_loss: 4.6586e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/500\n",
      "938/938 [==============================] - 0s 518us/step - loss: 1.0966e-09 - accuracy: 0.0000e+00 - val_loss: 4.6792e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/500\n",
      "938/938 [==============================] - 0s 507us/step - loss: 6.3585e-10 - accuracy: 0.0000e+00 - val_loss: 5.4849e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/500\n",
      "938/938 [==============================] - 0s 522us/step - loss: 7.8306e-10 - accuracy: 0.0000e+00 - val_loss: 2.2351e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/500\n",
      "938/938 [==============================] - 0s 509us/step - loss: 7.4209e-10 - accuracy: 0.0000e+00 - val_loss: 5.1631e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/500\n",
      "938/938 [==============================] - 0s 499us/step - loss: 8.9327e-10 - accuracy: 0.0000e+00 - val_loss: 5.9118e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/500\n",
      "938/938 [==============================] - 0s 492us/step - loss: 7.7888e-10 - accuracy: 0.0000e+00 - val_loss: 1.7509e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/500\n",
      "938/938 [==============================] - 0s 502us/step - loss: 8.6835e-10 - accuracy: 0.0000e+00 - val_loss: 5.1213e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/500\n",
      "938/938 [==============================] - 0s 502us/step - loss: 8.2381e-10 - accuracy: 0.0000e+00 - val_loss: 5.7625e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/500\n",
      "938/938 [==============================] - 0s 505us/step - loss: 7.5869e-10 - accuracy: 0.0000e+00 - val_loss: 9.0635e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/500\n",
      "938/938 [==============================] - 0s 495us/step - loss: 8.5091e-10 - accuracy: 0.0000e+00 - val_loss: 7.4759e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/500\n",
      "938/938 [==============================] - 0s 507us/step - loss: 1.0082e-09 - accuracy: 0.0000e+00 - val_loss: 4.2495e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/500\n",
      "938/938 [==============================] - 0s 492us/step - loss: 7.8503e-10 - accuracy: 0.0000e+00 - val_loss: 6.6278e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/500\n",
      "938/938 [==============================] - 0s 493us/step - loss: 9.0538e-10 - accuracy: 0.0000e+00 - val_loss: 4.2847e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/500\n",
      "938/938 [==============================] - 0s 503us/step - loss: 8.3204e-10 - accuracy: 0.0000e+00 - val_loss: 6.1137e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/500\n",
      "938/938 [==============================] - 0s 493us/step - loss: 7.0947e-10 - accuracy: 0.0000e+00 - val_loss: 4.6479e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/500\n",
      "938/938 [==============================] - 0s 484us/step - loss: 9.2863e-10 - accuracy: 0.0000e+00 - val_loss: 4.3364e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/500\n",
      "938/938 [==============================] - 0s 496us/step - loss: 8.7302e-10 - accuracy: 0.0000e+00 - val_loss: 3.7009e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/500\n",
      "938/938 [==============================] - 0s 520us/step - loss: 9.0157e-10 - accuracy: 0.0000e+00 - val_loss: 4.6898e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/500\n",
      "938/938 [==============================] - 0s 487us/step - loss: 6.3181e-10 - accuracy: 0.0000e+00 - val_loss: 1.1372e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/500\n",
      "938/938 [==============================] - 0s 497us/step - loss: 9.7018e-10 - accuracy: 0.0000e+00 - val_loss: 5.0288e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/500\n",
      "938/938 [==============================] - 0s 502us/step - loss: 8.0173e-10 - accuracy: 0.0000e+00 - val_loss: 4.1413e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/500\n",
      "938/938 [==============================] - 0s 507us/step - loss: 9.3647e-10 - accuracy: 0.0000e+00 - val_loss: 4.4100e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/500\n",
      "938/938 [==============================] - 0s 528us/step - loss: 9.1834e-10 - accuracy: 0.0000e+00 - val_loss: 4.6845e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/500\n",
      "938/938 [==============================] - 0s 481us/step - loss: 6.5601e-10 - accuracy: 0.0000e+00 - val_loss: 1.1806e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/500\n",
      "938/938 [==============================] - 0s 489us/step - loss: 8.6251e-10 - accuracy: 0.0000e+00 - val_loss: 3.4113e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/500\n",
      "938/938 [==============================] - 0s 508us/step - loss: 9.1126e-10 - accuracy: 0.0000e+00 - val_loss: 6.5464e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/500\n",
      "938/938 [==============================] - 0s 486us/step - loss: 8.6104e-10 - accuracy: 0.0000e+00 - val_loss: 4.5281e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/500\n",
      "938/938 [==============================] - 0s 477us/step - loss: 9.0650e-10 - accuracy: 0.0000e+00 - val_loss: 1.4043e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/500\n",
      "938/938 [==============================] - 0s 476us/step - loss: 8.6538e-10 - accuracy: 0.0000e+00 - val_loss: 3.0259e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/500\n",
      "938/938 [==============================] - 0s 477us/step - loss: 1.0443e-09 - accuracy: 0.0000e+00 - val_loss: 4.5572e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/500\n",
      "938/938 [==============================] - 0s 480us/step - loss: 6.0831e-10 - accuracy: 0.0000e+00 - val_loss: 2.2331e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/500\n",
      "938/938 [==============================] - 0s 494us/step - loss: 1.0925e-09 - accuracy: 0.0000e+00 - val_loss: 1.0368e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/500\n",
      "938/938 [==============================] - 0s 493us/step - loss: 7.1993e-10 - accuracy: 0.0000e+00 - val_loss: 2.3219e-08 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/500\n",
      "938/938 [==============================] - 0s 496us/step - loss: 9.1355e-10 - accuracy: 0.0000e+00 - val_loss: 8.5240e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/500\n",
      "938/938 [==============================] - 0s 495us/step - loss: 6.0083e-10 - accuracy: 0.0000e+00 - val_loss: 6.1764e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/500\n",
      "938/938 [==============================] - 0s 493us/step - loss: 1.0991e-09 - accuracy: 0.0000e+00 - val_loss: 5.9678e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/500\n",
      "938/938 [==============================] - 0s 488us/step - loss: 6.3651e-10 - accuracy: 0.0000e+00 - val_loss: 1.9857e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/500\n",
      "938/938 [==============================] - 0s 485us/step - loss: 8.5942e-10 - accuracy: 0.0000e+00 - val_loss: 4.6423e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/500\n",
      "938/938 [==============================] - 0s 492us/step - loss: 8.9342e-10 - accuracy: 0.0000e+00 - val_loss: 4.4285e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/500\n",
      "938/938 [==============================] - 0s 488us/step - loss: 1.0122e-09 - accuracy: 0.0000e+00 - val_loss: 4.2414e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/500\n",
      "938/938 [==============================] - 0s 519us/step - loss: 5.8203e-10 - accuracy: 0.0000e+00 - val_loss: 2.8269e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/500\n",
      "938/938 [==============================] - 0s 511us/step - loss: 9.3133e-10 - accuracy: 0.0000e+00 - val_loss: 4.5745e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 356/500\n",
      "938/938 [==============================] - 0s 507us/step - loss: 8.9483e-10 - accuracy: 0.0000e+00 - val_loss: 1.0429e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/500\n",
      "938/938 [==============================] - 0s 503us/step - loss: 9.2383e-10 - accuracy: 0.0000e+00 - val_loss: 6.0586e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/500\n",
      "938/938 [==============================] - 0s 504us/step - loss: 6.8729e-10 - accuracy: 0.0000e+00 - val_loss: 6.2569e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/500\n",
      "938/938 [==============================] - 0s 505us/step - loss: 9.6036e-10 - accuracy: 0.0000e+00 - val_loss: 6.5146e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/500\n",
      "938/938 [==============================] - 0s 511us/step - loss: 7.2427e-10 - accuracy: 0.0000e+00 - val_loss: 3.8055e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/500\n",
      "938/938 [==============================] - 0s 509us/step - loss: 8.9313e-10 - accuracy: 0.0000e+00 - val_loss: 8.5901e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/500\n",
      "938/938 [==============================] - 0s 513us/step - loss: 8.9555e-10 - accuracy: 0.0000e+00 - val_loss: 4.2758e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/500\n",
      "938/938 [==============================] - 0s 486us/step - loss: 8.4276e-10 - accuracy: 0.0000e+00 - val_loss: 4.6631e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/500\n",
      "938/938 [==============================] - 0s 518us/step - loss: 9.5579e-10 - accuracy: 0.0000e+00 - val_loss: 9.2305e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/500\n",
      "938/938 [==============================] - 0s 517us/step - loss: 8.8848e-10 - accuracy: 0.0000e+00 - val_loss: 1.3538e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/500\n",
      "938/938 [==============================] - 0s 511us/step - loss: 7.7502e-10 - accuracy: 0.0000e+00 - val_loss: 3.6952e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/500\n",
      "938/938 [==============================] - 0s 516us/step - loss: 1.1146e-09 - accuracy: 0.0000e+00 - val_loss: 9.3835e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/500\n",
      "938/938 [==============================] - 0s 485us/step - loss: 5.2268e-10 - accuracy: 0.0000e+00 - val_loss: 1.1857e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/500\n",
      "938/938 [==============================] - 0s 489us/step - loss: 8.4061e-10 - accuracy: 0.0000e+00 - val_loss: 4.4900e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/500\n",
      "938/938 [==============================] - 0s 486us/step - loss: 8.2828e-10 - accuracy: 0.0000e+00 - val_loss: 2.9997e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/500\n",
      "938/938 [==============================] - 0s 485us/step - loss: 1.1569e-09 - accuracy: 0.0000e+00 - val_loss: 9.7022e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/500\n",
      "938/938 [==============================] - 0s 492us/step - loss: 5.2285e-10 - accuracy: 0.0000e+00 - val_loss: 7.7517e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/500\n",
      "938/938 [==============================] - 0s 503us/step - loss: 9.8073e-10 - accuracy: 0.0000e+00 - val_loss: 4.4465e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/500\n",
      "938/938 [==============================] - 0s 492us/step - loss: 1.0018e-09 - accuracy: 0.0000e+00 - val_loss: 6.6249e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/500\n",
      "938/938 [==============================] - 0s 487us/step - loss: 5.4846e-10 - accuracy: 0.0000e+00 - val_loss: 5.7375e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/500\n",
      "938/938 [==============================] - 0s 486us/step - loss: 7.9347e-10 - accuracy: 0.0000e+00 - val_loss: 9.5904e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/500\n",
      "938/938 [==============================] - 0s 485us/step - loss: 8.9662e-10 - accuracy: 0.0000e+00 - val_loss: 5.8117e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/500\n",
      "938/938 [==============================] - 0s 486us/step - loss: 1.0332e-09 - accuracy: 0.0000e+00 - val_loss: 4.9022e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/500\n",
      "938/938 [==============================] - 0s 489us/step - loss: 8.6548e-10 - accuracy: 0.0000e+00 - val_loss: 1.2224e-08 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/500\n",
      "938/938 [==============================] - 0s 484us/step - loss: 8.2771e-10 - accuracy: 0.0000e+00 - val_loss: 4.8977e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/500\n",
      "938/938 [==============================] - 0s 486us/step - loss: 8.9158e-10 - accuracy: 0.0000e+00 - val_loss: 5.8359e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/500\n",
      "938/938 [==============================] - 0s 485us/step - loss: 6.8842e-10 - accuracy: 0.0000e+00 - val_loss: 7.7560e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/500\n",
      "938/938 [==============================] - 0s 499us/step - loss: 9.6200e-10 - accuracy: 0.0000e+00 - val_loss: 4.3108e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/500\n",
      "938/938 [==============================] - 0s 486us/step - loss: 9.4728e-10 - accuracy: 0.0000e+00 - val_loss: 8.6818e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 385/500\n",
      "938/938 [==============================] - 0s 484us/step - loss: 6.0687e-10 - accuracy: 0.0000e+00 - val_loss: 3.3418e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/500\n",
      "938/938 [==============================] - 0s 491us/step - loss: 7.8974e-10 - accuracy: 0.0000e+00 - val_loss: 4.6472e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/500\n",
      "938/938 [==============================] - 0s 484us/step - loss: 8.6971e-10 - accuracy: 0.0000e+00 - val_loss: 6.5850e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/500\n",
      "938/938 [==============================] - 0s 485us/step - loss: 1.0001e-09 - accuracy: 0.0000e+00 - val_loss: 4.4029e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/500\n",
      "938/938 [==============================] - 0s 484us/step - loss: 7.9840e-10 - accuracy: 0.0000e+00 - val_loss: 4.2520e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 390/500\n",
      "938/938 [==============================] - 0s 484us/step - loss: 7.2543e-10 - accuracy: 0.0000e+00 - val_loss: 4.8785e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/500\n",
      "938/938 [==============================] - 0s 484us/step - loss: 1.0908e-09 - accuracy: 0.0000e+00 - val_loss: 4.9249e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/500\n",
      "938/938 [==============================] - 0s 487us/step - loss: 6.9401e-10 - accuracy: 0.0000e+00 - val_loss: 4.8268e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/500\n",
      "938/938 [==============================] - 0s 490us/step - loss: 1.0367e-09 - accuracy: 0.0000e+00 - val_loss: 5.4435e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/500\n",
      "938/938 [==============================] - 0s 484us/step - loss: 6.0014e-10 - accuracy: 0.0000e+00 - val_loss: 2.8147e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/500\n",
      "938/938 [==============================] - 0s 481us/step - loss: 9.2274e-10 - accuracy: 0.0000e+00 - val_loss: 1.5298e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/500\n",
      "938/938 [==============================] - 0s 484us/step - loss: 9.5414e-10 - accuracy: 0.0000e+00 - val_loss: 6.0935e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/500\n",
      "938/938 [==============================] - 0s 487us/step - loss: 7.4782e-10 - accuracy: 0.0000e+00 - val_loss: 1.3460e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/500\n",
      "938/938 [==============================] - 0s 485us/step - loss: 9.6282e-10 - accuracy: 0.0000e+00 - val_loss: 8.6862e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 399/500\n",
      "938/938 [==============================] - 0s 485us/step - loss: 8.0993e-10 - accuracy: 0.0000e+00 - val_loss: 9.3003e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 400/500\n",
      "938/938 [==============================] - 0s 493us/step - loss: 8.2875e-10 - accuracy: 0.0000e+00 - val_loss: 6.7032e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 401/500\n",
      "938/938 [==============================] - 0s 486us/step - loss: 1.1707e-09 - accuracy: 0.0000e+00 - val_loss: 5.3867e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 402/500\n",
      "938/938 [==============================] - 0s 487us/step - loss: 6.1798e-10 - accuracy: 0.0000e+00 - val_loss: 1.7734e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 403/500\n",
      "938/938 [==============================] - 0s 485us/step - loss: 9.5188e-10 - accuracy: 0.0000e+00 - val_loss: 2.1712e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 404/500\n",
      "938/938 [==============================] - 0s 485us/step - loss: 6.9336e-10 - accuracy: 0.0000e+00 - val_loss: 7.8647e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 405/500\n",
      "938/938 [==============================] - 0s 509us/step - loss: 8.5680e-10 - accuracy: 0.0000e+00 - val_loss: 4.0094e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 406/500\n",
      "938/938 [==============================] - 0s 517us/step - loss: 8.0455e-10 - accuracy: 0.0000e+00 - val_loss: 8.3779e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 407/500\n",
      "938/938 [==============================] - 0s 505us/step - loss: 9.6378e-10 - accuracy: 0.0000e+00 - val_loss: 4.2691e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 408/500\n",
      "938/938 [==============================] - 0s 502us/step - loss: 6.9924e-10 - accuracy: 0.0000e+00 - val_loss: 7.4171e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 409/500\n",
      "938/938 [==============================] - 0s 509us/step - loss: 1.1089e-09 - accuracy: 0.0000e+00 - val_loss: 4.2455e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 410/500\n",
      "938/938 [==============================] - 0s 503us/step - loss: 6.7977e-10 - accuracy: 0.0000e+00 - val_loss: 5.7330e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 411/500\n",
      "938/938 [==============================] - 0s 524us/step - loss: 8.1584e-10 - accuracy: 0.0000e+00 - val_loss: 5.2359e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 412/500\n",
      "938/938 [==============================] - 0s 502us/step - loss: 8.7645e-10 - accuracy: 0.0000e+00 - val_loss: 3.0776e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 413/500\n",
      "938/938 [==============================] - 0s 493us/step - loss: 7.6570e-10 - accuracy: 0.0000e+00 - val_loss: 4.3465e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 414/500\n",
      "938/938 [==============================] - 0s 479us/step - loss: 8.7100e-10 - accuracy: 0.0000e+00 - val_loss: 5.3243e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 415/500\n",
      "938/938 [==============================] - 0s 479us/step - loss: 1.0186e-09 - accuracy: 0.0000e+00 - val_loss: 1.1996e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 416/500\n",
      "938/938 [==============================] - 0s 477us/step - loss: 6.7100e-10 - accuracy: 0.0000e+00 - val_loss: 7.0661e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 417/500\n",
      "938/938 [==============================] - 0s 478us/step - loss: 8.3136e-10 - accuracy: 0.0000e+00 - val_loss: 1.0052e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 418/500\n",
      "938/938 [==============================] - 0s 479us/step - loss: 9.0934e-10 - accuracy: 0.0000e+00 - val_loss: 4.3420e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 419/500\n",
      "938/938 [==============================] - 0s 481us/step - loss: 7.2893e-10 - accuracy: 0.0000e+00 - val_loss: 9.0445e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 420/500\n",
      "938/938 [==============================] - 0s 481us/step - loss: 1.1629e-09 - accuracy: 0.0000e+00 - val_loss: 5.2805e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 421/500\n",
      "938/938 [==============================] - 0s 477us/step - loss: 5.9518e-10 - accuracy: 0.0000e+00 - val_loss: 1.0973e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 422/500\n",
      "938/938 [==============================] - 0s 477us/step - loss: 7.8725e-10 - accuracy: 0.0000e+00 - val_loss: 3.4967e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 423/500\n",
      "938/938 [==============================] - 0s 477us/step - loss: 8.2265e-10 - accuracy: 0.0000e+00 - val_loss: 5.7988e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 424/500\n",
      "938/938 [==============================] - 0s 478us/step - loss: 8.4427e-10 - accuracy: 0.0000e+00 - val_loss: 1.4419e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 425/500\n",
      "938/938 [==============================] - 0s 477us/step - loss: 8.8980e-10 - accuracy: 0.0000e+00 - val_loss: 7.9804e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 426/500\n",
      "938/938 [==============================] - 0s 484us/step - loss: 8.6033e-10 - accuracy: 0.0000e+00 - val_loss: 2.1979e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 427/500\n",
      "938/938 [==============================] - 0s 478us/step - loss: 1.0011e-09 - accuracy: 0.0000e+00 - val_loss: 4.2231e-08 - val_accuracy: 0.0000e+00\n",
      "Epoch 428/500\n",
      "938/938 [==============================] - 0s 473us/step - loss: 1.0059e-09 - accuracy: 0.0000e+00 - val_loss: 2.2228e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 429/500\n",
      "938/938 [==============================] - 0s 475us/step - loss: 5.0522e-10 - accuracy: 0.0000e+00 - val_loss: 8.3189e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 430/500\n",
      "938/938 [==============================] - 0s 477us/step - loss: 9.3880e-10 - accuracy: 0.0000e+00 - val_loss: 2.4745e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 431/500\n",
      "938/938 [==============================] - 0s 477us/step - loss: 7.9434e-10 - accuracy: 0.0000e+00 - val_loss: 1.6395e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 432/500\n",
      "938/938 [==============================] - 0s 476us/step - loss: 8.3088e-10 - accuracy: 0.0000e+00 - val_loss: 6.9614e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 433/500\n",
      "938/938 [==============================] - 0s 484us/step - loss: 1.2172e-09 - accuracy: 0.0000e+00 - val_loss: 1.3927e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 434/500\n",
      "938/938 [==============================] - 0s 475us/step - loss: 7.3383e-10 - accuracy: 0.0000e+00 - val_loss: 4.8686e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 435/500\n",
      "938/938 [==============================] - 0s 475us/step - loss: 8.4852e-10 - accuracy: 0.0000e+00 - val_loss: 8.3240e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 436/500\n",
      "938/938 [==============================] - 0s 478us/step - loss: 6.4098e-10 - accuracy: 0.0000e+00 - val_loss: 6.3719e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 437/500\n",
      "938/938 [==============================] - 0s 485us/step - loss: 8.6020e-10 - accuracy: 0.0000e+00 - val_loss: 3.4735e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 438/500\n",
      "938/938 [==============================] - 0s 476us/step - loss: 8.2530e-10 - accuracy: 0.0000e+00 - val_loss: 9.3148e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 439/500\n",
      "938/938 [==============================] - 0s 478us/step - loss: 1.1019e-09 - accuracy: 0.0000e+00 - val_loss: 4.9146e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 440/500\n",
      "938/938 [==============================] - 0s 484us/step - loss: 6.2032e-10 - accuracy: 0.0000e+00 - val_loss: 4.2859e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 441/500\n",
      "938/938 [==============================] - 0s 475us/step - loss: 8.4972e-10 - accuracy: 0.0000e+00 - val_loss: 9.9134e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 442/500\n",
      "938/938 [==============================] - 0s 484us/step - loss: 8.0800e-10 - accuracy: 0.0000e+00 - val_loss: 4.4534e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 443/500\n",
      "938/938 [==============================] - 0s 499us/step - loss: 8.1783e-10 - accuracy: 0.0000e+00 - val_loss: 5.1033e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 444/500\n",
      "938/938 [==============================] - 0s 494us/step - loss: 8.3928e-10 - accuracy: 0.0000e+00 - val_loss: 1.4644e-08 - val_accuracy: 0.0000e+00\n",
      "Epoch 445/500\n",
      "938/938 [==============================] - 0s 482us/step - loss: 9.5929e-10 - accuracy: 0.0000e+00 - val_loss: 5.2652e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 446/500\n",
      "938/938 [==============================] - 0s 477us/step - loss: 7.6056e-10 - accuracy: 0.0000e+00 - val_loss: 2.2019e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 447/500\n",
      "938/938 [==============================] - 0s 495us/step - loss: 7.8710e-10 - accuracy: 0.0000e+00 - val_loss: 1.1698e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 448/500\n",
      "938/938 [==============================] - 0s 486us/step - loss: 1.1094e-09 - accuracy: 0.0000e+00 - val_loss: 4.4018e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 449/500\n",
      "938/938 [==============================] - 0s 479us/step - loss: 6.6788e-10 - accuracy: 0.0000e+00 - val_loss: 5.3252e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 450/500\n",
      "938/938 [==============================] - 0s 479us/step - loss: 8.0966e-10 - accuracy: 0.0000e+00 - val_loss: 8.0507e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 451/500\n",
      "938/938 [==============================] - 0s 478us/step - loss: 8.4075e-10 - accuracy: 0.0000e+00 - val_loss: 8.0009e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 452/500\n",
      "938/938 [==============================] - 0s 478us/step - loss: 8.6947e-10 - accuracy: 0.0000e+00 - val_loss: 4.3861e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 453/500\n",
      "938/938 [==============================] - 0s 496us/step - loss: 7.9698e-10 - accuracy: 0.0000e+00 - val_loss: 9.2042e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 454/500\n",
      "938/938 [==============================] - 0s 495us/step - loss: 8.1625e-10 - accuracy: 0.0000e+00 - val_loss: 4.9803e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 455/500\n",
      "938/938 [==============================] - 0s 494us/step - loss: 8.7993e-10 - accuracy: 0.0000e+00 - val_loss: 4.2912e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 456/500\n",
      "938/938 [==============================] - 0s 475us/step - loss: 1.0338e-09 - accuracy: 0.0000e+00 - val_loss: 4.2296e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 457/500\n",
      "938/938 [==============================] - 0s 480us/step - loss: 7.8171e-10 - accuracy: 0.0000e+00 - val_loss: 1.8648e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 458/500\n",
      "938/938 [==============================] - 0s 476us/step - loss: 9.6716e-10 - accuracy: 0.0000e+00 - val_loss: 4.7868e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 459/500\n",
      "938/938 [==============================] - 0s 489us/step - loss: 6.7062e-10 - accuracy: 0.0000e+00 - val_loss: 5.4461e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 460/500\n",
      "938/938 [==============================] - 0s 483us/step - loss: 1.1153e-09 - accuracy: 0.0000e+00 - val_loss: 1.1705e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 461/500\n",
      "938/938 [==============================] - 0s 484us/step - loss: 5.2873e-10 - accuracy: 0.0000e+00 - val_loss: 8.8968e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 462/500\n",
      "938/938 [==============================] - 0s 484us/step - loss: 9.1123e-10 - accuracy: 0.0000e+00 - val_loss: 4.7495e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 463/500\n",
      "938/938 [==============================] - 0s 488us/step - loss: 8.1121e-10 - accuracy: 0.0000e+00 - val_loss: 5.0297e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 464/500\n",
      "938/938 [==============================] - 0s 475us/step - loss: 9.0258e-10 - accuracy: 0.0000e+00 - val_loss: 4.2529e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 465/500\n",
      "938/938 [==============================] - 0s 478us/step - loss: 8.4017e-10 - accuracy: 0.0000e+00 - val_loss: 3.8485e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 466/500\n",
      "938/938 [==============================] - 0s 480us/step - loss: 8.3838e-10 - accuracy: 0.0000e+00 - val_loss: 2.6252e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 467/500\n",
      "938/938 [==============================] - 0s 479us/step - loss: 8.1858e-10 - accuracy: 0.0000e+00 - val_loss: 1.2960e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 468/500\n",
      "938/938 [==============================] - 0s 476us/step - loss: 8.7392e-10 - accuracy: 0.0000e+00 - val_loss: 7.2739e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 469/500\n",
      "938/938 [==============================] - 0s 487us/step - loss: 1.1181e-09 - accuracy: 0.0000e+00 - val_loss: 1.4796e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 470/500\n",
      "938/938 [==============================] - 0s 480us/step - loss: 7.8989e-10 - accuracy: 0.0000e+00 - val_loss: 1.5220e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 471/500\n",
      "938/938 [==============================] - 0s 478us/step - loss: 6.2193e-10 - accuracy: 0.0000e+00 - val_loss: 3.8459e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 472/500\n",
      "938/938 [==============================] - 0s 485us/step - loss: 1.2530e-09 - accuracy: 0.0000e+00 - val_loss: 1.2918e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 473/500\n",
      "938/938 [==============================] - 0s 483us/step - loss: 6.5488e-10 - accuracy: 0.0000e+00 - val_loss: 4.8124e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 474/500\n",
      "938/938 [==============================] - 0s 532us/step - loss: 6.7856e-10 - accuracy: 0.0000e+00 - val_loss: 7.7067e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 475/500\n",
      "938/938 [==============================] - 0s 507us/step - loss: 8.0391e-10 - accuracy: 0.0000e+00 - val_loss: 1.2007e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 476/500\n",
      "938/938 [==============================] - 0s 494us/step - loss: 8.6816e-10 - accuracy: 0.0000e+00 - val_loss: 4.3227e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 477/500\n",
      "938/938 [==============================] - 0s 487us/step - loss: 7.2957e-10 - accuracy: 0.0000e+00 - val_loss: 4.6944e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 478/500\n",
      "938/938 [==============================] - 0s 497us/step - loss: 8.7277e-10 - accuracy: 0.0000e+00 - val_loss: 7.9758e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 479/500\n",
      "938/938 [==============================] - 0s 489us/step - loss: 8.9240e-10 - accuracy: 0.0000e+00 - val_loss: 1.0969e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 480/500\n",
      "938/938 [==============================] - 0s 496us/step - loss: 8.1543e-10 - accuracy: 0.0000e+00 - val_loss: 2.4421e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 481/500\n",
      "938/938 [==============================] - 0s 486us/step - loss: 9.7824e-10 - accuracy: 0.0000e+00 - val_loss: 5.0865e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 482/500\n",
      "938/938 [==============================] - 0s 491us/step - loss: 7.2330e-10 - accuracy: 0.0000e+00 - val_loss: 1.2364e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 483/500\n",
      "938/938 [==============================] - 0s 519us/step - loss: 8.9288e-10 - accuracy: 0.0000e+00 - val_loss: 5.1037e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 484/500\n",
      "938/938 [==============================] - 0s 503us/step - loss: 9.9352e-10 - accuracy: 0.0000e+00 - val_loss: 6.5429e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 485/500\n",
      "938/938 [==============================] - 0s 492us/step - loss: 1.0247e-09 - accuracy: 0.0000e+00 - val_loss: 6.7950e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 486/500\n",
      "938/938 [==============================] - 0s 480us/step - loss: 4.9773e-10 - accuracy: 0.0000e+00 - val_loss: 4.4249e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 487/500\n",
      "938/938 [==============================] - 0s 498us/step - loss: 9.9138e-10 - accuracy: 0.0000e+00 - val_loss: 4.3025e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 488/500\n",
      "938/938 [==============================] - 0s 486us/step - loss: 8.2732e-10 - accuracy: 0.0000e+00 - val_loss: 4.3749e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 489/500\n",
      "938/938 [==============================] - 0s 491us/step - loss: 7.4756e-10 - accuracy: 0.0000e+00 - val_loss: 1.5534e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 490/500\n",
      "938/938 [==============================] - 0s 485us/step - loss: 8.3795e-10 - accuracy: 0.0000e+00 - val_loss: 1.8363e-09 - val_accuracy: 0.0000e+00\n",
      "Epoch 491/500\n",
      "938/938 [==============================] - 0s 482us/step - loss: 8.7799e-10 - accuracy: 0.0000e+00 - val_loss: 2.4389e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 492/500\n",
      "938/938 [==============================] - 0s 479us/step - loss: 9.2008e-10 - accuracy: 0.0000e+00 - val_loss: 5.3233e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 493/500\n",
      "938/938 [==============================] - 0s 477us/step - loss: 8.5368e-10 - accuracy: 0.0000e+00 - val_loss: 9.7470e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 494/500\n",
      "938/938 [==============================] - 0s 483us/step - loss: 8.3981e-10 - accuracy: 0.0000e+00 - val_loss: 9.2586e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 495/500\n",
      "938/938 [==============================] - 0s 485us/step - loss: 8.7405e-10 - accuracy: 0.0000e+00 - val_loss: 5.6443e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 496/500\n",
      "938/938 [==============================] - 0s 486us/step - loss: 8.0339e-10 - accuracy: 0.0000e+00 - val_loss: 8.5020e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 497/500\n",
      "938/938 [==============================] - 0s 511us/step - loss: 8.6868e-10 - accuracy: 0.0000e+00 - val_loss: 6.3682e-10 - val_accuracy: 0.0000e+00\n",
      "Epoch 498/500\n",
      "938/938 [==============================] - 0s 483us/step - loss: 8.4435e-10 - accuracy: 0.0000e+00 - val_loss: 4.2906e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 499/500\n",
      "938/938 [==============================] - 0s 482us/step - loss: 8.3867e-10 - accuracy: 0.0000e+00 - val_loss: 7.9762e-11 - val_accuracy: 0.0000e+00\n",
      "Epoch 500/500\n",
      "938/938 [==============================] - 0s 499us/step - loss: 1.0063e-09 - accuracy: 0.0000e+00 - val_loss: 4.7947e-11 - val_accuracy: 0.0000e+00\n",
      "training Runtime: 3.87 Minutes\n"
     ]
    }
   ],
   "source": [
    "start_vect=time.time()\n",
    "\n",
    "model.compile(loss = \"mse\",\n",
    "              optimizer = \"ADAM\",\n",
    "              metrics = [\"accuracy\"])\n",
    "history = model.fit(x = QF_train, y = alpha_target_train, validation_data=(QF_val, alpha_target_val),epochs = 500)\n",
    "\n",
    "\n",
    "print(\"training Runtime: %0.2f Minutes\"%((time.time() - start_vect)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "_4nRWiJzYn6S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 259us/step - loss: 2.5668e-11 - accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(QF_test, alpha_target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "P1eQyhSvPFQe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.05480231e-16, 5.09413801e-10, 3.35160265e-08, ...,\n",
       "       2.05651231e-09, 2.05651231e-09, 5.21400829e-09])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_target"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "2021_11_19-TIK (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
