{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "65d15e0a",
   "metadata": {
    "id": "65d15e0a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "T = 1\n",
    "delta = 5\n",
    "N = 10\n",
    "M = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e5da26b4",
   "metadata": {
    "id": "e5da26b4"
   },
   "outputs": [],
   "source": [
    "def generate_Q(N,  M, tau):\n",
    "    ii = 0\n",
    "    tore = tau*np.sqrt(2/np.pi)\n",
    "    Q = []\n",
    "    while ii < M:\n",
    "        tempQ = 2*tore*np.random.rand(N) - tore\n",
    "        tempQ = np.array(tempQ)\n",
    "        if np.linalg.norm(tempQ) <= tore:\n",
    "            Q = np.append(Q, tempQ)\n",
    "            ii += 1\n",
    "    return (Q.reshape(-1, N))\n",
    "\n",
    "def sol_act(Q, T):\n",
    "    N = len(Q[0])\n",
    "    A = np.diag(np.exp(-(np.arange(1, N+1))**2*T))\n",
    "    F = A@Q.T #A = NxN, Q = MxN, Q.T = NxM , F = NxM\n",
    "    return F\n",
    "\n",
    "def noise_data(F, delta):\n",
    "    e = 2*np.random.rand(len(F[:,0]), len(F[0])) - 1\n",
    "    N = len(F[:])\n",
    "    for m in range(len(F[0])):\n",
    "        norm = np.linalg.norm(F[:,m])\n",
    "        e[:, m] = e[:, 0]*norm*delta\n",
    "    nF = F+e\n",
    "    return nF\n",
    "\n",
    "def sol_Tik(alpha, T, F):\n",
    "    N = len(F[:])\n",
    "    invA = np.diag(1/(alpha*np.exp((np.arange(1, N+1))**2*T)+np.exp(-(np.arange(1, N+1))**2*T))) # A = NxN\n",
    "    hatQ = invA@F \n",
    "    return hatQ\n",
    "\n",
    "def result_gen_data(N, M, tau, Q, delta):\n",
    "    #Q = generate_Q(N, M, tau)\n",
    "    T = 1\n",
    "    F = sol_act(Q, T)\n",
    "    nF = noise_data(F, delta)\n",
    "    np.savetxt('Q1.txt', Q.T, fmt='%8f', delimiter = ',', header='')\n",
    "    np.savetxt('F1.txt', F, fmt='%8f', delimiter = ',', header='')\n",
    "    np.savetxt('nF1.txt', nF, fmt='%8f', delimiter = ',', header='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "9fc3c737",
   "metadata": {
    "id": "9fc3c737"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.14214105,  0.19029447, -0.32995014, ..., -0.24718805,\n",
       "         0.23495808, -0.33341153],\n",
       "       [-0.1093144 , -0.08745137, -0.10878991, ...,  0.40444791,\n",
       "         0.056255  ,  0.28577918],\n",
       "       [-0.13770495, -0.1564227 ,  0.38883787, ..., -0.2937906 ,\n",
       "         0.24111486, -0.10381808],\n",
       "       ...,\n",
       "       [-0.18094292,  0.07724999,  0.01827093, ..., -0.04208125,\n",
       "        -0.3321787 ,  0.4099182 ],\n",
       "       [ 0.1364351 ,  0.19686836,  0.24291953, ..., -0.10406047,\n",
       "         0.14012355, -0.13344818],\n",
       "       [ 0.03110481,  0.36876122,  0.02809461, ...,  0.20799935,\n",
       "        -0.06571024,  0.0610461 ]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = generate_Q(N, M, tau = 1)\n",
    "F = sol_act(Q, T)\n",
    "nF = noise_data(F, delta)\n",
    "result_gen_data(N, M, tau = 1, Q = Q, delta = 0.01)\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "914c0663",
   "metadata": {
    "id": "914c0663"
   },
   "outputs": [],
   "source": [
    "def result_Lcurve(N, tau, delta, min_al):\n",
    "    #get data\n",
    "    M = 1 #one data set\n",
    "    Q = generate_Q(N, M, tau)\n",
    "    \n",
    "    T = 1\n",
    "    F = sol_act(Q, T)\n",
    "    nF = noise_data(F, delta)\n",
    "    \n",
    "    al = np.linspace(0, min_al, 100)\n",
    "    q1 = []\n",
    "    q2 = []\n",
    "    for ii in range(len(al)):\n",
    "        q1.append(sol_Tik(10**al[ii], T, F))\n",
    "        q2.append(sol_Tik(10**al[ii], T, nF))\n",
    "    q1 = np.array(q1) \n",
    "    q2 = np.array(q2)\n",
    "    \n",
    "    n = np.arange(1, N+1)\n",
    "    A = np.diag(np.exp(-n**2*T))\n",
    "    \n",
    "    x1 = []\n",
    "    x2 = []\n",
    "    y1 = []\n",
    "    y2 = []\n",
    "\n",
    "    for i in range(len(al)):\n",
    "        x1.append(np.linalg.norm(A@q1[i]-F))\n",
    "        y1.append(np.linalg.norm(q1[i]))\n",
    "        x2.append(np.linalg.norm(A@q2[i]-nF))\n",
    "        y2.append(np.linalg.norm(q2[i]))\n",
    "    \n",
    "    fig = plt.figure(figsize = (10,10))\n",
    "    fig.add_subplot(2, 1, 1)\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.plot(x1, y1)\n",
    "    plt.title(\"without noise\")\n",
    "\n",
    "    \n",
    "    fig.add_subplot(2, 1, 2)\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.plot(x2, y2)\n",
    "    plt.title(\"with noise\")     \n",
    "\n",
    "    \n",
    "    plt.show()\n",
    "    return np.array(x1), np.array(y1), np.array(x2), np.array(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a9eb39ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 611
    },
    "id": "a9eb39ce",
    "outputId": "420c0019-2478-49de-8659-476cbc8116f2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1, y1, x2, y2 = result_Lcurve(10, 1, 0.01, -20)\n",
    "x2 = np.flip(x2)\n",
    "y2 = np.flip(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "HSX9t8wy8F6r",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HSX9t8wy8F6r",
    "outputId": "21de2784-0845-4e2a-80e8-c36c19463ecc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " x2 : \n",
      " [0.00115305 0.00115324 0.00115337 0.00115345 0.0011535  0.00115353\n",
      " 0.00115355 0.00115356 0.00115357 0.00115357 0.00115358 0.00115358\n",
      " 0.00115358 0.00115358 0.00115358 0.00115358 0.00115358 0.00115358\n",
      " 0.00115358 0.00115358 0.00115358 0.00115358 0.00115358 0.00115359\n",
      " 0.0011536  0.00115361 0.00115365 0.00115374 0.00115391 0.0011542\n",
      " 0.00115465 0.00115523 0.00115587 0.00115649 0.00115702 0.00115742\n",
      " 0.00115771 0.00115792 0.00115805 0.00115814 0.00115819 0.00115823\n",
      " 0.00115825 0.00115827 0.00115828 0.00115828 0.00115829 0.00115829\n",
      " 0.00115829 0.00115829 0.00115829 0.0011583  0.0011583  0.00115832\n",
      " 0.00115837 0.00115848 0.00115873 0.00115926 0.0011603  0.00116213\n",
      " 0.00116495 0.00116865 0.00117282 0.00117686 0.00118032 0.00118301\n",
      " 0.00118496 0.0011863  0.0011872  0.0011878  0.00118819 0.00118848\n",
      " 0.00118876 0.00118917 0.00119    0.00119192 0.00119642 0.00120675\n",
      " 0.00122921 0.00127421 0.00135464 0.00147915 0.00164418 0.00183512\n",
      " 0.00204071 0.00227399 0.00259442 0.00312923 0.00408064 0.00570786\n",
      " 0.00830611 0.01218825 0.01762149 0.02468652 0.03310621 0.04218453\n",
      " 0.05098533 0.0586834  0.0648353  0.06940653]\n",
      " \n",
      " y2 : \n",
      " [2.46908689e+05 1.56166692e+05 9.85184328e+04 6.20508758e+04\n",
      " 3.90454574e+04 2.45595868e+04 1.54517726e+04 9.73518780e+03\n",
      " 6.15806416e+03 3.93480355e+03 2.57456560e+03 1.77061114e+03\n",
      " 1.32547709e+03 1.10140391e+03 9.99167273e+02 9.55626164e+02\n",
      " 9.37551935e+02 9.29774473e+02 9.25809516e+02 9.22844379e+02\n",
      " 9.19460802e+02 9.14634475e+02 9.07252609e+02 8.95818654e+02\n",
      " 8.78225310e+02 8.51605893e+02 8.12401466e+02 7.56919323e+02\n",
      " 6.82682830e+02 5.90471484e+02 4.85956308e+02 3.79109994e+02\n",
      " 2.80805182e+02 1.98749592e+02 1.35644688e+02 9.01058082e+01\n",
      " 5.87342309e+01 3.78133145e+01 2.41715967e+01 1.54211069e+01\n",
      " 9.89028013e+00 6.46146990e+00 4.40701375e+00 3.24966636e+00\n",
      " 2.65527434e+00 2.37921634e+00 2.26015318e+00 2.21016867e+00\n",
      " 2.18818110e+00 2.17634452e+00 2.16674255e+00 2.15518491e+00\n",
      " 2.13843173e+00 2.11283805e+00 2.07355857e+00 2.01407947e+00\n",
      " 1.92627573e+00 1.80157633e+00 1.63395224e+00 1.42464562e+00\n",
      " 1.18633819e+00 9.42515576e-01 7.20098133e-01 5.39670532e-01\n",
      " 4.09922720e-01 3.27905582e-01 2.82618401e-01 2.60496010e-01\n",
      " 2.50605330e-01 2.46391679e-01 2.44603277e-01 2.43782049e-01\n",
      " 2.43294648e-01 2.42850515e-01 2.42284991e-01 2.41464121e-01\n",
      " 2.40244328e-01 2.38464604e-01 2.35973533e-01 2.32701894e-01\n",
      " 2.28769901e-01 2.24554464e-01 2.20594962e-01 2.17322926e-01\n",
      " 2.14822679e-01 2.12828511e-01 2.10888331e-01 2.08490976e-01\n",
      " 2.05079916e-01 2.00002437e-01 1.92469752e-01 1.81600736e-01\n",
      " 1.66626080e-01 1.47290002e-01 1.24319669e-01 9.95897127e-02\n",
      " 7.56335796e-02 5.46872481e-02 3.79515761e-02 2.55174649e-02]\n"
     ]
    }
   ],
   "source": [
    "print(f' x2 : \\n {x2}\\n \\n y2 : \\n {y2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "v9-EgoVaNIY4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v9-EgoVaNIY4",
    "outputId": "5728fbe1-07dd-4f24-fc79-8ca52074663e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 1.94983862e-07, -9.07419972e+04]),\n",
       " array([ 1.24573223e-07, -5.76482589e+04]),\n",
       " array([ 7.90868218e-08, -3.64675569e+04]),\n",
       " array([ 5.00085937e-08, -2.30054184e+04]),\n",
       " array([ 3.15418758e-08, -1.44858706e+04]),\n",
       " array([ 1.98627252e-08, -9.10781423e+03]),\n",
       " array([ 1.24955386e-08, -5.71658478e+03]),\n",
       " array([ 7.85592914e-09, -3.57712364e+03]),\n",
       " array([ 4.93706125e-09, -2.22326061e+03]),\n",
       " array([ 3.10193678e-09, -1.36023795e+03]),\n",
       " array([ 1.94865844e-09, -8.03954458e+02]),\n",
       " array([ 1.22411176e-09, -4.45134057e+02]),\n",
       " array([ 7.69097436e-10, -2.24073178e+02]),\n",
       " array([ 4.83654084e-10, -1.02236637e+02]),\n",
       " array([ 3.05298667e-10, -4.35411089e+01]),\n",
       " array([ 1.95633671e-10, -1.80742285e+01]),\n",
       " array([ 1.32712051e-10, -7.77746222e+00]),\n",
       " array([ 1.08224016e-10, -3.96495710e+00]),\n",
       " array([ 1.30684580e-10, -2.96513694e+00]),\n",
       " array([ 2.39667809e-10, -3.38357685e+00]),\n",
       " array([ 5.44448361e-10, -4.82632780e+00]),\n",
       " array([ 1.31849439e-09, -7.38186596e+00]),\n",
       " array([ 3.21769502e-09, -1.14339542e+01]),\n",
       " array([ 7.75085393e-09, -1.75933446e+01]),\n",
       " array([ 1.81852624e-08, -2.66194171e+01]),\n",
       " array([ 4.09453591e-08, -3.92044263e+01]),\n",
       " array([ 8.67756474e-08, -5.54821435e+01]),\n",
       " array([ 1.68942974e-07, -7.42364933e+01]),\n",
       " array([ 2.94021478e-07, -9.22113461e+01]),\n",
       " array([ 4.45926059e-07, -1.04515175e+02]),\n",
       " array([ 5.79489530e-07, -1.06846314e+02]),\n",
       " array([ 6.43402422e-07, -9.83048121e+01]),\n",
       " array([ 6.17828795e-07, -8.20555907e+01]),\n",
       " array([ 5.25079956e-07, -6.31049039e+01]),\n",
       " array([ 4.05886193e-07, -4.55388795e+01]),\n",
       " array([ 2.92808899e-07, -3.13715773e+01]),\n",
       " array([ 2.01340687e-07, -2.09209164e+01]),\n",
       " array([ 1.34058988e-07, -1.36417178e+01]),\n",
       " array([ 8.73958971e-08, -8.75048978e+00]),\n",
       " array([ 5.62038395e-08, -5.53082682e+00]),\n",
       " array([ 3.58309460e-08, -3.42881023e+00]),\n",
       " array([ 2.27172102e-08, -2.05445614e+00]),\n",
       " array([ 1.43537034e-08, -1.15734739e+00]),\n",
       " array([ 9.05200570e-09, -5.94392027e-01]),\n",
       " array([ 5.70753089e-09, -2.76057996e-01]),\n",
       " array([ 3.61311469e-09, -1.19063158e-01]),\n",
       " array([ 2.33023643e-09, -4.99845097e-02]),\n",
       " array([ 1.61336942e-09, -2.19875703e-02]),\n",
       " array([ 1.38953003e-09, -1.18365782e-02]),\n",
       " array([ 1.81787729e-09, -9.60197683e-03]),\n",
       " array([ 3.50556479e-09, -1.15576393e-02]),\n",
       " array([ 8.06731877e-09, -1.67531807e-02]),\n",
       " array([ 1.94415618e-08, -2.55936796e-02]),\n",
       " array([ 4.67600470e-08, -3.92794738e-02]),\n",
       " array([ 1.09952391e-07, -5.94791002e-02]),\n",
       " array([ 2.48652500e-07, -8.78037463e-02]),\n",
       " array([ 5.30401442e-07, -1.24699394e-01]),\n",
       " array([ 1.04173854e-06, -1.67624096e-01]),\n",
       " array([ 1.83299509e-06, -2.09306620e-01]),\n",
       " array([ 2.81504190e-06, -2.38307426e-01]),\n",
       " array([ 3.70583141e-06, -2.43822616e-01]),\n",
       " array([ 4.16444340e-06, -2.22417443e-01]),\n",
       " array([ 4.03990474e-06, -1.80427602e-01]),\n",
       " array([ 3.46083680e-06, -1.29747812e-01]),\n",
       " array([ 2.69087658e-06, -8.20171375e-02]),\n",
       " array([ 1.94937295e-06, -4.52871812e-02]),\n",
       " array([ 1.34492900e-06, -2.21223915e-02]),\n",
       " array([ 8.99353271e-07, -9.89068007e-03]),\n",
       " array([ 5.92769003e-07, -4.21365087e-03]),\n",
       " array([ 3.96177241e-07, -1.78840149e-03]),\n",
       " array([ 2.8979597e-07, -8.2122786e-04]),\n",
       " array([ 2.77035154e-07, -4.87401804e-04]),\n",
       " array([ 4.07729590e-07, -4.44132202e-04]),\n",
       " array([ 8.31459123e-07, -5.65524200e-04]),\n",
       " array([ 1.91826690e-06, -8.20870179e-04]),\n",
       " array([ 4.50665184e-06, -1.21979338e-03]),\n",
       " array([ 1.03274139e-05, -1.77972385e-03]),\n",
       " array([ 2.24571945e-05, -2.49107101e-03]),\n",
       " array([ 4.50055545e-05, -3.27163829e-03]),\n",
       " array([ 8.04293414e-05, -3.93199351e-03]),\n",
       " array([ 0.0001245 , -0.00421544]),\n",
       " array([ 0.00016503, -0.0039595 ]),\n",
       " array([ 0.00019094, -0.00327204]),\n",
       " array([ 0.00020559, -0.00250025]),\n",
       " array([ 0.00023328, -0.00199417]),\n",
       " array([ 0.00032043, -0.00194018]),\n",
       " array([ 0.0005348 , -0.00239735]),\n",
       " array([ 0.00095141, -0.00341106]),\n",
       " array([ 0.00162723, -0.00507748]),\n",
       " array([ 0.00259825, -0.00753268]),\n",
       " array([ 0.00388214, -0.01086902]),\n",
       " array([ 0.00543324, -0.01497466]),\n",
       " array([ 0.00706502, -0.01933608]),\n",
       " array([ 0.00841969, -0.02297033]),\n",
       " array([ 0.00907832, -0.02472996]),\n",
       " array([ 0.0088008 , -0.02395613]),\n",
       " array([ 0.00769807, -0.02094633]),\n",
       " array([ 0.0061519 , -0.01673567]),\n",
       " array([ 0.00457123, -0.01243411])]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O = np.column_stack((x2, y2))\n",
    "v = []\n",
    "for i in range(len(O) - 1):\n",
    "    v.append(O[i+1]-O[i])\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8660e4",
   "metadata": {},
   "source": [
    "## 기존의 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "cetZUBpIf_gF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cetZUBpIf_gF",
    "outputId": "3b29b209-2951-4960-ecc4-b930210cc5d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.734150657750801e-18"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos = []\n",
    "#array([-0.00443861,  0.01208635]) = v[0]\n",
    "for i in range(len(v)-1):\n",
    "    v1_norm = np.linalg.norm(v[i])\n",
    "    v2_norm = np.linalg.norm(v[i+1])\n",
    "    v_cos = np.dot(v[i], v[i+1])/(v1_norm*v2_norm)\n",
    "    cos.append(v_cos)\n",
    "a = np.argmin(cos)\n",
    "a\n",
    "\n",
    "min_al = -20\n",
    "al = np.linspace(0, min_al, 100)\n",
    "alpha = 10**al[a]\n",
    "alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc4e2bb",
   "metadata": {},
   "source": [
    "## 개선"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0b33c90c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.734150657750801e-18"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_best_idx(x2, y2):\n",
    "    O = np.column_stack((x2, y2))\n",
    "    v = []\n",
    "    k = 10\n",
    "    for i in range(len(O) - 1 - k):\n",
    "        v.append(O[i+k]-O[i])\n",
    "    v\n",
    "\n",
    "    cos = []\n",
    "\n",
    "    for i in range(len(v)-1-k):\n",
    "        v1_norm = np.linalg.norm(v[i])\n",
    "        v2_norm = np.linalg.norm(v[i+k])\n",
    "        v_cos = np.dot(v[i], v[i+k])/(v1_norm*v2_norm)\n",
    "        cos.append(v_cos)\n",
    "    a = np.argmin(cos) + k\n",
    "    return a   \n",
    "\n",
    "a = find_best_idx(x2, y2)\n",
    "al = np.linspace(0, -20, 100)\n",
    "alpha = 10**al[a]\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "eGKFGyNch5n1",
   "metadata": {
    "id": "eGKFGyNch5n1"
   },
   "outputs": [],
   "source": [
    "hatQ = sol_Tik(alpha, T, F)\n",
    "nF = noise_data(F, delta = delta)\n",
    "hatQ\n",
    "np.savetxt('hatQ.txt', hatQ, fmt='%8f', delimiter = ',', header='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "696ecc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "arr = []\n",
    "for i in range(M):\n",
    "    arr.append(i+1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0f25ff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "#column name에 data가 들어가있기 때문에 \"names = arr\" 로 처리해 줍니다. arr은 1 ~ len(F)의 숫자가 담겨있습니다.\n",
    "dataF = pd.read_csv('C:/Users/Administrator/Tikhonov/v1/F1.txt', sep = ',', names = arr)\n",
    "#dataQ : Q로 학습\n",
    "#dataQ = pd.read_csv('C:/Users/Administrator/Tikhonov/v1/Q.txt', sep = ',', names = arr)\n",
    "dataQ = pd.read_csv('C:/Users/Administrator/Tikhonov/v1/hatQ.txt', sep = ',', names = arr)\n",
    "data_nF = pd.read_csv('C:/Users/Administrator/Tikhonov/v1/nF1.txt', sep = ',', names = arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "080159b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_arr(A):\n",
    "    arA = []\n",
    "    for j in range(len(A.iloc[0, :])):\n",
    "        arA1 = []\n",
    "        for i in range(len(A.iloc[:,0])):\n",
    "            tmpA = A.iloc[:,j][i]\n",
    "            arA1.append(tmpA)\n",
    "        arA.append(arA1)\n",
    "    return arA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "802ee24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make array\n",
    "arrF = make_arr(dataF)\n",
    "dataF = np.array(arrF)\n",
    "\n",
    "arrQ = make_arr(dataQ)\n",
    "dataQ = np.array(arrQ)\n",
    "\n",
    "arr_nF = make_arr(data_nF)\n",
    "data_nF = np.array(arr_nF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a73f5a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 10), (2000, 10), (2000, 10)\n",
      "(6000, 10), (2000, 10), (2000, 10)\n",
      "(6000, 10), (2000, 10), (2000, 10)\n"
     ]
    }
   ],
   "source": [
    "# data 분할\n",
    "\n",
    "import math\n",
    "train_size = math.floor(len(dataF)*0.6) # train : 60%\n",
    "val_size = math.floor(len(dataF)*0.2) #val : 20%\n",
    "test_size = math.floor(len(dataF)*0.2) #test : 20%\n",
    "#generate F_data, F_val, F_test\n",
    "F_data = dataF[:train_size, :]\n",
    "F_val = dataF[train_size:(val_size + train_size), :]\n",
    "F_test = dataF[(val_size + train_size):(val_size + train_size + test_size), :]\n",
    "\n",
    "#generate Q_data, Q_val, Q_test\n",
    "Q_data = dataQ[:train_size, :]\n",
    "Q_val = dataQ[train_size:(val_size + train_size), :]\n",
    "Q_test = dataQ[(val_size + train_size):(val_size + train_size + test_size), :]\n",
    "\n",
    "#generate nF_data, nF_val, nF_test\n",
    "nF_data = data_nF[:train_size, :]\n",
    "nF_val = data_nF[train_size:(val_size + train_size), :]\n",
    "nF_test = data_nF[(val_size + train_size):(val_size + train_size + test_size), :]\n",
    "\n",
    "print(f'{F_data.shape}, {F_test.shape}, {F_val.shape}')\n",
    "print(f'{Q_data.shape}, {Q_test.shape}, {Q_val.shape}')\n",
    "print(f'{nF_data.shape}, {nF_test.shape}, {nF_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a4a2d120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.Sequential() #Sequentioal\n",
    "\n",
    "model.add(keras.layers.Dense(input_dim = 10, units = 10, activation= \"tanh\",kernel_initializer =\"HeNormal\" )) \n",
    "model.add(keras.layers.Dense(20, activation= \"tanh\")) \n",
    "model.add(keras.layers.Dense(50, activation= \"tanh\"))  \n",
    "model.add(keras.layers.Dense(100, activation= \"tanh\")) \n",
    "model.add(keras.layers.Dense(120, activation= \"tanh\")) \n",
    "model.add(keras.layers.Dense(50, activation= \"tanh\"))\n",
    "model.add(keras.layers.Dense(10, activation= \"tanh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c1510ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.EarlyStopping at 0x23a96877520>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    F_train = tf.constant(F_data)\n",
    "    Q_train = tf.constant(Q_data)\n",
    "    nF_train = tf.constant(nF_data)\n",
    "tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=0, verbose=0,\n",
    "    mode='auto', baseline=None, restore_best_weights=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "12410566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "188/188 [==============================] - 0s 798us/step - loss: 0.0125 - accuracy: 0.4482 - val_loss: 0.0108 - val_accuracy: 0.5695\n",
      "Epoch 2/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0107 - accuracy: 0.5275 - val_loss: 0.0108 - val_accuracy: 0.5370\n",
      "Epoch 3/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0107 - accuracy: 0.5417 - val_loss: 0.0108 - val_accuracy: 0.5715\n",
      "Epoch 4/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5443 - val_loss: 0.0108 - val_accuracy: 0.4695\n",
      "Epoch 5/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0106 - accuracy: 0.5513 - val_loss: 0.0108 - val_accuracy: 0.5245\n",
      "Epoch 6/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0106 - accuracy: 0.5228 - val_loss: 0.0108 - val_accuracy: 0.5670\n",
      "Epoch 7/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0106 - accuracy: 0.5428 - val_loss: 0.0107 - val_accuracy: 0.5590\n",
      "Epoch 8/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0106 - accuracy: 0.5367 - val_loss: 0.0108 - val_accuracy: 0.5625\n",
      "Epoch 9/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0106 - accuracy: 0.5507 - val_loss: 0.0108 - val_accuracy: 0.4745\n",
      "Epoch 10/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0106 - accuracy: 0.5303 - val_loss: 0.0108 - val_accuracy: 0.5690\n",
      "Epoch 11/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5390 - val_loss: 0.0108 - val_accuracy: 0.5700\n",
      "Epoch 12/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0106 - accuracy: 0.5407 - val_loss: 0.0107 - val_accuracy: 0.5695\n",
      "Epoch 13/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5422 - val_loss: 0.0107 - val_accuracy: 0.5100\n",
      "Epoch 14/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0106 - accuracy: 0.5433 - val_loss: 0.0108 - val_accuracy: 0.5700\n",
      "Epoch 15/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0106 - accuracy: 0.5387 - val_loss: 0.0108 - val_accuracy: 0.5700\n",
      "Epoch 16/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5385 - val_loss: 0.0108 - val_accuracy: 0.5655\n",
      "Epoch 17/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5392 - val_loss: 0.0108 - val_accuracy: 0.5655\n",
      "Epoch 18/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5525 - val_loss: 0.0107 - val_accuracy: 0.5750\n",
      "Epoch 19/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0106 - accuracy: 0.5517 - val_loss: 0.0108 - val_accuracy: 0.5585\n",
      "Epoch 20/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0106 - accuracy: 0.5370 - val_loss: 0.0107 - val_accuracy: 0.5640\n",
      "Epoch 21/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0106 - accuracy: 0.5517 - val_loss: 0.0108 - val_accuracy: 0.5665\n",
      "Epoch 22/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0106 - accuracy: 0.5555 - val_loss: 0.0108 - val_accuracy: 0.5645\n",
      "Epoch 23/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5532 - val_loss: 0.0108 - val_accuracy: 0.5500\n",
      "Epoch 24/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5272 - val_loss: 0.0108 - val_accuracy: 0.4965\n",
      "Epoch 25/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0106 - accuracy: 0.5492 - val_loss: 0.0108 - val_accuracy: 0.5165\n",
      "Epoch 26/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0106 - accuracy: 0.5335 - val_loss: 0.0108 - val_accuracy: 0.5715\n",
      "Epoch 27/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0106 - accuracy: 0.5528 - val_loss: 0.0107 - val_accuracy: 0.5040\n",
      "Epoch 28/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0106 - accuracy: 0.5412 - val_loss: 0.0107 - val_accuracy: 0.5700\n",
      "Epoch 29/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5462 - val_loss: 0.0107 - val_accuracy: 0.5375\n",
      "Epoch 30/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0106 - accuracy: 0.5572 - val_loss: 0.0108 - val_accuracy: 0.5615\n",
      "Epoch 31/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0106 - accuracy: 0.5307 - val_loss: 0.0108 - val_accuracy: 0.5680\n",
      "Epoch 32/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5548 - val_loss: 0.0108 - val_accuracy: 0.5660\n",
      "Epoch 33/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0106 - accuracy: 0.5555 - val_loss: 0.0107 - val_accuracy: 0.5675\n",
      "Epoch 34/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0106 - accuracy: 0.5508 - val_loss: 0.0107 - val_accuracy: 0.5265\n",
      "Epoch 35/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0106 - accuracy: 0.5595 - val_loss: 0.0108 - val_accuracy: 0.5710\n",
      "Epoch 36/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5487 - val_loss: 0.0108 - val_accuracy: 0.5605\n",
      "Epoch 37/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0106 - accuracy: 0.5372 - val_loss: 0.0107 - val_accuracy: 0.5545\n",
      "Epoch 38/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0106 - accuracy: 0.5568 - val_loss: 0.0107 - val_accuracy: 0.5320\n",
      "Epoch 39/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5532 - val_loss: 0.0107 - val_accuracy: 0.5370\n",
      "Epoch 40/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0106 - accuracy: 0.5415 - val_loss: 0.0107 - val_accuracy: 0.5670\n",
      "Epoch 41/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5610 - val_loss: 0.0108 - val_accuracy: 0.5545\n",
      "Epoch 42/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0106 - accuracy: 0.5477 - val_loss: 0.0107 - val_accuracy: 0.5630\n",
      "Epoch 43/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0106 - accuracy: 0.5510 - val_loss: 0.0107 - val_accuracy: 0.5675\n",
      "Epoch 44/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0106 - accuracy: 0.5592 - val_loss: 0.0107 - val_accuracy: 0.4825\n",
      "Epoch 45/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0106 - accuracy: 0.5487 - val_loss: 0.0107 - val_accuracy: 0.5600\n",
      "Epoch 46/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5410 - val_loss: 0.0107 - val_accuracy: 0.5680\n",
      "Epoch 47/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0106 - accuracy: 0.5545 - val_loss: 0.0107 - val_accuracy: 0.5695\n",
      "Epoch 48/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0106 - accuracy: 0.5480 - val_loss: 0.0108 - val_accuracy: 0.5455\n",
      "Epoch 49/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0106 - accuracy: 0.5482 - val_loss: 0.0107 - val_accuracy: 0.5605\n",
      "Epoch 50/1000\n",
      "188/188 [==============================] - 0s 569us/step - loss: 0.0106 - accuracy: 0.5500 - val_loss: 0.0107 - val_accuracy: 0.5680\n",
      "Epoch 51/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0106 - accuracy: 0.5548 - val_loss: 0.0107 - val_accuracy: 0.5665\n",
      "Epoch 52/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0106 - accuracy: 0.5505 - val_loss: 0.0107 - val_accuracy: 0.5710\n",
      "Epoch 53/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0106 - accuracy: 0.5470 - val_loss: 0.0108 - val_accuracy: 0.5735\n",
      "Epoch 54/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0106 - accuracy: 0.5465 - val_loss: 0.0108 - val_accuracy: 0.5725\n",
      "Epoch 55/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0106 - accuracy: 0.5620 - val_loss: 0.0108 - val_accuracy: 0.5695\n",
      "Epoch 56/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0106 - accuracy: 0.5433 - val_loss: 0.0108 - val_accuracy: 0.5695\n",
      "Epoch 57/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0106 - accuracy: 0.5495 - val_loss: 0.0107 - val_accuracy: 0.5660\n",
      "Epoch 58/1000\n",
      "188/188 [==============================] - 0s 564us/step - loss: 0.0106 - accuracy: 0.5547 - val_loss: 0.0107 - val_accuracy: 0.5655\n",
      "Epoch 59/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0106 - accuracy: 0.5568 - val_loss: 0.0107 - val_accuracy: 0.5715\n",
      "Epoch 60/1000\n",
      "188/188 [==============================] - 0s 564us/step - loss: 0.0106 - accuracy: 0.5567 - val_loss: 0.0108 - val_accuracy: 0.5610\n",
      "Epoch 61/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5548 - val_loss: 0.0107 - val_accuracy: 0.5660\n",
      "Epoch 62/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0106 - accuracy: 0.5542 - val_loss: 0.0107 - val_accuracy: 0.5610\n",
      "Epoch 63/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0106 - accuracy: 0.5575 - val_loss: 0.0108 - val_accuracy: 0.5360\n",
      "Epoch 64/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0106 - accuracy: 0.5475 - val_loss: 0.0107 - val_accuracy: 0.5695\n",
      "Epoch 65/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0106 - accuracy: 0.5482 - val_loss: 0.0107 - val_accuracy: 0.5715\n",
      "Epoch 66/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0106 - accuracy: 0.5583 - val_loss: 0.0108 - val_accuracy: 0.5570\n",
      "Epoch 67/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0106 - accuracy: 0.5508 - val_loss: 0.0108 - val_accuracy: 0.5105\n",
      "Epoch 68/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0106 - accuracy: 0.5505 - val_loss: 0.0107 - val_accuracy: 0.5695\n",
      "Epoch 69/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0106 - accuracy: 0.5555 - val_loss: 0.0107 - val_accuracy: 0.5740\n",
      "Epoch 70/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0106 - accuracy: 0.5540 - val_loss: 0.0107 - val_accuracy: 0.5595\n",
      "Epoch 71/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0106 - accuracy: 0.5567 - val_loss: 0.0107 - val_accuracy: 0.5745\n",
      "Epoch 72/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0106 - accuracy: 0.5605 - val_loss: 0.0108 - val_accuracy: 0.5700\n",
      "Epoch 73/1000\n",
      "188/188 [==============================] - 0s 575us/step - loss: 0.0106 - accuracy: 0.5560 - val_loss: 0.0108 - val_accuracy: 0.5755\n",
      "Epoch 74/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0106 - accuracy: 0.5548 - val_loss: 0.0107 - val_accuracy: 0.5650\n",
      "Epoch 75/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5562 - val_loss: 0.0108 - val_accuracy: 0.5585\n",
      "Epoch 76/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0106 - accuracy: 0.5573 - val_loss: 0.0107 - val_accuracy: 0.5615\n",
      "Epoch 77/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0106 - accuracy: 0.5533 - val_loss: 0.0107 - val_accuracy: 0.5360\n",
      "Epoch 78/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0106 - accuracy: 0.5510 - val_loss: 0.0107 - val_accuracy: 0.5700\n",
      "Epoch 79/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0106 - accuracy: 0.5583 - val_loss: 0.0107 - val_accuracy: 0.5670\n",
      "Epoch 80/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0106 - accuracy: 0.5598 - val_loss: 0.0107 - val_accuracy: 0.5655\n",
      "Epoch 81/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0106 - accuracy: 0.5580 - val_loss: 0.0108 - val_accuracy: 0.5655\n",
      "Epoch 82/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0106 - accuracy: 0.5488 - val_loss: 0.0107 - val_accuracy: 0.5735\n",
      "Epoch 83/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5508 - val_loss: 0.0107 - val_accuracy: 0.5725\n",
      "Epoch 84/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5532 - val_loss: 0.0108 - val_accuracy: 0.5635\n",
      "Epoch 85/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0106 - accuracy: 0.5490 - val_loss: 0.0107 - val_accuracy: 0.5805\n",
      "Epoch 86/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0106 - accuracy: 0.5497 - val_loss: 0.0107 - val_accuracy: 0.4725\n",
      "Epoch 87/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5355 - val_loss: 0.0107 - val_accuracy: 0.5620\n",
      "Epoch 88/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5428 - val_loss: 0.0106 - val_accuracy: 0.5630\n",
      "Epoch 89/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0106 - accuracy: 0.5370 - val_loss: 0.0108 - val_accuracy: 0.5675\n",
      "Epoch 90/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0106 - accuracy: 0.5557 - val_loss: 0.0105 - val_accuracy: 0.5290\n",
      "Epoch 91/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0105 - accuracy: 0.5543 - val_loss: 0.0102 - val_accuracy: 0.5880\n",
      "Epoch 92/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0104 - accuracy: 0.5587 - val_loss: 0.0103 - val_accuracy: 0.5870\n",
      "Epoch 93/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0103 - accuracy: 0.5665 - val_loss: 0.0098 - val_accuracy: 0.5820\n",
      "Epoch 94/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0100 - accuracy: 0.5635 - val_loss: 0.0097 - val_accuracy: 0.6140\n",
      "Epoch 95/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0099 - accuracy: 0.6000 - val_loss: 0.0104 - val_accuracy: 0.4900\n",
      "Epoch 96/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0093 - accuracy: 0.5790 - val_loss: 0.0067 - val_accuracy: 0.6675\n",
      "Epoch 97/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0104 - accuracy: 0.5710 - val_loss: 0.0088 - val_accuracy: 0.6445\n",
      "Epoch 98/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0068 - accuracy: 0.6785 - val_loss: 0.0066 - val_accuracy: 0.7095\n",
      "Epoch 99/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0063 - accuracy: 0.6768 - val_loss: 0.0056 - val_accuracy: 0.7415\n",
      "Epoch 100/1000\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0058 - accuracy: 0.7067 - val_loss: 0.0057 - val_accuracy: 0.7470\n",
      "Epoch 101/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0056 - accuracy: 0.7242 - val_loss: 0.0055 - val_accuracy: 0.7650\n",
      "Epoch 102/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0056 - accuracy: 0.7283 - val_loss: 0.0055 - val_accuracy: 0.7255\n",
      "Epoch 103/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0057 - accuracy: 0.7143 - val_loss: 0.0055 - val_accuracy: 0.7400\n",
      "Epoch 104/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0055 - accuracy: 0.7255 - val_loss: 0.0058 - val_accuracy: 0.7275\n",
      "Epoch 105/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0056 - accuracy: 0.7107 - val_loss: 0.0055 - val_accuracy: 0.7575\n",
      "Epoch 106/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0058 - accuracy: 0.7183 - val_loss: 0.0055 - val_accuracy: 0.7270\n",
      "Epoch 107/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0056 - accuracy: 0.7225 - val_loss: 0.0059 - val_accuracy: 0.6735\n",
      "Epoch 108/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0055 - accuracy: 0.7067 - val_loss: 0.0057 - val_accuracy: 0.7475\n",
      "Epoch 109/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7272 - val_loss: 0.0056 - val_accuracy: 0.7475\n",
      "Epoch 110/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0056 - accuracy: 0.7190 - val_loss: 0.0055 - val_accuracy: 0.7385\n",
      "Epoch 111/1000\n",
      "188/188 [==============================] - 0s 569us/step - loss: 0.0059 - accuracy: 0.7037 - val_loss: 0.0056 - val_accuracy: 0.7305\n",
      "Epoch 112/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0055 - accuracy: 0.7083 - val_loss: 0.0055 - val_accuracy: 0.7490\n",
      "Epoch 113/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0055 - accuracy: 0.7293 - val_loss: 0.0055 - val_accuracy: 0.7175\n",
      "Epoch 114/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0057 - accuracy: 0.7068 - val_loss: 0.0056 - val_accuracy: 0.6980\n",
      "Epoch 115/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0056 - accuracy: 0.7062 - val_loss: 0.0055 - val_accuracy: 0.7585\n",
      "Epoch 116/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0055 - accuracy: 0.7300 - val_loss: 0.0062 - val_accuracy: 0.7210\n",
      "Epoch 117/1000\n",
      "188/188 [==============================] - 0s 591us/step - loss: 0.0057 - accuracy: 0.7095 - val_loss: 0.0055 - val_accuracy: 0.7640\n",
      "Epoch 118/1000\n",
      "188/188 [==============================] - 0s 596us/step - loss: 0.0056 - accuracy: 0.7155 - val_loss: 0.0061 - val_accuracy: 0.6910\n",
      "Epoch 119/1000\n",
      "188/188 [==============================] - 0s 644us/step - loss: 0.0059 - accuracy: 0.6983 - val_loss: 0.0055 - val_accuracy: 0.7510\n",
      "Epoch 120/1000\n",
      "188/188 [==============================] - 0s 612us/step - loss: 0.0054 - accuracy: 0.7303 - val_loss: 0.0055 - val_accuracy: 0.7455\n",
      "Epoch 121/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0055 - accuracy: 0.7238 - val_loss: 0.0056 - val_accuracy: 0.7305\n",
      "Epoch 122/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0055 - accuracy: 0.7387 - val_loss: 0.0055 - val_accuracy: 0.7315\n",
      "Epoch 123/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0055 - accuracy: 0.7215 - val_loss: 0.0055 - val_accuracy: 0.7255\n",
      "Epoch 124/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0056 - accuracy: 0.7070 - val_loss: 0.0056 - val_accuracy: 0.7215\n",
      "Epoch 125/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0057 - accuracy: 0.7175 - val_loss: 0.0055 - val_accuracy: 0.7780\n",
      "Epoch 126/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0055 - accuracy: 0.7307 - val_loss: 0.0055 - val_accuracy: 0.7195\n",
      "Epoch 127/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0055 - accuracy: 0.7185 - val_loss: 0.0055 - val_accuracy: 0.7640\n",
      "Epoch 128/1000\n",
      "188/188 [==============================] - 0s 591us/step - loss: 0.0056 - accuracy: 0.7245 - val_loss: 0.0056 - val_accuracy: 0.7610\n",
      "Epoch 129/1000\n",
      "188/188 [==============================] - 0s 564us/step - loss: 0.0055 - accuracy: 0.7113 - val_loss: 0.0055 - val_accuracy: 0.7530\n",
      "Epoch 130/1000\n",
      "188/188 [==============================] - 0s 575us/step - loss: 0.0054 - accuracy: 0.7390 - val_loss: 0.0055 - val_accuracy: 0.7260\n",
      "Epoch 131/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0056 - accuracy: 0.7175 - val_loss: 0.0055 - val_accuracy: 0.7565\n",
      "Epoch 132/1000\n",
      "188/188 [==============================] - 0s 575us/step - loss: 0.0056 - accuracy: 0.7155 - val_loss: 0.0064 - val_accuracy: 0.6625\n",
      "Epoch 133/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0055 - accuracy: 0.7247 - val_loss: 0.0055 - val_accuracy: 0.7715\n",
      "Epoch 134/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0055 - accuracy: 0.7257 - val_loss: 0.0055 - val_accuracy: 0.7485\n",
      "Epoch 135/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0055 - accuracy: 0.7350 - val_loss: 0.0055 - val_accuracy: 0.7360\n",
      "Epoch 136/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0056 - accuracy: 0.7033 - val_loss: 0.0057 - val_accuracy: 0.7040\n",
      "Epoch 137/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0055 - accuracy: 0.7213 - val_loss: 0.0055 - val_accuracy: 0.7630\n",
      "Epoch 138/1000\n",
      "188/188 [==============================] - 0s 633us/step - loss: 0.0055 - accuracy: 0.7132 - val_loss: 0.0055 - val_accuracy: 0.7085\n",
      "Epoch 139/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0055 - accuracy: 0.7088 - val_loss: 0.0055 - val_accuracy: 0.7710\n",
      "Epoch 140/1000\n",
      "188/188 [==============================] - 0s 569us/step - loss: 0.0055 - accuracy: 0.7255 - val_loss: 0.0056 - val_accuracy: 0.7480\n",
      "Epoch 141/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0056 - accuracy: 0.7158 - val_loss: 0.0055 - val_accuracy: 0.7485\n",
      "Epoch 142/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0055 - accuracy: 0.7305 - val_loss: 0.0057 - val_accuracy: 0.6970\n",
      "Epoch 143/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7317 - val_loss: 0.0057 - val_accuracy: 0.7120\n",
      "Epoch 144/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0057 - accuracy: 0.7088 - val_loss: 0.0055 - val_accuracy: 0.7705\n",
      "Epoch 145/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7363 - val_loss: 0.0055 - val_accuracy: 0.7395\n",
      "Epoch 146/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0055 - accuracy: 0.7267 - val_loss: 0.0055 - val_accuracy: 0.7280\n",
      "Epoch 147/1000\n",
      "188/188 [==============================] - 0s 628us/step - loss: 0.0055 - accuracy: 0.7312 - val_loss: 0.0055 - val_accuracy: 0.7420\n",
      "Epoch 148/1000\n",
      "188/188 [==============================] - 0s 569us/step - loss: 0.0056 - accuracy: 0.7218 - val_loss: 0.0059 - val_accuracy: 0.7195\n",
      "Epoch 149/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0055 - accuracy: 0.7223 - val_loss: 0.0056 - val_accuracy: 0.7245\n",
      "Epoch 150/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0055 - accuracy: 0.7147 - val_loss: 0.0055 - val_accuracy: 0.7605\n",
      "Epoch 151/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0055 - accuracy: 0.7345 - val_loss: 0.0055 - val_accuracy: 0.7290\n",
      "Epoch 152/1000\n",
      "188/188 [==============================] - 0s 585us/step - loss: 0.0055 - accuracy: 0.7167 - val_loss: 0.0058 - val_accuracy: 0.7430\n",
      "Epoch 153/1000\n",
      "188/188 [==============================] - 0s 564us/step - loss: 0.0055 - accuracy: 0.7253 - val_loss: 0.0055 - val_accuracy: 0.7685\n",
      "Epoch 154/1000\n",
      "188/188 [==============================] - 0s 575us/step - loss: 0.0054 - accuracy: 0.7422 - val_loss: 0.0055 - val_accuracy: 0.7395\n",
      "Epoch 155/1000\n",
      "188/188 [==============================] - 0s 575us/step - loss: 0.0055 - accuracy: 0.7232 - val_loss: 0.0055 - val_accuracy: 0.7105\n",
      "Epoch 156/1000\n",
      "188/188 [==============================] - 0s 575us/step - loss: 0.0055 - accuracy: 0.7087 - val_loss: 0.0056 - val_accuracy: 0.7465\n",
      "Epoch 157/1000\n",
      "188/188 [==============================] - 0s 585us/step - loss: 0.0056 - accuracy: 0.7227 - val_loss: 0.0057 - val_accuracy: 0.7280\n",
      "Epoch 158/1000\n",
      "188/188 [==============================] - 0s 585us/step - loss: 0.0055 - accuracy: 0.7317 - val_loss: 0.0055 - val_accuracy: 0.7275\n",
      "Epoch 159/1000\n",
      "188/188 [==============================] - 0s 569us/step - loss: 0.0055 - accuracy: 0.7283 - val_loss: 0.0055 - val_accuracy: 0.7215\n",
      "Epoch 160/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0054 - accuracy: 0.7185 - val_loss: 0.0055 - val_accuracy: 0.7645\n",
      "Epoch 161/1000\n",
      "188/188 [==============================] - 0s 569us/step - loss: 0.0055 - accuracy: 0.7237 - val_loss: 0.0057 - val_accuracy: 0.7555\n",
      "Epoch 162/1000\n",
      "188/188 [==============================] - 0s 569us/step - loss: 0.0055 - accuracy: 0.7370 - val_loss: 0.0055 - val_accuracy: 0.7245\n",
      "Epoch 163/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0055 - accuracy: 0.7222 - val_loss: 0.0055 - val_accuracy: 0.7620\n",
      "Epoch 164/1000\n",
      "188/188 [==============================] - 0s 569us/step - loss: 0.0055 - accuracy: 0.7188 - val_loss: 0.0055 - val_accuracy: 0.7375\n",
      "Epoch 165/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0056 - accuracy: 0.7160 - val_loss: 0.0055 - val_accuracy: 0.7380\n",
      "Epoch 166/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7233 - val_loss: 0.0055 - val_accuracy: 0.7715\n",
      "Epoch 167/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0055 - accuracy: 0.7302 - val_loss: 0.0055 - val_accuracy: 0.7495\n",
      "Epoch 168/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0055 - accuracy: 0.7245 - val_loss: 0.0055 - val_accuracy: 0.7465\n",
      "Epoch 169/1000\n",
      "188/188 [==============================] - 0s 622us/step - loss: 0.0054 - accuracy: 0.7407 - val_loss: 0.0057 - val_accuracy: 0.6980\n",
      "Epoch 170/1000\n",
      "188/188 [==============================] - 0s 575us/step - loss: 0.0055 - accuracy: 0.7110 - val_loss: 0.0055 - val_accuracy: 0.7495\n",
      "Epoch 171/1000\n",
      "188/188 [==============================] - 0s 575us/step - loss: 0.0054 - accuracy: 0.7317 - val_loss: 0.0056 - val_accuracy: 0.7050\n",
      "Epoch 172/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0055 - accuracy: 0.7265 - val_loss: 0.0055 - val_accuracy: 0.7525\n",
      "Epoch 173/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0055 - accuracy: 0.7252 - val_loss: 0.0055 - val_accuracy: 0.7635\n",
      "Epoch 174/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7263 - val_loss: 0.0057 - val_accuracy: 0.7315\n",
      "Epoch 175/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0055 - accuracy: 0.7243 - val_loss: 0.0056 - val_accuracy: 0.7520\n",
      "Epoch 176/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0055 - accuracy: 0.7295 - val_loss: 0.0055 - val_accuracy: 0.7525\n",
      "Epoch 177/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7343 - val_loss: 0.0055 - val_accuracy: 0.7580\n",
      "Epoch 178/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0055 - accuracy: 0.7278 - val_loss: 0.0055 - val_accuracy: 0.7550\n",
      "Epoch 179/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7295 - val_loss: 0.0055 - val_accuracy: 0.7320\n",
      "Epoch 180/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0056 - accuracy: 0.7017 - val_loss: 0.0058 - val_accuracy: 0.7350\n",
      "Epoch 181/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0055 - accuracy: 0.7375 - val_loss: 0.0055 - val_accuracy: 0.7140\n",
      "Epoch 182/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7085 - val_loss: 0.0055 - val_accuracy: 0.7515\n",
      "Epoch 183/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7255 - val_loss: 0.0055 - val_accuracy: 0.7730\n",
      "Epoch 184/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7292 - val_loss: 0.0055 - val_accuracy: 0.7615\n",
      "Epoch 185/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7345 - val_loss: 0.0055 - val_accuracy: 0.7440\n",
      "Epoch 186/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7265 - val_loss: 0.0055 - val_accuracy: 0.7175\n",
      "Epoch 187/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7173 - val_loss: 0.0057 - val_accuracy: 0.7260\n",
      "Epoch 188/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0055 - accuracy: 0.7278 - val_loss: 0.0056 - val_accuracy: 0.7175\n",
      "Epoch 189/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0055 - accuracy: 0.7133 - val_loss: 0.0055 - val_accuracy: 0.7690\n",
      "Epoch 190/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7328 - val_loss: 0.0055 - val_accuracy: 0.7520\n",
      "Epoch 191/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0055 - accuracy: 0.7260 - val_loss: 0.0055 - val_accuracy: 0.7445\n",
      "Epoch 192/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0055 - accuracy: 0.7132 - val_loss: 0.0055 - val_accuracy: 0.7720\n",
      "Epoch 193/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0055 - accuracy: 0.7242 - val_loss: 0.0055 - val_accuracy: 0.7365\n",
      "Epoch 194/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7352 - val_loss: 0.0055 - val_accuracy: 0.7565\n",
      "Epoch 195/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7210 - val_loss: 0.0055 - val_accuracy: 0.7485\n",
      "Epoch 196/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0055 - accuracy: 0.7180 - val_loss: 0.0055 - val_accuracy: 0.7650\n",
      "Epoch 197/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7377 - val_loss: 0.0055 - val_accuracy: 0.7505\n",
      "Epoch 198/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0055 - accuracy: 0.7262 - val_loss: 0.0055 - val_accuracy: 0.7750\n",
      "Epoch 199/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7263 - val_loss: 0.0055 - val_accuracy: 0.7755\n",
      "Epoch 200/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7333 - val_loss: 0.0056 - val_accuracy: 0.7090\n",
      "Epoch 201/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7207 - val_loss: 0.0055 - val_accuracy: 0.7630\n",
      "Epoch 202/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7227 - val_loss: 0.0055 - val_accuracy: 0.7345\n",
      "Epoch 203/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7255 - val_loss: 0.0055 - val_accuracy: 0.7390\n",
      "Epoch 204/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7262 - val_loss: 0.0055 - val_accuracy: 0.7515\n",
      "Epoch 205/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7248 - val_loss: 0.0055 - val_accuracy: 0.7365\n",
      "Epoch 206/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7310 - val_loss: 0.0055 - val_accuracy: 0.7655\n",
      "Epoch 207/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7232 - val_loss: 0.0055 - val_accuracy: 0.7735\n",
      "Epoch 208/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7292 - val_loss: 0.0055 - val_accuracy: 0.7725\n",
      "Epoch 209/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0055 - accuracy: 0.7137 - val_loss: 0.0055 - val_accuracy: 0.7575\n",
      "Epoch 210/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7372 - val_loss: 0.0055 - val_accuracy: 0.7170\n",
      "Epoch 211/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7125 - val_loss: 0.0055 - val_accuracy: 0.7670\n",
      "Epoch 212/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7368 - val_loss: 0.0055 - val_accuracy: 0.7305\n",
      "Epoch 213/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7318 - val_loss: 0.0056 - val_accuracy: 0.7415\n",
      "Epoch 214/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7088 - val_loss: 0.0055 - val_accuracy: 0.7590\n",
      "Epoch 215/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7418 - val_loss: 0.0055 - val_accuracy: 0.7305\n",
      "Epoch 216/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0055 - accuracy: 0.7160 - val_loss: 0.0055 - val_accuracy: 0.7590\n",
      "Epoch 217/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7323 - val_loss: 0.0055 - val_accuracy: 0.7155\n",
      "Epoch 218/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7257 - val_loss: 0.0055 - val_accuracy: 0.7400\n",
      "Epoch 219/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7250 - val_loss: 0.0055 - val_accuracy: 0.7605\n",
      "Epoch 220/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7387 - val_loss: 0.0055 - val_accuracy: 0.7150\n",
      "Epoch 221/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0055 - accuracy: 0.7228 - val_loss: 0.0055 - val_accuracy: 0.7025\n",
      "Epoch 222/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7258 - val_loss: 0.0055 - val_accuracy: 0.7355\n",
      "Epoch 223/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7405 - val_loss: 0.0055 - val_accuracy: 0.7335\n",
      "Epoch 224/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0055 - accuracy: 0.7135 - val_loss: 0.0055 - val_accuracy: 0.7360\n",
      "Epoch 225/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7193 - val_loss: 0.0055 - val_accuracy: 0.7690\n",
      "Epoch 226/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7328 - val_loss: 0.0055 - val_accuracy: 0.7555\n",
      "Epoch 227/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7353 - val_loss: 0.0055 - val_accuracy: 0.7705\n",
      "Epoch 228/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0055 - accuracy: 0.7368 - val_loss: 0.0056 - val_accuracy: 0.7380\n",
      "Epoch 229/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7287 - val_loss: 0.0055 - val_accuracy: 0.7740\n",
      "Epoch 230/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7237 - val_loss: 0.0055 - val_accuracy: 0.7510\n",
      "Epoch 231/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0055 - accuracy: 0.7305 - val_loss: 0.0055 - val_accuracy: 0.7235\n",
      "Epoch 232/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7232 - val_loss: 0.0055 - val_accuracy: 0.7565\n",
      "Epoch 233/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7343 - val_loss: 0.0055 - val_accuracy: 0.7620\n",
      "Epoch 234/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7227 - val_loss: 0.0056 - val_accuracy: 0.7545\n",
      "Epoch 235/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7347 - val_loss: 0.0055 - val_accuracy: 0.7540\n",
      "Epoch 236/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7410 - val_loss: 0.0055 - val_accuracy: 0.6940\n",
      "Epoch 237/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7202 - val_loss: 0.0055 - val_accuracy: 0.7680\n",
      "Epoch 238/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0055 - accuracy: 0.7313 - val_loss: 0.0055 - val_accuracy: 0.7405\n",
      "Epoch 239/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7327 - val_loss: 0.0055 - val_accuracy: 0.7220\n",
      "Epoch 240/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7203 - val_loss: 0.0055 - val_accuracy: 0.7545\n",
      "Epoch 241/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0055 - accuracy: 0.7197 - val_loss: 0.0055 - val_accuracy: 0.7485\n",
      "Epoch 242/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7372 - val_loss: 0.0055 - val_accuracy: 0.7515\n",
      "Epoch 243/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0055 - accuracy: 0.7212 - val_loss: 0.0055 - val_accuracy: 0.7505\n",
      "Epoch 244/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7298 - val_loss: 0.0055 - val_accuracy: 0.7675\n",
      "Epoch 245/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7333 - val_loss: 0.0055 - val_accuracy: 0.7555\n",
      "Epoch 246/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7407 - val_loss: 0.0055 - val_accuracy: 0.7100\n",
      "Epoch 247/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7282 - val_loss: 0.0058 - val_accuracy: 0.7010\n",
      "Epoch 248/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7190 - val_loss: 0.0056 - val_accuracy: 0.7500\n",
      "Epoch 249/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7397 - val_loss: 0.0055 - val_accuracy: 0.7490\n",
      "Epoch 250/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7232 - val_loss: 0.0055 - val_accuracy: 0.7415\n",
      "Epoch 251/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0055 - accuracy: 0.7235 - val_loss: 0.0055 - val_accuracy: 0.7695\n",
      "Epoch 252/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7302 - val_loss: 0.0055 - val_accuracy: 0.7655\n",
      "Epoch 253/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7308 - val_loss: 0.0055 - val_accuracy: 0.7545\n",
      "Epoch 254/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7320 - val_loss: 0.0055 - val_accuracy: 0.7515\n",
      "Epoch 255/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7378 - val_loss: 0.0055 - val_accuracy: 0.7560\n",
      "Epoch 256/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7297 - val_loss: 0.0055 - val_accuracy: 0.7570\n",
      "Epoch 257/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7138 - val_loss: 0.0055 - val_accuracy: 0.7710\n",
      "Epoch 258/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7377 - val_loss: 0.0055 - val_accuracy: 0.7470\n",
      "Epoch 259/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7340 - val_loss: 0.0055 - val_accuracy: 0.7510\n",
      "Epoch 260/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7417 - val_loss: 0.0056 - val_accuracy: 0.6885\n",
      "Epoch 261/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0055 - accuracy: 0.7193 - val_loss: 0.0056 - val_accuracy: 0.7425\n",
      "Epoch 262/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7248 - val_loss: 0.0057 - val_accuracy: 0.7375\n",
      "Epoch 263/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7415 - val_loss: 0.0055 - val_accuracy: 0.7585\n",
      "Epoch 264/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7340 - val_loss: 0.0056 - val_accuracy: 0.7445\n",
      "Epoch 265/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7308 - val_loss: 0.0055 - val_accuracy: 0.7745\n",
      "Epoch 266/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7472 - val_loss: 0.0056 - val_accuracy: 0.7035\n",
      "Epoch 267/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7235 - val_loss: 0.0055 - val_accuracy: 0.7575\n",
      "Epoch 268/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7278 - val_loss: 0.0055 - val_accuracy: 0.7585\n",
      "Epoch 269/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7282 - val_loss: 0.0056 - val_accuracy: 0.7450\n",
      "Epoch 270/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7315 - val_loss: 0.0055 - val_accuracy: 0.7205\n",
      "Epoch 271/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7263 - val_loss: 0.0054 - val_accuracy: 0.7750\n",
      "Epoch 272/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7410 - val_loss: 0.0055 - val_accuracy: 0.7035\n",
      "Epoch 273/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7248 - val_loss: 0.0055 - val_accuracy: 0.7585\n",
      "Epoch 274/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0055 - accuracy: 0.7257 - val_loss: 0.0056 - val_accuracy: 0.7220\n",
      "Epoch 275/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7478 - val_loss: 0.0055 - val_accuracy: 0.7290\n",
      "Epoch 276/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7262 - val_loss: 0.0055 - val_accuracy: 0.7235\n",
      "Epoch 277/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7225 - val_loss: 0.0055 - val_accuracy: 0.7695\n",
      "Epoch 278/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7467 - val_loss: 0.0055 - val_accuracy: 0.7050\n",
      "Epoch 279/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7185 - val_loss: 0.0056 - val_accuracy: 0.7045\n",
      "Epoch 280/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0055 - accuracy: 0.7232 - val_loss: 0.0055 - val_accuracy: 0.7570\n",
      "Epoch 281/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7372 - val_loss: 0.0055 - val_accuracy: 0.7060\n",
      "Epoch 282/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7193 - val_loss: 0.0055 - val_accuracy: 0.7685\n",
      "Epoch 283/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7407 - val_loss: 0.0055 - val_accuracy: 0.7300\n",
      "Epoch 284/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7333 - val_loss: 0.0055 - val_accuracy: 0.7340\n",
      "Epoch 285/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7237 - val_loss: 0.0055 - val_accuracy: 0.7350\n",
      "Epoch 286/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0055 - accuracy: 0.7273 - val_loss: 0.0055 - val_accuracy: 0.7345\n",
      "Epoch 287/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7278 - val_loss: 0.0055 - val_accuracy: 0.7745\n",
      "Epoch 288/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7337 - val_loss: 0.0055 - val_accuracy: 0.7635\n",
      "Epoch 289/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7357 - val_loss: 0.0057 - val_accuracy: 0.7320\n",
      "Epoch 290/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7250 - val_loss: 0.0055 - val_accuracy: 0.7660\n",
      "Epoch 291/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7365 - val_loss: 0.0055 - val_accuracy: 0.7440\n",
      "Epoch 292/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7265 - val_loss: 0.0055 - val_accuracy: 0.7640\n",
      "Epoch 293/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7495 - val_loss: 0.0055 - val_accuracy: 0.7145\n",
      "Epoch 294/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7193 - val_loss: 0.0055 - val_accuracy: 0.7545\n",
      "Epoch 295/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7327 - val_loss: 0.0055 - val_accuracy: 0.7645\n",
      "Epoch 296/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7282 - val_loss: 0.0055 - val_accuracy: 0.7700\n",
      "Epoch 297/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7350 - val_loss: 0.0055 - val_accuracy: 0.7425\n",
      "Epoch 298/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7258 - val_loss: 0.0056 - val_accuracy: 0.7370\n",
      "Epoch 299/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0055 - accuracy: 0.7252 - val_loss: 0.0055 - val_accuracy: 0.7315\n",
      "Epoch 300/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7277 - val_loss: 0.0055 - val_accuracy: 0.7150\n",
      "Epoch 301/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7238 - val_loss: 0.0056 - val_accuracy: 0.7390\n",
      "Epoch 302/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7337 - val_loss: 0.0055 - val_accuracy: 0.7450\n",
      "Epoch 303/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7375 - val_loss: 0.0055 - val_accuracy: 0.7220\n",
      "Epoch 304/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7165 - val_loss: 0.0055 - val_accuracy: 0.7655\n",
      "Epoch 305/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7272 - val_loss: 0.0055 - val_accuracy: 0.7605\n",
      "Epoch 306/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7467 - val_loss: 0.0055 - val_accuracy: 0.7605\n",
      "Epoch 307/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7210 - val_loss: 0.0055 - val_accuracy: 0.7690\n",
      "Epoch 308/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7257 - val_loss: 0.0055 - val_accuracy: 0.7730\n",
      "Epoch 309/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7332 - val_loss: 0.0055 - val_accuracy: 0.7435\n",
      "Epoch 310/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7182 - val_loss: 0.0055 - val_accuracy: 0.7450\n",
      "Epoch 311/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7382 - val_loss: 0.0056 - val_accuracy: 0.7470\n",
      "Epoch 312/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7288 - val_loss: 0.0055 - val_accuracy: 0.7705\n",
      "Epoch 313/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0055 - accuracy: 0.7287 - val_loss: 0.0054 - val_accuracy: 0.7740\n",
      "Epoch 314/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7260 - val_loss: 0.0055 - val_accuracy: 0.7745\n",
      "Epoch 315/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7255 - val_loss: 0.0055 - val_accuracy: 0.7700\n",
      "Epoch 316/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7382 - val_loss: 0.0055 - val_accuracy: 0.7100\n",
      "Epoch 317/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7470 - val_loss: 0.0055 - val_accuracy: 0.7315\n",
      "Epoch 318/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7338 - val_loss: 0.0055 - val_accuracy: 0.7310\n",
      "Epoch 319/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7272 - val_loss: 0.0055 - val_accuracy: 0.7230\n",
      "Epoch 320/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7282 - val_loss: 0.0055 - val_accuracy: 0.7650\n",
      "Epoch 321/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7398 - val_loss: 0.0056 - val_accuracy: 0.7440\n",
      "Epoch 322/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7233 - val_loss: 0.0055 - val_accuracy: 0.7475\n",
      "Epoch 323/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0055 - accuracy: 0.7323 - val_loss: 0.0055 - val_accuracy: 0.7160\n",
      "Epoch 324/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7268 - val_loss: 0.0055 - val_accuracy: 0.7710\n",
      "Epoch 325/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7325 - val_loss: 0.0055 - val_accuracy: 0.7585\n",
      "Epoch 326/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7222 - val_loss: 0.0055 - val_accuracy: 0.7545\n",
      "Epoch 327/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7232 - val_loss: 0.0055 - val_accuracy: 0.7770\n",
      "Epoch 328/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7388 - val_loss: 0.0055 - val_accuracy: 0.7510\n",
      "Epoch 329/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7210 - val_loss: 0.0055 - val_accuracy: 0.7455\n",
      "Epoch 330/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7303 - val_loss: 0.0055 - val_accuracy: 0.7580\n",
      "Epoch 331/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7305 - val_loss: 0.0055 - val_accuracy: 0.7235\n",
      "Epoch 332/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7267 - val_loss: 0.0055 - val_accuracy: 0.7600\n",
      "Epoch 333/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7327 - val_loss: 0.0055 - val_accuracy: 0.7505\n",
      "Epoch 334/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7258 - val_loss: 0.0055 - val_accuracy: 0.7425\n",
      "Epoch 335/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7223 - val_loss: 0.0055 - val_accuracy: 0.7705\n",
      "Epoch 336/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7270 - val_loss: 0.0055 - val_accuracy: 0.7595\n",
      "Epoch 337/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7313 - val_loss: 0.0055 - val_accuracy: 0.7690\n",
      "Epoch 338/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7337 - val_loss: 0.0055 - val_accuracy: 0.7440\n",
      "Epoch 339/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0055 - accuracy: 0.7318 - val_loss: 0.0055 - val_accuracy: 0.7650\n",
      "Epoch 340/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7378 - val_loss: 0.0055 - val_accuracy: 0.7170\n",
      "Epoch 341/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7183 - val_loss: 0.0055 - val_accuracy: 0.7660\n",
      "Epoch 342/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7360 - val_loss: 0.0055 - val_accuracy: 0.7235\n",
      "Epoch 343/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7312 - val_loss: 0.0055 - val_accuracy: 0.7335\n",
      "Epoch 344/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7303 - val_loss: 0.0058 - val_accuracy: 0.6775\n",
      "Epoch 345/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7360 - val_loss: 0.0055 - val_accuracy: 0.7105\n",
      "Epoch 346/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7300 - val_loss: 0.0055 - val_accuracy: 0.7260\n",
      "Epoch 347/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7240 - val_loss: 0.0055 - val_accuracy: 0.7365\n",
      "Epoch 348/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7232 - val_loss: 0.0055 - val_accuracy: 0.7615\n",
      "Epoch 349/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7370 - val_loss: 0.0056 - val_accuracy: 0.7495\n",
      "Epoch 350/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7303 - val_loss: 0.0055 - val_accuracy: 0.7430\n",
      "Epoch 351/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7215 - val_loss: 0.0055 - val_accuracy: 0.7780\n",
      "Epoch 352/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7433 - val_loss: 0.0055 - val_accuracy: 0.7115\n",
      "Epoch 353/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7292 - val_loss: 0.0055 - val_accuracy: 0.7370\n",
      "Epoch 354/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7158 - val_loss: 0.0055 - val_accuracy: 0.7650\n",
      "Epoch 355/1000\n",
      "188/188 [==============================] - 0s 564us/step - loss: 0.0054 - accuracy: 0.7378 - val_loss: 0.0055 - val_accuracy: 0.7550\n",
      "Epoch 356/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7410 - val_loss: 0.0055 - val_accuracy: 0.7495\n",
      "Epoch 357/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7305 - val_loss: 0.0055 - val_accuracy: 0.7475\n",
      "Epoch 358/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7245 - val_loss: 0.0055 - val_accuracy: 0.7645\n",
      "Epoch 359/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7350 - val_loss: 0.0056 - val_accuracy: 0.7255\n",
      "Epoch 360/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7303 - val_loss: 0.0055 - val_accuracy: 0.7445\n",
      "Epoch 361/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7325 - val_loss: 0.0055 - val_accuracy: 0.7375\n",
      "Epoch 362/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7235 - val_loss: 0.0055 - val_accuracy: 0.7570\n",
      "Epoch 363/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7497 - val_loss: 0.0055 - val_accuracy: 0.7270\n",
      "Epoch 364/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7278 - val_loss: 0.0056 - val_accuracy: 0.6950\n",
      "Epoch 365/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0055 - accuracy: 0.7235 - val_loss: 0.0055 - val_accuracy: 0.7375\n",
      "Epoch 366/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7332 - val_loss: 0.0055 - val_accuracy: 0.7515\n",
      "Epoch 367/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7353 - val_loss: 0.0055 - val_accuracy: 0.7310\n",
      "Epoch 368/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7320 - val_loss: 0.0055 - val_accuracy: 0.7600\n",
      "Epoch 369/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7363 - val_loss: 0.0056 - val_accuracy: 0.7015\n",
      "Epoch 370/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7258 - val_loss: 0.0055 - val_accuracy: 0.7450\n",
      "Epoch 371/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7343 - val_loss: 0.0055 - val_accuracy: 0.7340\n",
      "Epoch 372/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7262 - val_loss: 0.0055 - val_accuracy: 0.7320\n",
      "Epoch 373/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7375 - val_loss: 0.0055 - val_accuracy: 0.7245\n",
      "Epoch 374/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7288 - val_loss: 0.0055 - val_accuracy: 0.7655\n",
      "Epoch 375/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7328 - val_loss: 0.0055 - val_accuracy: 0.7570\n",
      "Epoch 376/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7388 - val_loss: 0.0055 - val_accuracy: 0.7445\n",
      "Epoch 377/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7158 - val_loss: 0.0056 - val_accuracy: 0.7520\n",
      "Epoch 378/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7375 - val_loss: 0.0055 - val_accuracy: 0.7450\n",
      "Epoch 379/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7333 - val_loss: 0.0055 - val_accuracy: 0.7240\n",
      "Epoch 380/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7265 - val_loss: 0.0056 - val_accuracy: 0.7255\n",
      "Epoch 381/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0054 - accuracy: 0.7338 - val_loss: 0.0055 - val_accuracy: 0.7590\n",
      "Epoch 382/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7448 - val_loss: 0.0055 - val_accuracy: 0.7045\n",
      "Epoch 383/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7205 - val_loss: 0.0055 - val_accuracy: 0.7620\n",
      "Epoch 384/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7462 - val_loss: 0.0055 - val_accuracy: 0.7055\n",
      "Epoch 385/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7220 - val_loss: 0.0055 - val_accuracy: 0.7580\n",
      "Epoch 386/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7245 - val_loss: 0.0055 - val_accuracy: 0.7695\n",
      "Epoch 387/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7365 - val_loss: 0.0055 - val_accuracy: 0.7290\n",
      "Epoch 388/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7293 - val_loss: 0.0055 - val_accuracy: 0.7375\n",
      "Epoch 389/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7310 - val_loss: 0.0055 - val_accuracy: 0.7135\n",
      "Epoch 390/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7250 - val_loss: 0.0055 - val_accuracy: 0.7300\n",
      "Epoch 391/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7303 - val_loss: 0.0055 - val_accuracy: 0.7765\n",
      "Epoch 392/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7295 - val_loss: 0.0055 - val_accuracy: 0.7535\n",
      "Epoch 393/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7378 - val_loss: 0.0055 - val_accuracy: 0.7320\n",
      "Epoch 394/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7288 - val_loss: 0.0055 - val_accuracy: 0.7750\n",
      "Epoch 395/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7330 - val_loss: 0.0055 - val_accuracy: 0.7755\n",
      "Epoch 396/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7392 - val_loss: 0.0055 - val_accuracy: 0.7635\n",
      "Epoch 397/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7333 - val_loss: 0.0055 - val_accuracy: 0.7605\n",
      "Epoch 398/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7290 - val_loss: 0.0055 - val_accuracy: 0.7695\n",
      "Epoch 399/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7452 - val_loss: 0.0055 - val_accuracy: 0.7420\n",
      "Epoch 400/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7243 - val_loss: 0.0055 - val_accuracy: 0.7650\n",
      "Epoch 401/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7305 - val_loss: 0.0055 - val_accuracy: 0.7595\n",
      "Epoch 402/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7387 - val_loss: 0.0055 - val_accuracy: 0.7440\n",
      "Epoch 403/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7305 - val_loss: 0.0055 - val_accuracy: 0.7230\n",
      "Epoch 404/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7377 - val_loss: 0.0055 - val_accuracy: 0.7545\n",
      "Epoch 405/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7288 - val_loss: 0.0055 - val_accuracy: 0.7385\n",
      "Epoch 406/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7298 - val_loss: 0.0055 - val_accuracy: 0.7545\n",
      "Epoch 407/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7418 - val_loss: 0.0055 - val_accuracy: 0.7150\n",
      "Epoch 408/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7317 - val_loss: 0.0055 - val_accuracy: 0.7725\n",
      "Epoch 409/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7372 - val_loss: 0.0056 - val_accuracy: 0.7150\n",
      "Epoch 410/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7185 - val_loss: 0.0055 - val_accuracy: 0.7690\n",
      "Epoch 411/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7303 - val_loss: 0.0055 - val_accuracy: 0.7505\n",
      "Epoch 412/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7308 - val_loss: 0.0055 - val_accuracy: 0.7680\n",
      "Epoch 413/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7298 - val_loss: 0.0055 - val_accuracy: 0.7725\n",
      "Epoch 414/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7455 - val_loss: 0.0055 - val_accuracy: 0.7175\n",
      "Epoch 415/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7202 - val_loss: 0.0055 - val_accuracy: 0.7730\n",
      "Epoch 416/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7515 - val_loss: 0.0055 - val_accuracy: 0.7205\n",
      "Epoch 417/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7283 - val_loss: 0.0055 - val_accuracy: 0.7390\n",
      "Epoch 418/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7205 - val_loss: 0.0055 - val_accuracy: 0.7730\n",
      "Epoch 419/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7355 - val_loss: 0.0056 - val_accuracy: 0.7470\n",
      "Epoch 420/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7392 - val_loss: 0.0055 - val_accuracy: 0.7345\n",
      "Epoch 421/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7172 - val_loss: 0.0055 - val_accuracy: 0.7740\n",
      "Epoch 422/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7353 - val_loss: 0.0055 - val_accuracy: 0.7390\n",
      "Epoch 423/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7168 - val_loss: 0.0055 - val_accuracy: 0.7630\n",
      "Epoch 424/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7390 - val_loss: 0.0055 - val_accuracy: 0.7380\n",
      "Epoch 425/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7288 - val_loss: 0.0055 - val_accuracy: 0.7745\n",
      "Epoch 426/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7238 - val_loss: 0.0055 - val_accuracy: 0.7745\n",
      "Epoch 427/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7485 - val_loss: 0.0055 - val_accuracy: 0.7550\n",
      "Epoch 428/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7263 - val_loss: 0.0055 - val_accuracy: 0.7710\n",
      "Epoch 429/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7477 - val_loss: 0.0055 - val_accuracy: 0.7125\n",
      "Epoch 430/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7212 - val_loss: 0.0055 - val_accuracy: 0.7580\n",
      "Epoch 431/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7372 - val_loss: 0.0055 - val_accuracy: 0.7005\n",
      "Epoch 432/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7187 - val_loss: 0.0055 - val_accuracy: 0.7630\n",
      "Epoch 433/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7388 - val_loss: 0.0055 - val_accuracy: 0.7250\n",
      "Epoch 434/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7270 - val_loss: 0.0055 - val_accuracy: 0.7210\n",
      "Epoch 435/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7302 - val_loss: 0.0055 - val_accuracy: 0.7550\n",
      "Epoch 436/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7400 - val_loss: 0.0055 - val_accuracy: 0.7205\n",
      "Epoch 437/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7352 - val_loss: 0.0055 - val_accuracy: 0.7695\n",
      "Epoch 438/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7375 - val_loss: 0.0055 - val_accuracy: 0.7385\n",
      "Epoch 439/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7277 - val_loss: 0.0055 - val_accuracy: 0.7755\n",
      "Epoch 440/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7443 - val_loss: 0.0055 - val_accuracy: 0.7430\n",
      "Epoch 441/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7317 - val_loss: 0.0055 - val_accuracy: 0.7305\n",
      "Epoch 442/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7208 - val_loss: 0.0055 - val_accuracy: 0.7660\n",
      "Epoch 443/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7372 - val_loss: 0.0056 - val_accuracy: 0.7480\n",
      "Epoch 444/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7312 - val_loss: 0.0056 - val_accuracy: 0.7445\n",
      "Epoch 445/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7318 - val_loss: 0.0055 - val_accuracy: 0.7505\n",
      "Epoch 446/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7355 - val_loss: 0.0056 - val_accuracy: 0.7170\n",
      "Epoch 447/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7432 - val_loss: 0.0055 - val_accuracy: 0.7195\n",
      "Epoch 448/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7250 - val_loss: 0.0055 - val_accuracy: 0.7720\n",
      "Epoch 449/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7332 - val_loss: 0.0055 - val_accuracy: 0.7750\n",
      "Epoch 450/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7410 - val_loss: 0.0055 - val_accuracy: 0.7300\n",
      "Epoch 451/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7360 - val_loss: 0.0055 - val_accuracy: 0.7545\n",
      "Epoch 452/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7333 - val_loss: 0.0055 - val_accuracy: 0.7540\n",
      "Epoch 453/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7312 - val_loss: 0.0055 - val_accuracy: 0.7610\n",
      "Epoch 454/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7423 - val_loss: 0.0055 - val_accuracy: 0.7425\n",
      "Epoch 455/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7248 - val_loss: 0.0055 - val_accuracy: 0.7555\n",
      "Epoch 456/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7393 - val_loss: 0.0055 - val_accuracy: 0.7590\n",
      "Epoch 457/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7422 - val_loss: 0.0056 - val_accuracy: 0.7115\n",
      "Epoch 458/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7325 - val_loss: 0.0055 - val_accuracy: 0.7555\n",
      "Epoch 459/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7310 - val_loss: 0.0055 - val_accuracy: 0.7575\n",
      "Epoch 460/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7295 - val_loss: 0.0055 - val_accuracy: 0.7400\n",
      "Epoch 461/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7297 - val_loss: 0.0055 - val_accuracy: 0.7635\n",
      "Epoch 462/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7475 - val_loss: 0.0055 - val_accuracy: 0.7300\n",
      "Epoch 463/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7212 - val_loss: 0.0055 - val_accuracy: 0.7675\n",
      "Epoch 464/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7342 - val_loss: 0.0055 - val_accuracy: 0.7475\n",
      "Epoch 465/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7373 - val_loss: 0.0055 - val_accuracy: 0.7240\n",
      "Epoch 466/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7233 - val_loss: 0.0055 - val_accuracy: 0.7580\n",
      "Epoch 467/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7323 - val_loss: 0.0055 - val_accuracy: 0.7695\n",
      "Epoch 468/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7410 - val_loss: 0.0055 - val_accuracy: 0.7445\n",
      "Epoch 469/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7300 - val_loss: 0.0055 - val_accuracy: 0.7525\n",
      "Epoch 470/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7233 - val_loss: 0.0055 - val_accuracy: 0.7655\n",
      "Epoch 471/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7440 - val_loss: 0.0055 - val_accuracy: 0.7260\n",
      "Epoch 472/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7293 - val_loss: 0.0055 - val_accuracy: 0.7655\n",
      "Epoch 473/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7378 - val_loss: 0.0055 - val_accuracy: 0.7565\n",
      "Epoch 474/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7380 - val_loss: 0.0055 - val_accuracy: 0.7465\n",
      "Epoch 475/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7267 - val_loss: 0.0055 - val_accuracy: 0.7415\n",
      "Epoch 476/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7370 - val_loss: 0.0055 - val_accuracy: 0.7175\n",
      "Epoch 477/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7315 - val_loss: 0.0055 - val_accuracy: 0.7400\n",
      "Epoch 478/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7282 - val_loss: 0.0055 - val_accuracy: 0.7635\n",
      "Epoch 479/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7405 - val_loss: 0.0055 - val_accuracy: 0.7130\n",
      "Epoch 480/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7292 - val_loss: 0.0055 - val_accuracy: 0.7530\n",
      "Epoch 481/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7490 - val_loss: 0.0055 - val_accuracy: 0.7005\n",
      "Epoch 482/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7218 - val_loss: 0.0055 - val_accuracy: 0.7430\n",
      "Epoch 483/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7457 - val_loss: 0.0055 - val_accuracy: 0.7670\n",
      "Epoch 484/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7397 - val_loss: 0.0056 - val_accuracy: 0.7140\n",
      "Epoch 485/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7320 - val_loss: 0.0055 - val_accuracy: 0.7415\n",
      "Epoch 486/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7343 - val_loss: 0.0055 - val_accuracy: 0.7120\n",
      "Epoch 487/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7167 - val_loss: 0.0055 - val_accuracy: 0.7770\n",
      "Epoch 488/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7422 - val_loss: 0.0055 - val_accuracy: 0.7435\n",
      "Epoch 489/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7488 - val_loss: 0.0055 - val_accuracy: 0.7195\n",
      "Epoch 490/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7288 - val_loss: 0.0056 - val_accuracy: 0.7165\n",
      "Epoch 491/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7153 - val_loss: 0.0055 - val_accuracy: 0.7390\n",
      "Epoch 492/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7298 - val_loss: 0.0055 - val_accuracy: 0.7465\n",
      "Epoch 493/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7328 - val_loss: 0.0055 - val_accuracy: 0.7645\n",
      "Epoch 494/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7333 - val_loss: 0.0055 - val_accuracy: 0.7745\n",
      "Epoch 495/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7315 - val_loss: 0.0055 - val_accuracy: 0.7520\n",
      "Epoch 496/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7408 - val_loss: 0.0055 - val_accuracy: 0.7650\n",
      "Epoch 497/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7400 - val_loss: 0.0055 - val_accuracy: 0.7350\n",
      "Epoch 498/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7323 - val_loss: 0.0055 - val_accuracy: 0.7605\n",
      "Epoch 499/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7377 - val_loss: 0.0055 - val_accuracy: 0.7625\n",
      "Epoch 500/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7340 - val_loss: 0.0055 - val_accuracy: 0.7580\n",
      "Epoch 501/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7427 - val_loss: 0.0055 - val_accuracy: 0.7170\n",
      "Epoch 502/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7258 - val_loss: 0.0055 - val_accuracy: 0.7445\n",
      "Epoch 503/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7325 - val_loss: 0.0055 - val_accuracy: 0.7540\n",
      "Epoch 504/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7267 - val_loss: 0.0055 - val_accuracy: 0.7425\n",
      "Epoch 505/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7342 - val_loss: 0.0055 - val_accuracy: 0.7350\n",
      "Epoch 506/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7350 - val_loss: 0.0055 - val_accuracy: 0.7700\n",
      "Epoch 507/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7275 - val_loss: 0.0055 - val_accuracy: 0.7490\n",
      "Epoch 508/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0054 - accuracy: 0.7355 - val_loss: 0.0055 - val_accuracy: 0.7465\n",
      "Epoch 509/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7343 - val_loss: 0.0055 - val_accuracy: 0.7515\n",
      "Epoch 510/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7358 - val_loss: 0.0055 - val_accuracy: 0.7235\n",
      "Epoch 511/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7313 - val_loss: 0.0055 - val_accuracy: 0.7480\n",
      "Epoch 512/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7267 - val_loss: 0.0055 - val_accuracy: 0.7465\n",
      "Epoch 513/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7332 - val_loss: 0.0055 - val_accuracy: 0.7710\n",
      "Epoch 514/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7337 - val_loss: 0.0055 - val_accuracy: 0.7565\n",
      "Epoch 515/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7392 - val_loss: 0.0055 - val_accuracy: 0.7440\n",
      "Epoch 516/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7268 - val_loss: 0.0055 - val_accuracy: 0.7745\n",
      "Epoch 517/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7325 - val_loss: 0.0055 - val_accuracy: 0.7645\n",
      "Epoch 518/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7395 - val_loss: 0.0055 - val_accuracy: 0.7590\n",
      "Epoch 519/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7282 - val_loss: 0.0056 - val_accuracy: 0.7485\n",
      "Epoch 520/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7283 - val_loss: 0.0055 - val_accuracy: 0.7710\n",
      "Epoch 521/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7465 - val_loss: 0.0055 - val_accuracy: 0.7350\n",
      "Epoch 522/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7273 - val_loss: 0.0055 - val_accuracy: 0.7625\n",
      "Epoch 523/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7340 - val_loss: 0.0055 - val_accuracy: 0.7750\n",
      "Epoch 524/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7468 - val_loss: 0.0055 - val_accuracy: 0.7565\n",
      "Epoch 525/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7362 - val_loss: 0.0055 - val_accuracy: 0.7515\n",
      "Epoch 526/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7383 - val_loss: 0.0055 - val_accuracy: 0.7630\n",
      "Epoch 527/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7277 - val_loss: 0.0055 - val_accuracy: 0.7605\n",
      "Epoch 528/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7320 - val_loss: 0.0054 - val_accuracy: 0.7740\n",
      "Epoch 529/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7422 - val_loss: 0.0055 - val_accuracy: 0.7180\n",
      "Epoch 530/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7260 - val_loss: 0.0055 - val_accuracy: 0.7630\n",
      "Epoch 531/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7382 - val_loss: 0.0055 - val_accuracy: 0.7315\n",
      "Epoch 532/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7357 - val_loss: 0.0055 - val_accuracy: 0.7690\n",
      "Epoch 533/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7400 - val_loss: 0.0055 - val_accuracy: 0.7465\n",
      "Epoch 534/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7343 - val_loss: 0.0055 - val_accuracy: 0.7650\n",
      "Epoch 535/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7353 - val_loss: 0.0055 - val_accuracy: 0.7285\n",
      "Epoch 536/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7305 - val_loss: 0.0055 - val_accuracy: 0.7005\n",
      "Epoch 537/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7350 - val_loss: 0.0055 - val_accuracy: 0.7390\n",
      "Epoch 538/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7330 - val_loss: 0.0055 - val_accuracy: 0.7490\n",
      "Epoch 539/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7258 - val_loss: 0.0055 - val_accuracy: 0.7585\n",
      "Epoch 540/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7342 - val_loss: 0.0055 - val_accuracy: 0.7750\n",
      "Epoch 541/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7420 - val_loss: 0.0055 - val_accuracy: 0.7560\n",
      "Epoch 542/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7437 - val_loss: 0.0055 - val_accuracy: 0.7585\n",
      "Epoch 543/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7342 - val_loss: 0.0055 - val_accuracy: 0.7185\n",
      "Epoch 544/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7347 - val_loss: 0.0055 - val_accuracy: 0.7165\n",
      "Epoch 545/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7292 - val_loss: 0.0055 - val_accuracy: 0.7730\n",
      "Epoch 546/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7397 - val_loss: 0.0055 - val_accuracy: 0.7580\n",
      "Epoch 547/1000\n",
      "188/188 [==============================] - 0s 564us/step - loss: 0.0054 - accuracy: 0.7387 - val_loss: 0.0055 - val_accuracy: 0.7420\n",
      "Epoch 548/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7247 - val_loss: 0.0055 - val_accuracy: 0.7605\n",
      "Epoch 549/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7372 - val_loss: 0.0055 - val_accuracy: 0.7290\n",
      "Epoch 550/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7363 - val_loss: 0.0055 - val_accuracy: 0.7400\n",
      "Epoch 551/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7293 - val_loss: 0.0055 - val_accuracy: 0.7585\n",
      "Epoch 552/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7420 - val_loss: 0.0055 - val_accuracy: 0.7615\n",
      "Epoch 553/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7442 - val_loss: 0.0057 - val_accuracy: 0.7100\n",
      "Epoch 554/1000\n",
      "188/188 [==============================] - 0s 569us/step - loss: 0.0054 - accuracy: 0.7233 - val_loss: 0.0055 - val_accuracy: 0.7740\n",
      "Epoch 555/1000\n",
      "188/188 [==============================] - 0s 561us/step - loss: 0.0054 - accuracy: 0.7315 - val_loss: 0.0055 - val_accuracy: 0.7760\n",
      "Epoch 556/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7422 - val_loss: 0.0055 - val_accuracy: 0.7380\n",
      "Epoch 557/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7282 - val_loss: 0.0055 - val_accuracy: 0.7570\n",
      "Epoch 558/1000\n",
      "188/188 [==============================] - 0s 539us/step - loss: 0.0054 - accuracy: 0.7450 - val_loss: 0.0055 - val_accuracy: 0.7195\n",
      "Epoch 559/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7338 - val_loss: 0.0055 - val_accuracy: 0.7365\n",
      "Epoch 560/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7305 - val_loss: 0.0055 - val_accuracy: 0.7465\n",
      "Epoch 561/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7330 - val_loss: 0.0055 - val_accuracy: 0.7620\n",
      "Epoch 562/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0054 - accuracy: 0.7405 - val_loss: 0.0055 - val_accuracy: 0.7265\n",
      "Epoch 563/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7272 - val_loss: 0.0055 - val_accuracy: 0.7550\n",
      "Epoch 564/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7363 - val_loss: 0.0055 - val_accuracy: 0.7200\n",
      "Epoch 565/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7317 - val_loss: 0.0055 - val_accuracy: 0.7290\n",
      "Epoch 566/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7358 - val_loss: 0.0055 - val_accuracy: 0.7280\n",
      "Epoch 567/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7177 - val_loss: 0.0054 - val_accuracy: 0.7760\n",
      "Epoch 568/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7420 - val_loss: 0.0055 - val_accuracy: 0.7655\n",
      "Epoch 569/1000\n",
      "188/188 [==============================] - 0s 569us/step - loss: 0.0054 - accuracy: 0.7425 - val_loss: 0.0055 - val_accuracy: 0.7505\n",
      "Epoch 570/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7237 - val_loss: 0.0055 - val_accuracy: 0.7525\n",
      "Epoch 571/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7313 - val_loss: 0.0055 - val_accuracy: 0.7265\n",
      "Epoch 572/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7285 - val_loss: 0.0055 - val_accuracy: 0.7640\n",
      "Epoch 573/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7378 - val_loss: 0.0055 - val_accuracy: 0.7585\n",
      "Epoch 574/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7425 - val_loss: 0.0055 - val_accuracy: 0.7410\n",
      "Epoch 575/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7342 - val_loss: 0.0056 - val_accuracy: 0.7255\n",
      "Epoch 576/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7327 - val_loss: 0.0055 - val_accuracy: 0.7235\n",
      "Epoch 577/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7333 - val_loss: 0.0055 - val_accuracy: 0.7380\n",
      "Epoch 578/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7247 - val_loss: 0.0055 - val_accuracy: 0.7365\n",
      "Epoch 579/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7267 - val_loss: 0.0055 - val_accuracy: 0.7730\n",
      "Epoch 580/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7322 - val_loss: 0.0055 - val_accuracy: 0.7705\n",
      "Epoch 581/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7365 - val_loss: 0.0057 - val_accuracy: 0.7330\n",
      "Epoch 582/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7228 - val_loss: 0.0055 - val_accuracy: 0.7735\n",
      "Epoch 583/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7420 - val_loss: 0.0055 - val_accuracy: 0.7360\n",
      "Epoch 584/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7235 - val_loss: 0.0055 - val_accuracy: 0.7740\n",
      "Epoch 585/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7407 - val_loss: 0.0055 - val_accuracy: 0.7245\n",
      "Epoch 586/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7335 - val_loss: 0.0055 - val_accuracy: 0.7620\n",
      "Epoch 587/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7307 - val_loss: 0.0055 - val_accuracy: 0.7615\n",
      "Epoch 588/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7357 - val_loss: 0.0055 - val_accuracy: 0.7660\n",
      "Epoch 589/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7287 - val_loss: 0.0055 - val_accuracy: 0.7690\n",
      "Epoch 590/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7283 - val_loss: 0.0055 - val_accuracy: 0.7645\n",
      "Epoch 591/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7335 - val_loss: 0.0055 - val_accuracy: 0.7690\n",
      "Epoch 592/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7453 - val_loss: 0.0055 - val_accuracy: 0.7440\n",
      "Epoch 593/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7342 - val_loss: 0.0055 - val_accuracy: 0.7445\n",
      "Epoch 594/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7315 - val_loss: 0.0055 - val_accuracy: 0.7540\n",
      "Epoch 595/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7398 - val_loss: 0.0055 - val_accuracy: 0.7560\n",
      "Epoch 596/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7268 - val_loss: 0.0055 - val_accuracy: 0.7420\n",
      "Epoch 597/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7422 - val_loss: 0.0055 - val_accuracy: 0.7315\n",
      "Epoch 598/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7275 - val_loss: 0.0055 - val_accuracy: 0.7530\n",
      "Epoch 599/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7382 - val_loss: 0.0054 - val_accuracy: 0.7765\n",
      "Epoch 600/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0054 - accuracy: 0.7342 - val_loss: 0.0055 - val_accuracy: 0.7380\n",
      "Epoch 601/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7275 - val_loss: 0.0055 - val_accuracy: 0.7680\n",
      "Epoch 602/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7230 - val_loss: 0.0055 - val_accuracy: 0.7415\n",
      "Epoch 603/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7347 - val_loss: 0.0055 - val_accuracy: 0.7715\n",
      "Epoch 604/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7343 - val_loss: 0.0055 - val_accuracy: 0.7775\n",
      "Epoch 605/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7410 - val_loss: 0.0055 - val_accuracy: 0.7510\n",
      "Epoch 606/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7328 - val_loss: 0.0055 - val_accuracy: 0.7775\n",
      "Epoch 607/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7242 - val_loss: 0.0055 - val_accuracy: 0.7755\n",
      "Epoch 608/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7458 - val_loss: 0.0055 - val_accuracy: 0.7330\n",
      "Epoch 609/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7335 - val_loss: 0.0056 - val_accuracy: 0.7200\n",
      "Epoch 610/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7397 - val_loss: 0.0055 - val_accuracy: 0.7300\n",
      "Epoch 611/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7278 - val_loss: 0.0055 - val_accuracy: 0.7605\n",
      "Epoch 612/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7405 - val_loss: 0.0055 - val_accuracy: 0.7475\n",
      "Epoch 613/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7335 - val_loss: 0.0055 - val_accuracy: 0.7500\n",
      "Epoch 614/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7373 - val_loss: 0.0055 - val_accuracy: 0.7665\n",
      "Epoch 615/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7358 - val_loss: 0.0055 - val_accuracy: 0.7570\n",
      "Epoch 616/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7312 - val_loss: 0.0055 - val_accuracy: 0.7310\n",
      "Epoch 617/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7250 - val_loss: 0.0055 - val_accuracy: 0.7720\n",
      "Epoch 618/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7273 - val_loss: 0.0055 - val_accuracy: 0.7655\n",
      "Epoch 619/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7390 - val_loss: 0.0055 - val_accuracy: 0.7775\n",
      "Epoch 620/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7350 - val_loss: 0.0055 - val_accuracy: 0.7460\n",
      "Epoch 621/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7442 - val_loss: 0.0055 - val_accuracy: 0.7380\n",
      "Epoch 622/1000\n",
      "188/188 [==============================] - 0s 528us/step - loss: 0.0054 - accuracy: 0.7258 - val_loss: 0.0055 - val_accuracy: 0.7595\n",
      "Epoch 623/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7383 - val_loss: 0.0055 - val_accuracy: 0.7435\n",
      "Epoch 624/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7302 - val_loss: 0.0055 - val_accuracy: 0.7325\n",
      "Epoch 625/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7422 - val_loss: 0.0055 - val_accuracy: 0.7240\n",
      "Epoch 626/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7218 - val_loss: 0.0055 - val_accuracy: 0.7395\n",
      "Epoch 627/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7317 - val_loss: 0.0055 - val_accuracy: 0.7465\n",
      "Epoch 628/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7423 - val_loss: 0.0055 - val_accuracy: 0.7095\n",
      "Epoch 629/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7275 - val_loss: 0.0055 - val_accuracy: 0.7700\n",
      "Epoch 630/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7440 - val_loss: 0.0055 - val_accuracy: 0.7390\n",
      "Epoch 631/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7188 - val_loss: 0.0055 - val_accuracy: 0.7750\n",
      "Epoch 632/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7418 - val_loss: 0.0055 - val_accuracy: 0.7085\n",
      "Epoch 633/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7290 - val_loss: 0.0055 - val_accuracy: 0.7760\n",
      "Epoch 634/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7357 - val_loss: 0.0055 - val_accuracy: 0.7505\n",
      "Epoch 635/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7242 - val_loss: 0.0055 - val_accuracy: 0.7585\n",
      "Epoch 636/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7500 - val_loss: 0.0055 - val_accuracy: 0.7530\n",
      "Epoch 637/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7300 - val_loss: 0.0055 - val_accuracy: 0.7615\n",
      "Epoch 638/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7242 - val_loss: 0.0055 - val_accuracy: 0.7540\n",
      "Epoch 639/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7442 - val_loss: 0.0055 - val_accuracy: 0.7040\n",
      "Epoch 640/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7348 - val_loss: 0.0055 - val_accuracy: 0.7615\n",
      "Epoch 641/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7325 - val_loss: 0.0055 - val_accuracy: 0.7385\n",
      "Epoch 642/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7273 - val_loss: 0.0055 - val_accuracy: 0.7705\n",
      "Epoch 643/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7418 - val_loss: 0.0055 - val_accuracy: 0.7385\n",
      "Epoch 644/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7370 - val_loss: 0.0055 - val_accuracy: 0.7215\n",
      "Epoch 645/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7253 - val_loss: 0.0055 - val_accuracy: 0.7610\n",
      "Epoch 646/1000\n",
      "188/188 [==============================] - 0s 540us/step - loss: 0.0054 - accuracy: 0.7397 - val_loss: 0.0055 - val_accuracy: 0.7460\n",
      "Epoch 647/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7330 - val_loss: 0.0055 - val_accuracy: 0.7090\n",
      "Epoch 648/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7238 - val_loss: 0.0055 - val_accuracy: 0.7450\n",
      "Epoch 649/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7350 - val_loss: 0.0056 - val_accuracy: 0.7530\n",
      "Epoch 650/1000\n",
      "188/188 [==============================] - 0s 534us/step - loss: 0.0054 - accuracy: 0.7415 - val_loss: 0.0055 - val_accuracy: 0.7640\n",
      "Epoch 651/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7387 - val_loss: 0.0055 - val_accuracy: 0.7160\n",
      "Epoch 652/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7262 - val_loss: 0.0056 - val_accuracy: 0.7230\n",
      "Epoch 653/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7412 - val_loss: 0.0055 - val_accuracy: 0.7405\n",
      "Epoch 654/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7343 - val_loss: 0.0055 - val_accuracy: 0.7705\n",
      "Epoch 655/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7460 - val_loss: 0.0055 - val_accuracy: 0.7360\n",
      "Epoch 656/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7268 - val_loss: 0.0055 - val_accuracy: 0.7620\n",
      "Epoch 657/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0055 - accuracy: 0.7248 - val_loss: 0.0055 - val_accuracy: 0.7345\n",
      "Epoch 658/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7343 - val_loss: 0.0055 - val_accuracy: 0.7300\n",
      "Epoch 659/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7398 - val_loss: 0.0055 - val_accuracy: 0.7190\n",
      "Epoch 660/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7242 - val_loss: 0.0055 - val_accuracy: 0.7490\n",
      "Epoch 661/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7430 - val_loss: 0.0055 - val_accuracy: 0.7370\n",
      "Epoch 662/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7352 - val_loss: 0.0055 - val_accuracy: 0.7585\n",
      "Epoch 663/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7253 - val_loss: 0.0055 - val_accuracy: 0.7705\n",
      "Epoch 664/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7403 - val_loss: 0.0055 - val_accuracy: 0.7615\n",
      "Epoch 665/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7277 - val_loss: 0.0055 - val_accuracy: 0.7610\n",
      "Epoch 666/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7337 - val_loss: 0.0056 - val_accuracy: 0.7410\n",
      "Epoch 667/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7288 - val_loss: 0.0055 - val_accuracy: 0.7730\n",
      "Epoch 668/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7358 - val_loss: 0.0055 - val_accuracy: 0.7660\n",
      "Epoch 669/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7415 - val_loss: 0.0055 - val_accuracy: 0.7660\n",
      "Epoch 670/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7355 - val_loss: 0.0055 - val_accuracy: 0.7530\n",
      "Epoch 671/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7417 - val_loss: 0.0055 - val_accuracy: 0.7235\n",
      "Epoch 672/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7362 - val_loss: 0.0055 - val_accuracy: 0.7225\n",
      "Epoch 673/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7185 - val_loss: 0.0055 - val_accuracy: 0.7510\n",
      "Epoch 674/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7342 - val_loss: 0.0055 - val_accuracy: 0.7435\n",
      "Epoch 675/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7325 - val_loss: 0.0055 - val_accuracy: 0.7380\n",
      "Epoch 676/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7363 - val_loss: 0.0055 - val_accuracy: 0.7645\n",
      "Epoch 677/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7398 - val_loss: 0.0055 - val_accuracy: 0.7375\n",
      "Epoch 678/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7298 - val_loss: 0.0055 - val_accuracy: 0.7300\n",
      "Epoch 679/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7348 - val_loss: 0.0055 - val_accuracy: 0.7415\n",
      "Epoch 680/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7310 - val_loss: 0.0055 - val_accuracy: 0.7710\n",
      "Epoch 681/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7258 - val_loss: 0.0057 - val_accuracy: 0.7335\n",
      "Epoch 682/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7348 - val_loss: 0.0055 - val_accuracy: 0.7730\n",
      "Epoch 683/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7453 - val_loss: 0.0055 - val_accuracy: 0.7585\n",
      "Epoch 684/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7265 - val_loss: 0.0055 - val_accuracy: 0.7595\n",
      "Epoch 685/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7330 - val_loss: 0.0055 - val_accuracy: 0.7305\n",
      "Epoch 686/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7353 - val_loss: 0.0055 - val_accuracy: 0.7425\n",
      "Epoch 687/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7290 - val_loss: 0.0055 - val_accuracy: 0.7555\n",
      "Epoch 688/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7265 - val_loss: 0.0055 - val_accuracy: 0.7545\n",
      "Epoch 689/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7430 - val_loss: 0.0055 - val_accuracy: 0.7265\n",
      "Epoch 690/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7377 - val_loss: 0.0055 - val_accuracy: 0.7330\n",
      "Epoch 691/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7220 - val_loss: 0.0055 - val_accuracy: 0.7710\n",
      "Epoch 692/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7443 - val_loss: 0.0055 - val_accuracy: 0.7515\n",
      "Epoch 693/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7190 - val_loss: 0.0055 - val_accuracy: 0.7725\n",
      "Epoch 694/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7388 - val_loss: 0.0055 - val_accuracy: 0.7390\n",
      "Epoch 695/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7273 - val_loss: 0.0055 - val_accuracy: 0.7615\n",
      "Epoch 696/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7323 - val_loss: 0.0055 - val_accuracy: 0.7720\n",
      "Epoch 697/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7438 - val_loss: 0.0055 - val_accuracy: 0.7560\n",
      "Epoch 698/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7333 - val_loss: 0.0055 - val_accuracy: 0.7675\n",
      "Epoch 699/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7293 - val_loss: 0.0055 - val_accuracy: 0.7480\n",
      "Epoch 700/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7358 - val_loss: 0.0055 - val_accuracy: 0.7600\n",
      "Epoch 701/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7363 - val_loss: 0.0055 - val_accuracy: 0.7405\n",
      "Epoch 702/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7185 - val_loss: 0.0055 - val_accuracy: 0.7530\n",
      "Epoch 703/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7300 - val_loss: 0.0055 - val_accuracy: 0.7360\n",
      "Epoch 704/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7337 - val_loss: 0.0055 - val_accuracy: 0.7750\n",
      "Epoch 705/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7322 - val_loss: 0.0055 - val_accuracy: 0.7670\n",
      "Epoch 706/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7323 - val_loss: 0.0055 - val_accuracy: 0.7700\n",
      "Epoch 707/1000\n",
      "188/188 [==============================] - 0s 575us/step - loss: 0.0054 - accuracy: 0.7330 - val_loss: 0.0055 - val_accuracy: 0.7690\n",
      "Epoch 708/1000\n",
      "188/188 [==============================] - 0s 580us/step - loss: 0.0054 - accuracy: 0.7438 - val_loss: 0.0055 - val_accuracy: 0.7425\n",
      "Epoch 709/1000\n",
      "188/188 [==============================] - 0s 580us/step - loss: 0.0054 - accuracy: 0.7415 - val_loss: 0.0055 - val_accuracy: 0.7070\n",
      "Epoch 710/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0054 - accuracy: 0.7313 - val_loss: 0.0055 - val_accuracy: 0.7075\n",
      "Epoch 711/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7253 - val_loss: 0.0055 - val_accuracy: 0.7325\n",
      "Epoch 712/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7345 - val_loss: 0.0055 - val_accuracy: 0.7355\n",
      "Epoch 713/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7358 - val_loss: 0.0055 - val_accuracy: 0.7490\n",
      "Epoch 714/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7293 - val_loss: 0.0055 - val_accuracy: 0.7575\n",
      "Epoch 715/1000\n",
      "188/188 [==============================] - 0s 580us/step - loss: 0.0054 - accuracy: 0.7345 - val_loss: 0.0055 - val_accuracy: 0.7255\n",
      "Epoch 716/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7377 - val_loss: 0.0055 - val_accuracy: 0.7430\n",
      "Epoch 717/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7380 - val_loss: 0.0055 - val_accuracy: 0.7525\n",
      "Epoch 718/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0054 - accuracy: 0.7342 - val_loss: 0.0055 - val_accuracy: 0.7610\n",
      "Epoch 719/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7325 - val_loss: 0.0055 - val_accuracy: 0.7590\n",
      "Epoch 720/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7315 - val_loss: 0.0055 - val_accuracy: 0.7735\n",
      "Epoch 721/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7407 - val_loss: 0.0055 - val_accuracy: 0.7285\n",
      "Epoch 722/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7305 - val_loss: 0.0055 - val_accuracy: 0.7680\n",
      "Epoch 723/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7397 - val_loss: 0.0055 - val_accuracy: 0.7535\n",
      "Epoch 724/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7372 - val_loss: 0.0055 - val_accuracy: 0.7575\n",
      "Epoch 725/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7272 - val_loss: 0.0055 - val_accuracy: 0.7790\n",
      "Epoch 726/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7363 - val_loss: 0.0055 - val_accuracy: 0.7710\n",
      "Epoch 727/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7397 - val_loss: 0.0055 - val_accuracy: 0.7160\n",
      "Epoch 728/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7415 - val_loss: 0.0055 - val_accuracy: 0.7640\n",
      "Epoch 729/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7303 - val_loss: 0.0055 - val_accuracy: 0.7375\n",
      "Epoch 730/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7313 - val_loss: 0.0055 - val_accuracy: 0.7650\n",
      "Epoch 731/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7392 - val_loss: 0.0055 - val_accuracy: 0.7255\n",
      "Epoch 732/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7363 - val_loss: 0.0055 - val_accuracy: 0.7180\n",
      "Epoch 733/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7218 - val_loss: 0.0055 - val_accuracy: 0.7575\n",
      "Epoch 734/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7395 - val_loss: 0.0055 - val_accuracy: 0.7480\n",
      "Epoch 735/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7242 - val_loss: 0.0055 - val_accuracy: 0.7745\n",
      "Epoch 736/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7325 - val_loss: 0.0055 - val_accuracy: 0.7465\n",
      "Epoch 737/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7302 - val_loss: 0.0055 - val_accuracy: 0.7050\n",
      "Epoch 738/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7370 - val_loss: 0.0055 - val_accuracy: 0.7400\n",
      "Epoch 739/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7333 - val_loss: 0.0055 - val_accuracy: 0.7670\n",
      "Epoch 740/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7437 - val_loss: 0.0055 - val_accuracy: 0.7130\n",
      "Epoch 741/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7193 - val_loss: 0.0055 - val_accuracy: 0.7470\n",
      "Epoch 742/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7180 - val_loss: 0.0055 - val_accuracy: 0.7500\n",
      "Epoch 743/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7365 - val_loss: 0.0055 - val_accuracy: 0.7485\n",
      "Epoch 744/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7302 - val_loss: 0.0055 - val_accuracy: 0.7695\n",
      "Epoch 745/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7398 - val_loss: 0.0055 - val_accuracy: 0.7425\n",
      "Epoch 746/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7302 - val_loss: 0.0055 - val_accuracy: 0.7515\n",
      "Epoch 747/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7380 - val_loss: 0.0055 - val_accuracy: 0.7240\n",
      "Epoch 748/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7368 - val_loss: 0.0055 - val_accuracy: 0.7455\n",
      "Epoch 749/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7397 - val_loss: 0.0055 - val_accuracy: 0.7225\n",
      "Epoch 750/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7227 - val_loss: 0.0055 - val_accuracy: 0.7635\n",
      "Epoch 751/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7307 - val_loss: 0.0055 - val_accuracy: 0.7595\n",
      "Epoch 752/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7423 - val_loss: 0.0055 - val_accuracy: 0.7720\n",
      "Epoch 753/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7322 - val_loss: 0.0055 - val_accuracy: 0.7670\n",
      "Epoch 754/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7218 - val_loss: 0.0055 - val_accuracy: 0.7675\n",
      "Epoch 755/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7477 - val_loss: 0.0055 - val_accuracy: 0.7415\n",
      "Epoch 756/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7267 - val_loss: 0.0055 - val_accuracy: 0.7735\n",
      "Epoch 757/1000\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0054 - accuracy: 0.7300 - val_loss: 0.0055 - val_accuracy: 0.7540\n",
      "Epoch 758/1000\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0054 - accuracy: 0.7440 - val_loss: 0.0055 - val_accuracy: 0.7280\n",
      "Epoch 759/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7252 - val_loss: 0.0055 - val_accuracy: 0.7505\n",
      "Epoch 760/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7412 - val_loss: 0.0055 - val_accuracy: 0.7320\n",
      "Epoch 761/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7207 - val_loss: 0.0055 - val_accuracy: 0.7675\n",
      "Epoch 762/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7353 - val_loss: 0.0055 - val_accuracy: 0.7355\n",
      "Epoch 763/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7383 - val_loss: 0.0055 - val_accuracy: 0.7315\n",
      "Epoch 764/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7323 - val_loss: 0.0055 - val_accuracy: 0.7475\n",
      "Epoch 765/1000\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0054 - accuracy: 0.7363 - val_loss: 0.0055 - val_accuracy: 0.7120\n",
      "Epoch 766/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7343 - val_loss: 0.0055 - val_accuracy: 0.7375\n",
      "Epoch 767/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7273 - val_loss: 0.0055 - val_accuracy: 0.7430\n",
      "Epoch 768/1000\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0054 - accuracy: 0.7390 - val_loss: 0.0055 - val_accuracy: 0.7625\n",
      "Epoch 769/1000\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0054 - accuracy: 0.7260 - val_loss: 0.0055 - val_accuracy: 0.7715\n",
      "Epoch 770/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7408 - val_loss: 0.0055 - val_accuracy: 0.7255\n",
      "Epoch 771/1000\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0054 - accuracy: 0.7337 - val_loss: 0.0055 - val_accuracy: 0.7560\n",
      "Epoch 772/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7270 - val_loss: 0.0054 - val_accuracy: 0.7765\n",
      "Epoch 773/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7268 - val_loss: 0.0055 - val_accuracy: 0.7650\n",
      "Epoch 774/1000\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0054 - accuracy: 0.7352 - val_loss: 0.0055 - val_accuracy: 0.7585\n",
      "Epoch 775/1000\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0054 - accuracy: 0.7400 - val_loss: 0.0055 - val_accuracy: 0.7445\n",
      "Epoch 776/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7295 - val_loss: 0.0055 - val_accuracy: 0.7750\n",
      "Epoch 777/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7388 - val_loss: 0.0055 - val_accuracy: 0.7130\n",
      "Epoch 778/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7257 - val_loss: 0.0055 - val_accuracy: 0.7295\n",
      "Epoch 779/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0054 - accuracy: 0.7327 - val_loss: 0.0055 - val_accuracy: 0.7420\n",
      "Epoch 780/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7298 - val_loss: 0.0055 - val_accuracy: 0.7360\n",
      "Epoch 781/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7272 - val_loss: 0.0055 - val_accuracy: 0.7660\n",
      "Epoch 782/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7425 - val_loss: 0.0055 - val_accuracy: 0.7560\n",
      "Epoch 783/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7315 - val_loss: 0.0055 - val_accuracy: 0.7715\n",
      "Epoch 784/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7382 - val_loss: 0.0055 - val_accuracy: 0.7530\n",
      "Epoch 785/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7353 - val_loss: 0.0055 - val_accuracy: 0.7435\n",
      "Epoch 786/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7303 - val_loss: 0.0055 - val_accuracy: 0.7610\n",
      "Epoch 787/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7403 - val_loss: 0.0055 - val_accuracy: 0.7330\n",
      "Epoch 788/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7320 - val_loss: 0.0055 - val_accuracy: 0.7205\n",
      "Epoch 789/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7257 - val_loss: 0.0055 - val_accuracy: 0.7375\n",
      "Epoch 790/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7350 - val_loss: 0.0055 - val_accuracy: 0.7605\n",
      "Epoch 791/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7293 - val_loss: 0.0055 - val_accuracy: 0.7670\n",
      "Epoch 792/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7255 - val_loss: 0.0055 - val_accuracy: 0.7525\n",
      "Epoch 793/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7342 - val_loss: 0.0055 - val_accuracy: 0.7330\n",
      "Epoch 794/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7257 - val_loss: 0.0055 - val_accuracy: 0.7385\n",
      "Epoch 795/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7272 - val_loss: 0.0055 - val_accuracy: 0.7580\n",
      "Epoch 796/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7262 - val_loss: 0.0055 - val_accuracy: 0.7665\n",
      "Epoch 797/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7360 - val_loss: 0.0055 - val_accuracy: 0.7260\n",
      "Epoch 798/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7330 - val_loss: 0.0055 - val_accuracy: 0.7570\n",
      "Epoch 799/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7223 - val_loss: 0.0055 - val_accuracy: 0.7720\n",
      "Epoch 800/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7370 - val_loss: 0.0055 - val_accuracy: 0.7680\n",
      "Epoch 801/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7330 - val_loss: 0.0055 - val_accuracy: 0.7645\n",
      "Epoch 802/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7340 - val_loss: 0.0055 - val_accuracy: 0.7370\n",
      "Epoch 803/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7278 - val_loss: 0.0055 - val_accuracy: 0.7615\n",
      "Epoch 804/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7447 - val_loss: 0.0055 - val_accuracy: 0.7325\n",
      "Epoch 805/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7232 - val_loss: 0.0055 - val_accuracy: 0.7575\n",
      "Epoch 806/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7475 - val_loss: 0.0055 - val_accuracy: 0.7320\n",
      "Epoch 807/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7362 - val_loss: 0.0055 - val_accuracy: 0.7165\n",
      "Epoch 808/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7335 - val_loss: 0.0055 - val_accuracy: 0.7195\n",
      "Epoch 809/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7313 - val_loss: 0.0055 - val_accuracy: 0.7490\n",
      "Epoch 810/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7327 - val_loss: 0.0055 - val_accuracy: 0.7695\n",
      "Epoch 811/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7233 - val_loss: 0.0055 - val_accuracy: 0.7685\n",
      "Epoch 812/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7372 - val_loss: 0.0055 - val_accuracy: 0.7515\n",
      "Epoch 813/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7327 - val_loss: 0.0055 - val_accuracy: 0.7625\n",
      "Epoch 814/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7360 - val_loss: 0.0055 - val_accuracy: 0.7620\n",
      "Epoch 815/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7402 - val_loss: 0.0055 - val_accuracy: 0.7460\n",
      "Epoch 816/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0054 - accuracy: 0.7292 - val_loss: 0.0055 - val_accuracy: 0.7380\n",
      "Epoch 817/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0054 - accuracy: 0.7435 - val_loss: 0.0055 - val_accuracy: 0.7525\n",
      "Epoch 818/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7350 - val_loss: 0.0055 - val_accuracy: 0.7155\n",
      "Epoch 819/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7237 - val_loss: 0.0055 - val_accuracy: 0.7660\n",
      "Epoch 820/1000\n",
      "188/188 [==============================] - 0s 577us/step - loss: 0.0054 - accuracy: 0.7383 - val_loss: 0.0055 - val_accuracy: 0.7370\n",
      "Epoch 821/1000\n",
      "188/188 [==============================] - 0s 569us/step - loss: 0.0054 - accuracy: 0.7405 - val_loss: 0.0055 - val_accuracy: 0.7425\n",
      "Epoch 822/1000\n",
      "188/188 [==============================] - 0s 575us/step - loss: 0.0054 - accuracy: 0.7232 - val_loss: 0.0055 - val_accuracy: 0.7560\n",
      "Epoch 823/1000\n",
      "188/188 [==============================] - 0s 569us/step - loss: 0.0054 - accuracy: 0.7450 - val_loss: 0.0055 - val_accuracy: 0.7590\n",
      "Epoch 824/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7332 - val_loss: 0.0055 - val_accuracy: 0.7735\n",
      "Epoch 825/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7333 - val_loss: 0.0055 - val_accuracy: 0.7685\n",
      "Epoch 826/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7348 - val_loss: 0.0055 - val_accuracy: 0.7665\n",
      "Epoch 827/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7457 - val_loss: 0.0055 - val_accuracy: 0.7245\n",
      "Epoch 828/1000\n",
      "188/188 [==============================] - 0s 575us/step - loss: 0.0054 - accuracy: 0.7260 - val_loss: 0.0055 - val_accuracy: 0.7310\n",
      "Epoch 829/1000\n",
      "188/188 [==============================] - 0s 564us/step - loss: 0.0054 - accuracy: 0.7462 - val_loss: 0.0055 - val_accuracy: 0.7130\n",
      "Epoch 830/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7292 - val_loss: 0.0055 - val_accuracy: 0.7385\n",
      "Epoch 831/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7210 - val_loss: 0.0055 - val_accuracy: 0.7650\n",
      "Epoch 832/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7397 - val_loss: 0.0055 - val_accuracy: 0.7720\n",
      "Epoch 833/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7302 - val_loss: 0.0055 - val_accuracy: 0.7755\n",
      "Epoch 834/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7400 - val_loss: 0.0055 - val_accuracy: 0.7725\n",
      "Epoch 835/1000\n",
      "188/188 [==============================] - 0s 575us/step - loss: 0.0054 - accuracy: 0.7367 - val_loss: 0.0055 - val_accuracy: 0.7690\n",
      "Epoch 836/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7405 - val_loss: 0.0055 - val_accuracy: 0.7530\n",
      "Epoch 837/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7373 - val_loss: 0.0055 - val_accuracy: 0.7740\n",
      "Epoch 838/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7268 - val_loss: 0.0055 - val_accuracy: 0.7630\n",
      "Epoch 839/1000\n",
      "188/188 [==============================] - 0s 585us/step - loss: 0.0054 - accuracy: 0.7397 - val_loss: 0.0055 - val_accuracy: 0.7650\n",
      "Epoch 840/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7408 - val_loss: 0.0055 - val_accuracy: 0.7195\n",
      "Epoch 841/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7318 - val_loss: 0.0055 - val_accuracy: 0.7630\n",
      "Epoch 842/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7247 - val_loss: 0.0055 - val_accuracy: 0.7715\n",
      "Epoch 843/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7420 - val_loss: 0.0055 - val_accuracy: 0.7330\n",
      "Epoch 844/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7422 - val_loss: 0.0055 - val_accuracy: 0.7465\n",
      "Epoch 845/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7302 - val_loss: 0.0055 - val_accuracy: 0.7710\n",
      "Epoch 846/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7428 - val_loss: 0.0055 - val_accuracy: 0.7420\n",
      "Epoch 847/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7317 - val_loss: 0.0055 - val_accuracy: 0.7495\n",
      "Epoch 848/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7330 - val_loss: 0.0055 - val_accuracy: 0.7730\n",
      "Epoch 849/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7363 - val_loss: 0.0055 - val_accuracy: 0.7705\n",
      "Epoch 850/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7350 - val_loss: 0.0055 - val_accuracy: 0.7615\n",
      "Epoch 851/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7363 - val_loss: 0.0055 - val_accuracy: 0.7250\n",
      "Epoch 852/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7258 - val_loss: 0.0055 - val_accuracy: 0.7520\n",
      "Epoch 853/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7353 - val_loss: 0.0054 - val_accuracy: 0.7765\n",
      "Epoch 854/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7527 - val_loss: 0.0055 - val_accuracy: 0.7340\n",
      "Epoch 855/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7230 - val_loss: 0.0055 - val_accuracy: 0.7595\n",
      "Epoch 856/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7405 - val_loss: 0.0055 - val_accuracy: 0.7645\n",
      "Epoch 857/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7397 - val_loss: 0.0055 - val_accuracy: 0.7115\n",
      "Epoch 858/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7222 - val_loss: 0.0055 - val_accuracy: 0.7560\n",
      "Epoch 859/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7413 - val_loss: 0.0055 - val_accuracy: 0.7345\n",
      "Epoch 860/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7365 - val_loss: 0.0055 - val_accuracy: 0.7325\n",
      "Epoch 861/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7265 - val_loss: 0.0055 - val_accuracy: 0.7715\n",
      "Epoch 862/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7387 - val_loss: 0.0055 - val_accuracy: 0.7520\n",
      "Epoch 863/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7368 - val_loss: 0.0055 - val_accuracy: 0.7735\n",
      "Epoch 864/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7407 - val_loss: 0.0055 - val_accuracy: 0.7435\n",
      "Epoch 865/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7270 - val_loss: 0.0055 - val_accuracy: 0.7425\n",
      "Epoch 866/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7350 - val_loss: 0.0055 - val_accuracy: 0.7350\n",
      "Epoch 867/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7355 - val_loss: 0.0055 - val_accuracy: 0.7550\n",
      "Epoch 868/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7372 - val_loss: 0.0055 - val_accuracy: 0.7325\n",
      "Epoch 869/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7305 - val_loss: 0.0055 - val_accuracy: 0.7340\n",
      "Epoch 870/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7395 - val_loss: 0.0055 - val_accuracy: 0.7360\n",
      "Epoch 871/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7413 - val_loss: 0.0055 - val_accuracy: 0.7415\n",
      "Epoch 872/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7217 - val_loss: 0.0055 - val_accuracy: 0.7640\n",
      "Epoch 873/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7410 - val_loss: 0.0055 - val_accuracy: 0.7170\n",
      "Epoch 874/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7232 - val_loss: 0.0055 - val_accuracy: 0.7750\n",
      "Epoch 875/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7475 - val_loss: 0.0055 - val_accuracy: 0.7375\n",
      "Epoch 876/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7252 - val_loss: 0.0055 - val_accuracy: 0.7430\n",
      "Epoch 877/1000\n",
      "188/188 [==============================] - 0s 580us/step - loss: 0.0054 - accuracy: 0.7392 - val_loss: 0.0055 - val_accuracy: 0.7370\n",
      "Epoch 878/1000\n",
      "188/188 [==============================] - 0s 564us/step - loss: 0.0054 - accuracy: 0.7255 - val_loss: 0.0055 - val_accuracy: 0.7715\n",
      "Epoch 879/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7410 - val_loss: 0.0055 - val_accuracy: 0.7185\n",
      "Epoch 880/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7223 - val_loss: 0.0055 - val_accuracy: 0.7695\n",
      "Epoch 881/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7385 - val_loss: 0.0055 - val_accuracy: 0.7645\n",
      "Epoch 882/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7288 - val_loss: 0.0055 - val_accuracy: 0.7645\n",
      "Epoch 883/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7273 - val_loss: 0.0055 - val_accuracy: 0.7560\n",
      "Epoch 884/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7418 - val_loss: 0.0055 - val_accuracy: 0.7505\n",
      "Epoch 885/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7370 - val_loss: 0.0055 - val_accuracy: 0.7585\n",
      "Epoch 886/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7355 - val_loss: 0.0055 - val_accuracy: 0.7670\n",
      "Epoch 887/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7312 - val_loss: 0.0055 - val_accuracy: 0.7645\n",
      "Epoch 888/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7427 - val_loss: 0.0055 - val_accuracy: 0.7695\n",
      "Epoch 889/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7347 - val_loss: 0.0055 - val_accuracy: 0.7430\n",
      "Epoch 890/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7312 - val_loss: 0.0055 - val_accuracy: 0.7460\n",
      "Epoch 891/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7247 - val_loss: 0.0055 - val_accuracy: 0.7790\n",
      "Epoch 892/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7498 - val_loss: 0.0055 - val_accuracy: 0.7530\n",
      "Epoch 893/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7330 - val_loss: 0.0055 - val_accuracy: 0.7030\n",
      "Epoch 894/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7263 - val_loss: 0.0055 - val_accuracy: 0.7625\n",
      "Epoch 895/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7393 - val_loss: 0.0055 - val_accuracy: 0.7625\n",
      "Epoch 896/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7253 - val_loss: 0.0055 - val_accuracy: 0.7165\n",
      "Epoch 897/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7417 - val_loss: 0.0055 - val_accuracy: 0.7290\n",
      "Epoch 898/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7322 - val_loss: 0.0055 - val_accuracy: 0.7355\n",
      "Epoch 899/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7270 - val_loss: 0.0055 - val_accuracy: 0.7630\n",
      "Epoch 900/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7313 - val_loss: 0.0055 - val_accuracy: 0.7700\n",
      "Epoch 901/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7355 - val_loss: 0.0055 - val_accuracy: 0.7460\n",
      "Epoch 902/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7405 - val_loss: 0.0055 - val_accuracy: 0.7455\n",
      "Epoch 903/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7367 - val_loss: 0.0055 - val_accuracy: 0.7070\n",
      "Epoch 904/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7337 - val_loss: 0.0055 - val_accuracy: 0.7545\n",
      "Epoch 905/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7273 - val_loss: 0.0055 - val_accuracy: 0.7765\n",
      "Epoch 906/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7370 - val_loss: 0.0055 - val_accuracy: 0.7565\n",
      "Epoch 907/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7258 - val_loss: 0.0055 - val_accuracy: 0.7745\n",
      "Epoch 908/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7455 - val_loss: 0.0055 - val_accuracy: 0.7205\n",
      "Epoch 909/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7317 - val_loss: 0.0055 - val_accuracy: 0.7260\n",
      "Epoch 910/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7353 - val_loss: 0.0055 - val_accuracy: 0.7615\n",
      "Epoch 911/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7307 - val_loss: 0.0055 - val_accuracy: 0.7715\n",
      "Epoch 912/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7392 - val_loss: 0.0055 - val_accuracy: 0.7410\n",
      "Epoch 913/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7277 - val_loss: 0.0055 - val_accuracy: 0.7480\n",
      "Epoch 914/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7307 - val_loss: 0.0055 - val_accuracy: 0.7730\n",
      "Epoch 915/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7395 - val_loss: 0.0055 - val_accuracy: 0.7450\n",
      "Epoch 916/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7330 - val_loss: 0.0055 - val_accuracy: 0.7595\n",
      "Epoch 917/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7440 - val_loss: 0.0055 - val_accuracy: 0.7420\n",
      "Epoch 918/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7313 - val_loss: 0.0055 - val_accuracy: 0.7500\n",
      "Epoch 919/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7375 - val_loss: 0.0055 - val_accuracy: 0.7635\n",
      "Epoch 920/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7315 - val_loss: 0.0055 - val_accuracy: 0.7625\n",
      "Epoch 921/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7333 - val_loss: 0.0055 - val_accuracy: 0.7725\n",
      "Epoch 922/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7388 - val_loss: 0.0055 - val_accuracy: 0.7640\n",
      "Epoch 923/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7482 - val_loss: 0.0055 - val_accuracy: 0.7195\n",
      "Epoch 924/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7347 - val_loss: 0.0055 - val_accuracy: 0.7330\n",
      "Epoch 925/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7288 - val_loss: 0.0055 - val_accuracy: 0.7580\n",
      "Epoch 926/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7402 - val_loss: 0.0055 - val_accuracy: 0.7485\n",
      "Epoch 927/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7312 - val_loss: 0.0055 - val_accuracy: 0.7560\n",
      "Epoch 928/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7420 - val_loss: 0.0055 - val_accuracy: 0.7495\n",
      "Epoch 929/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7242 - val_loss: 0.0055 - val_accuracy: 0.7665\n",
      "Epoch 930/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7307 - val_loss: 0.0055 - val_accuracy: 0.7730\n",
      "Epoch 931/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7517 - val_loss: 0.0055 - val_accuracy: 0.7300\n",
      "Epoch 932/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7302 - val_loss: 0.0055 - val_accuracy: 0.7215\n",
      "Epoch 933/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7387 - val_loss: 0.0055 - val_accuracy: 0.7205\n",
      "Epoch 934/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7225 - val_loss: 0.0055 - val_accuracy: 0.7740\n",
      "Epoch 935/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7397 - val_loss: 0.0055 - val_accuracy: 0.7280\n",
      "Epoch 936/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7320 - val_loss: 0.0055 - val_accuracy: 0.7165\n",
      "Epoch 937/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7338 - val_loss: 0.0055 - val_accuracy: 0.7410\n",
      "Epoch 938/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7342 - val_loss: 0.0055 - val_accuracy: 0.7725\n",
      "Epoch 939/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7358 - val_loss: 0.0055 - val_accuracy: 0.7610\n",
      "Epoch 940/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7440 - val_loss: 0.0055 - val_accuracy: 0.7310\n",
      "Epoch 941/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7200 - val_loss: 0.0055 - val_accuracy: 0.7775\n",
      "Epoch 942/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7343 - val_loss: 0.0055 - val_accuracy: 0.7740\n",
      "Epoch 943/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7388 - val_loss: 0.0055 - val_accuracy: 0.7540\n",
      "Epoch 944/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7272 - val_loss: 0.0055 - val_accuracy: 0.7550\n",
      "Epoch 945/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7367 - val_loss: 0.0055 - val_accuracy: 0.7525\n",
      "Epoch 946/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7205 - val_loss: 0.0055 - val_accuracy: 0.7725\n",
      "Epoch 947/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7437 - val_loss: 0.0055 - val_accuracy: 0.7390\n",
      "Epoch 948/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7390 - val_loss: 0.0055 - val_accuracy: 0.7520\n",
      "Epoch 949/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7410 - val_loss: 0.0055 - val_accuracy: 0.7300\n",
      "Epoch 950/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7288 - val_loss: 0.0055 - val_accuracy: 0.7315\n",
      "Epoch 951/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7277 - val_loss: 0.0055 - val_accuracy: 0.7475\n",
      "Epoch 952/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7317 - val_loss: 0.0055 - val_accuracy: 0.7590\n",
      "Epoch 953/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7433 - val_loss: 0.0055 - val_accuracy: 0.7560\n",
      "Epoch 954/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7220 - val_loss: 0.0055 - val_accuracy: 0.7715\n",
      "Epoch 955/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7395 - val_loss: 0.0055 - val_accuracy: 0.7560\n",
      "Epoch 956/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7378 - val_loss: 0.0055 - val_accuracy: 0.7550\n",
      "Epoch 957/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7352 - val_loss: 0.0055 - val_accuracy: 0.7685\n",
      "Epoch 958/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7368 - val_loss: 0.0055 - val_accuracy: 0.7750\n",
      "Epoch 959/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7280 - val_loss: 0.0055 - val_accuracy: 0.7690\n",
      "Epoch 960/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7397 - val_loss: 0.0055 - val_accuracy: 0.7575\n",
      "Epoch 961/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7378 - val_loss: 0.0055 - val_accuracy: 0.7470\n",
      "Epoch 962/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7417 - val_loss: 0.0055 - val_accuracy: 0.7475\n",
      "Epoch 963/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7232 - val_loss: 0.0055 - val_accuracy: 0.7690\n",
      "Epoch 964/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7432 - val_loss: 0.0055 - val_accuracy: 0.7165\n",
      "Epoch 965/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7315 - val_loss: 0.0055 - val_accuracy: 0.7130\n",
      "Epoch 966/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7347 - val_loss: 0.0055 - val_accuracy: 0.7005\n",
      "Epoch 967/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7222 - val_loss: 0.0055 - val_accuracy: 0.7525\n",
      "Epoch 968/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7227 - val_loss: 0.0055 - val_accuracy: 0.7760\n",
      "Epoch 969/1000\n",
      "188/188 [==============================] - 0s 564us/step - loss: 0.0054 - accuracy: 0.7482 - val_loss: 0.0055 - val_accuracy: 0.7110\n",
      "Epoch 970/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7275 - val_loss: 0.0055 - val_accuracy: 0.7360\n",
      "Epoch 971/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7408 - val_loss: 0.0055 - val_accuracy: 0.7530\n",
      "Epoch 972/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7285 - val_loss: 0.0055 - val_accuracy: 0.7720\n",
      "Epoch 973/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7347 - val_loss: 0.0055 - val_accuracy: 0.7450\n",
      "Epoch 974/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7397 - val_loss: 0.0055 - val_accuracy: 0.7265\n",
      "Epoch 975/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7383 - val_loss: 0.0055 - val_accuracy: 0.7230\n",
      "Epoch 976/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7337 - val_loss: 0.0055 - val_accuracy: 0.7450\n",
      "Epoch 977/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7317 - val_loss: 0.0055 - val_accuracy: 0.7475\n",
      "Epoch 978/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7210 - val_loss: 0.0055 - val_accuracy: 0.7730\n",
      "Epoch 979/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7462 - val_loss: 0.0055 - val_accuracy: 0.7265\n",
      "Epoch 980/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7348 - val_loss: 0.0055 - val_accuracy: 0.7510\n",
      "Epoch 981/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7270 - val_loss: 0.0055 - val_accuracy: 0.7245\n",
      "Epoch 982/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7378 - val_loss: 0.0055 - val_accuracy: 0.7320\n",
      "Epoch 983/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7370 - val_loss: 0.0055 - val_accuracy: 0.7440\n",
      "Epoch 984/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7318 - val_loss: 0.0055 - val_accuracy: 0.7415\n",
      "Epoch 985/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7302 - val_loss: 0.0055 - val_accuracy: 0.7750\n",
      "Epoch 986/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7433 - val_loss: 0.0055 - val_accuracy: 0.7390\n",
      "Epoch 987/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7387 - val_loss: 0.0055 - val_accuracy: 0.7490\n",
      "Epoch 988/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7327 - val_loss: 0.0056 - val_accuracy: 0.7230\n",
      "Epoch 989/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7327 - val_loss: 0.0055 - val_accuracy: 0.7310\n",
      "Epoch 990/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7343 - val_loss: 0.0055 - val_accuracy: 0.7600\n",
      "Epoch 991/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7393 - val_loss: 0.0055 - val_accuracy: 0.7520\n",
      "Epoch 992/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7285 - val_loss: 0.0055 - val_accuracy: 0.7505\n",
      "Epoch 993/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7333 - val_loss: 0.0055 - val_accuracy: 0.7480\n",
      "Epoch 994/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7268 - val_loss: 0.0055 - val_accuracy: 0.7660\n",
      "Epoch 995/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7370 - val_loss: 0.0055 - val_accuracy: 0.7290\n",
      "Epoch 996/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7385 - val_loss: 0.0055 - val_accuracy: 0.7500\n",
      "Epoch 997/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7390 - val_loss: 0.0055 - val_accuracy: 0.7780\n",
      "Epoch 998/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7443 - val_loss: 0.0055 - val_accuracy: 0.7435\n",
      "Epoch 999/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7365 - val_loss: 0.0055 - val_accuracy: 0.7365\n",
      "Epoch 1000/1000\n",
      "188/188 [==============================] - 0s 564us/step - loss: 0.0054 - accuracy: 0.7293 - val_loss: 0.0055 - val_accuracy: 0.7330\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = \"mse\",\n",
    "              optimizer = \"ADAM\",\n",
    "              metrics = [\"accuracy\"])\n",
    "history = model.fit(x = F_train, y = Q_train, validation_data=(F_val, Q_val),epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "89353f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 286us/step - loss: 0.0053 - accuracy: 0.7255\n"
     ]
    }
   ],
   "source": [
    "#F 학습 후 F accuracy\n",
    "result = model.evaluate(F_test, Q_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "84dc2bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 302us/step - loss: 0.0053 - accuracy: 0.7260\n"
     ]
    }
   ],
   "source": [
    "#F 학습 후 nF accuracy\n",
    "result = model.evaluate(nF_test, Q_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f2fdf1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "188/188 [==============================] - 0s 803us/step - loss: 0.0121 - accuracy: 0.4828 - val_loss: 0.0109 - val_accuracy: 0.5665\n",
      "Epoch 2/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0107 - accuracy: 0.5388 - val_loss: 0.0109 - val_accuracy: 0.5710\n",
      "Epoch 3/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0107 - accuracy: 0.5403 - val_loss: 0.0108 - val_accuracy: 0.5500\n",
      "Epoch 4/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0107 - accuracy: 0.5363 - val_loss: 0.0108 - val_accuracy: 0.5250\n",
      "Epoch 5/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5455 - val_loss: 0.0108 - val_accuracy: 0.5660\n",
      "Epoch 6/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0106 - accuracy: 0.5442 - val_loss: 0.0108 - val_accuracy: 0.5355\n",
      "Epoch 7/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5440 - val_loss: 0.0108 - val_accuracy: 0.5590\n",
      "Epoch 8/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5515 - val_loss: 0.0108 - val_accuracy: 0.5595\n",
      "Epoch 9/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0106 - accuracy: 0.5410 - val_loss: 0.0108 - val_accuracy: 0.5630\n",
      "Epoch 10/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5388 - val_loss: 0.0108 - val_accuracy: 0.5205\n",
      "Epoch 11/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5397 - val_loss: 0.0108 - val_accuracy: 0.5770\n",
      "Epoch 12/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5458 - val_loss: 0.0108 - val_accuracy: 0.5600\n",
      "Epoch 13/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0106 - accuracy: 0.5515 - val_loss: 0.0108 - val_accuracy: 0.5015\n",
      "Epoch 14/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5332 - val_loss: 0.0109 - val_accuracy: 0.5725\n",
      "Epoch 15/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0106 - accuracy: 0.5363 - val_loss: 0.0107 - val_accuracy: 0.5720\n",
      "Epoch 16/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0106 - accuracy: 0.5512 - val_loss: 0.0107 - val_accuracy: 0.5645\n",
      "Epoch 17/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0106 - accuracy: 0.5505 - val_loss: 0.0107 - val_accuracy: 0.5575\n",
      "Epoch 18/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5383 - val_loss: 0.0108 - val_accuracy: 0.5670\n",
      "Epoch 19/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0106 - accuracy: 0.5518 - val_loss: 0.0108 - val_accuracy: 0.5680\n",
      "Epoch 20/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0106 - accuracy: 0.5478 - val_loss: 0.0107 - val_accuracy: 0.5315\n",
      "Epoch 21/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0106 - accuracy: 0.5443 - val_loss: 0.0107 - val_accuracy: 0.5540\n",
      "Epoch 22/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0106 - accuracy: 0.5507 - val_loss: 0.0108 - val_accuracy: 0.5420\n",
      "Epoch 23/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5488 - val_loss: 0.0108 - val_accuracy: 0.5765\n",
      "Epoch 24/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0106 - accuracy: 0.5453 - val_loss: 0.0108 - val_accuracy: 0.5730\n",
      "Epoch 25/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0106 - accuracy: 0.5373 - val_loss: 0.0107 - val_accuracy: 0.5635\n",
      "Epoch 26/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0106 - accuracy: 0.5583 - val_loss: 0.0108 - val_accuracy: 0.5310\n",
      "Epoch 27/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0106 - accuracy: 0.5493 - val_loss: 0.0107 - val_accuracy: 0.5640\n",
      "Epoch 28/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5558 - val_loss: 0.0108 - val_accuracy: 0.5105\n",
      "Epoch 29/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5360 - val_loss: 0.0108 - val_accuracy: 0.5735\n",
      "Epoch 30/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0106 - accuracy: 0.5540 - val_loss: 0.0107 - val_accuracy: 0.5650\n",
      "Epoch 31/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0106 - accuracy: 0.5525 - val_loss: 0.0107 - val_accuracy: 0.5640\n",
      "Epoch 32/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0106 - accuracy: 0.5450 - val_loss: 0.0107 - val_accuracy: 0.5690\n",
      "Epoch 33/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0106 - accuracy: 0.5488 - val_loss: 0.0108 - val_accuracy: 0.5465\n",
      "Epoch 34/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0106 - accuracy: 0.5588 - val_loss: 0.0107 - val_accuracy: 0.5630\n",
      "Epoch 35/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0106 - accuracy: 0.5520 - val_loss: 0.0108 - val_accuracy: 0.5055\n",
      "Epoch 36/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0106 - accuracy: 0.5453 - val_loss: 0.0108 - val_accuracy: 0.5550\n",
      "Epoch 37/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0106 - accuracy: 0.5403 - val_loss: 0.0107 - val_accuracy: 0.5655\n",
      "Epoch 38/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0106 - accuracy: 0.5438 - val_loss: 0.0107 - val_accuracy: 0.5635\n",
      "Epoch 39/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0106 - accuracy: 0.5405 - val_loss: 0.0108 - val_accuracy: 0.5665\n",
      "Epoch 40/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5550 - val_loss: 0.0108 - val_accuracy: 0.5735\n",
      "Epoch 41/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0106 - accuracy: 0.5528 - val_loss: 0.0108 - val_accuracy: 0.5725\n",
      "Epoch 42/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5505 - val_loss: 0.0107 - val_accuracy: 0.5650\n",
      "Epoch 43/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0106 - accuracy: 0.5442 - val_loss: 0.0108 - val_accuracy: 0.5665\n",
      "Epoch 44/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5423 - val_loss: 0.0107 - val_accuracy: 0.5425\n",
      "Epoch 45/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0106 - accuracy: 0.5503 - val_loss: 0.0107 - val_accuracy: 0.5350\n",
      "Epoch 46/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0106 - accuracy: 0.5500 - val_loss: 0.0108 - val_accuracy: 0.5710\n",
      "Epoch 47/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5553 - val_loss: 0.0107 - val_accuracy: 0.5740\n",
      "Epoch 48/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0106 - accuracy: 0.5532 - val_loss: 0.0107 - val_accuracy: 0.5680\n",
      "Epoch 49/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0106 - accuracy: 0.5517 - val_loss: 0.0107 - val_accuracy: 0.5705\n",
      "Epoch 50/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5518 - val_loss: 0.0107 - val_accuracy: 0.5730\n",
      "Epoch 51/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5573 - val_loss: 0.0107 - val_accuracy: 0.5655\n",
      "Epoch 52/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0106 - accuracy: 0.5395 - val_loss: 0.0108 - val_accuracy: 0.5690\n",
      "Epoch 53/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0106 - accuracy: 0.5582 - val_loss: 0.0107 - val_accuracy: 0.5745\n",
      "Epoch 54/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0106 - accuracy: 0.5578 - val_loss: 0.0108 - val_accuracy: 0.5520\n",
      "Epoch 55/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0106 - accuracy: 0.5570 - val_loss: 0.0107 - val_accuracy: 0.5700\n",
      "Epoch 56/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0106 - accuracy: 0.5540 - val_loss: 0.0107 - val_accuracy: 0.5540\n",
      "Epoch 57/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0106 - accuracy: 0.5513 - val_loss: 0.0107 - val_accuracy: 0.5720\n",
      "Epoch 58/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5532 - val_loss: 0.0108 - val_accuracy: 0.5665\n",
      "Epoch 59/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5550 - val_loss: 0.0107 - val_accuracy: 0.5620\n",
      "Epoch 60/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0106 - accuracy: 0.5523 - val_loss: 0.0107 - val_accuracy: 0.5700\n",
      "Epoch 61/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5572 - val_loss: 0.0108 - val_accuracy: 0.5660\n",
      "Epoch 62/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5500 - val_loss: 0.0107 - val_accuracy: 0.5720\n",
      "Epoch 63/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0106 - accuracy: 0.5568 - val_loss: 0.0107 - val_accuracy: 0.5425\n",
      "Epoch 64/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0106 - accuracy: 0.5433 - val_loss: 0.0107 - val_accuracy: 0.5635\n",
      "Epoch 65/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5567 - val_loss: 0.0108 - val_accuracy: 0.5625\n",
      "Epoch 66/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5483 - val_loss: 0.0107 - val_accuracy: 0.5520\n",
      "Epoch 67/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0106 - accuracy: 0.5453 - val_loss: 0.0107 - val_accuracy: 0.5690\n",
      "Epoch 68/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0106 - accuracy: 0.5480 - val_loss: 0.0108 - val_accuracy: 0.5330\n",
      "Epoch 69/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0106 - accuracy: 0.5367 - val_loss: 0.0108 - val_accuracy: 0.5660\n",
      "Epoch 70/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0106 - accuracy: 0.5523 - val_loss: 0.0107 - val_accuracy: 0.5830\n",
      "Epoch 71/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0106 - accuracy: 0.5482 - val_loss: 0.0108 - val_accuracy: 0.5665\n",
      "Epoch 72/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0106 - accuracy: 0.5533 - val_loss: 0.0107 - val_accuracy: 0.5695\n",
      "Epoch 73/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0106 - accuracy: 0.5608 - val_loss: 0.0107 - val_accuracy: 0.5470\n",
      "Epoch 74/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0106 - accuracy: 0.5362 - val_loss: 0.0107 - val_accuracy: 0.5665\n",
      "Epoch 75/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0105 - accuracy: 0.5428 - val_loss: 0.0107 - val_accuracy: 0.5645\n",
      "Epoch 76/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0105 - accuracy: 0.5567 - val_loss: 0.0105 - val_accuracy: 0.5460\n",
      "Epoch 77/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0104 - accuracy: 0.5490 - val_loss: 0.0103 - val_accuracy: 0.5595\n",
      "Epoch 78/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0103 - accuracy: 0.5593 - val_loss: 0.0114 - val_accuracy: 0.5420\n",
      "Epoch 79/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0099 - accuracy: 0.5497 - val_loss: 0.0104 - val_accuracy: 0.4695\n",
      "Epoch 80/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0101 - accuracy: 0.5647 - val_loss: 0.0096 - val_accuracy: 0.5565\n",
      "Epoch 81/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0093 - accuracy: 0.5897 - val_loss: 0.0073 - val_accuracy: 0.6690\n",
      "Epoch 82/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0087 - accuracy: 0.5908 - val_loss: 0.0079 - val_accuracy: 0.6660\n",
      "Epoch 83/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0076 - accuracy: 0.6495 - val_loss: 0.0061 - val_accuracy: 0.7160\n",
      "Epoch 84/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0065 - accuracy: 0.6680 - val_loss: 0.0072 - val_accuracy: 0.6940\n",
      "Epoch 85/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0066 - accuracy: 0.6757 - val_loss: 0.0058 - val_accuracy: 0.7335\n",
      "Epoch 86/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0061 - accuracy: 0.6988 - val_loss: 0.0062 - val_accuracy: 0.6845\n",
      "Epoch 87/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0059 - accuracy: 0.7012 - val_loss: 0.0058 - val_accuracy: 0.7350\n",
      "Epoch 88/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0059 - accuracy: 0.7088 - val_loss: 0.0075 - val_accuracy: 0.6380\n",
      "Epoch 89/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0060 - accuracy: 0.6852 - val_loss: 0.0062 - val_accuracy: 0.6805\n",
      "Epoch 90/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0058 - accuracy: 0.7190 - val_loss: 0.0058 - val_accuracy: 0.6975\n",
      "Epoch 91/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0059 - accuracy: 0.7000 - val_loss: 0.0061 - val_accuracy: 0.7165\n",
      "Epoch 92/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0058 - accuracy: 0.7052 - val_loss: 0.0069 - val_accuracy: 0.6750\n",
      "Epoch 93/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0057 - accuracy: 0.7110 - val_loss: 0.0059 - val_accuracy: 0.6850\n",
      "Epoch 94/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0059 - accuracy: 0.7040 - val_loss: 0.0056 - val_accuracy: 0.7320\n",
      "Epoch 95/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0057 - accuracy: 0.7173 - val_loss: 0.0057 - val_accuracy: 0.7190\n",
      "Epoch 96/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0059 - accuracy: 0.6968 - val_loss: 0.0064 - val_accuracy: 0.6785\n",
      "Epoch 97/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0059 - accuracy: 0.6950 - val_loss: 0.0061 - val_accuracy: 0.6685\n",
      "Epoch 98/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0058 - accuracy: 0.6992 - val_loss: 0.0056 - val_accuracy: 0.7220\n",
      "Epoch 99/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0057 - accuracy: 0.7065 - val_loss: 0.0056 - val_accuracy: 0.7610\n",
      "Epoch 100/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0057 - accuracy: 0.7178 - val_loss: 0.0061 - val_accuracy: 0.6685\n",
      "Epoch 101/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0057 - accuracy: 0.7043 - val_loss: 0.0057 - val_accuracy: 0.7290\n",
      "Epoch 102/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0057 - accuracy: 0.7107 - val_loss: 0.0058 - val_accuracy: 0.7450\n",
      "Epoch 103/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0057 - accuracy: 0.7180 - val_loss: 0.0062 - val_accuracy: 0.6935\n",
      "Epoch 104/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0059 - accuracy: 0.7055 - val_loss: 0.0058 - val_accuracy: 0.7320\n",
      "Epoch 105/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0058 - accuracy: 0.7077 - val_loss: 0.0060 - val_accuracy: 0.7230\n",
      "Epoch 106/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0057 - accuracy: 0.7153 - val_loss: 0.0057 - val_accuracy: 0.6930\n",
      "Epoch 107/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0056 - accuracy: 0.7077 - val_loss: 0.0055 - val_accuracy: 0.7500\n",
      "Epoch 108/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0056 - accuracy: 0.7172 - val_loss: 0.0062 - val_accuracy: 0.6695\n",
      "Epoch 109/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0058 - accuracy: 0.6960 - val_loss: 0.0058 - val_accuracy: 0.7285\n",
      "Epoch 110/1000\n",
      "188/188 [==============================] - 0s 591us/step - loss: 0.0056 - accuracy: 0.7143 - val_loss: 0.0055 - val_accuracy: 0.7445\n",
      "Epoch 111/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0057 - accuracy: 0.7107 - val_loss: 0.0083 - val_accuracy: 0.6570\n",
      "Epoch 112/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0058 - accuracy: 0.7107 - val_loss: 0.0056 - val_accuracy: 0.7470\n",
      "Epoch 113/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0057 - accuracy: 0.7235 - val_loss: 0.0056 - val_accuracy: 0.7145\n",
      "Epoch 114/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0057 - accuracy: 0.7033 - val_loss: 0.0056 - val_accuracy: 0.7390\n",
      "Epoch 115/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0057 - accuracy: 0.7168 - val_loss: 0.0057 - val_accuracy: 0.7235\n",
      "Epoch 116/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0056 - accuracy: 0.7172 - val_loss: 0.0056 - val_accuracy: 0.7225\n",
      "Epoch 117/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0056 - accuracy: 0.7185 - val_loss: 0.0062 - val_accuracy: 0.6545\n",
      "Epoch 118/1000\n",
      "188/188 [==============================] - 0s 569us/step - loss: 0.0057 - accuracy: 0.6872 - val_loss: 0.0060 - val_accuracy: 0.7330\n",
      "Epoch 119/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0057 - accuracy: 0.7212 - val_loss: 0.0056 - val_accuracy: 0.7285\n",
      "Epoch 120/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0056 - accuracy: 0.7032 - val_loss: 0.0072 - val_accuracy: 0.6525\n",
      "Epoch 121/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0056 - accuracy: 0.7138 - val_loss: 0.0055 - val_accuracy: 0.7300\n",
      "Epoch 122/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0056 - accuracy: 0.7125 - val_loss: 0.0055 - val_accuracy: 0.7270\n",
      "Epoch 123/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0056 - accuracy: 0.7137 - val_loss: 0.0055 - val_accuracy: 0.7595\n",
      "Epoch 124/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0055 - accuracy: 0.7297 - val_loss: 0.0057 - val_accuracy: 0.7405\n",
      "Epoch 125/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0055 - accuracy: 0.7233 - val_loss: 0.0057 - val_accuracy: 0.7410\n",
      "Epoch 126/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0056 - accuracy: 0.7095 - val_loss: 0.0062 - val_accuracy: 0.7105\n",
      "Epoch 127/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0059 - accuracy: 0.7042 - val_loss: 0.0059 - val_accuracy: 0.7320\n",
      "Epoch 128/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0056 - accuracy: 0.7158 - val_loss: 0.0056 - val_accuracy: 0.6990\n",
      "Epoch 129/1000\n",
      "188/188 [==============================] - 0s 569us/step - loss: 0.0056 - accuracy: 0.7098 - val_loss: 0.0056 - val_accuracy: 0.7090\n",
      "Epoch 130/1000\n",
      "188/188 [==============================] - 0s 585us/step - loss: 0.0056 - accuracy: 0.7145 - val_loss: 0.0056 - val_accuracy: 0.7325\n",
      "Epoch 131/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0057 - accuracy: 0.7115 - val_loss: 0.0056 - val_accuracy: 0.7435\n",
      "Epoch 132/1000\n",
      "188/188 [==============================] - 0s 569us/step - loss: 0.0055 - accuracy: 0.7350 - val_loss: 0.0055 - val_accuracy: 0.7380\n",
      "Epoch 133/1000\n",
      "188/188 [==============================] - 0s 612us/step - loss: 0.0056 - accuracy: 0.7170 - val_loss: 0.0057 - val_accuracy: 0.7515\n",
      "Epoch 134/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0056 - accuracy: 0.7075 - val_loss: 0.0057 - val_accuracy: 0.7110\n",
      "Epoch 135/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0056 - accuracy: 0.7158 - val_loss: 0.0061 - val_accuracy: 0.6855\n",
      "Epoch 136/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0056 - accuracy: 0.7082 - val_loss: 0.0060 - val_accuracy: 0.7145\n",
      "Epoch 137/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0055 - accuracy: 0.7208 - val_loss: 0.0056 - val_accuracy: 0.7565\n",
      "Epoch 138/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0056 - accuracy: 0.7228 - val_loss: 0.0056 - val_accuracy: 0.7470\n",
      "Epoch 139/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0056 - accuracy: 0.7152 - val_loss: 0.0057 - val_accuracy: 0.6860\n",
      "Epoch 140/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0055 - accuracy: 0.7187 - val_loss: 0.0057 - val_accuracy: 0.7145\n",
      "Epoch 141/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0056 - accuracy: 0.7112 - val_loss: 0.0055 - val_accuracy: 0.7540\n",
      "Epoch 142/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0055 - accuracy: 0.7133 - val_loss: 0.0057 - val_accuracy: 0.7405\n",
      "Epoch 143/1000\n",
      "188/188 [==============================] - 0s 569us/step - loss: 0.0055 - accuracy: 0.7270 - val_loss: 0.0056 - val_accuracy: 0.7360\n",
      "Epoch 144/1000\n",
      "188/188 [==============================] - 0s 575us/step - loss: 0.0056 - accuracy: 0.7193 - val_loss: 0.0055 - val_accuracy: 0.7700\n",
      "Epoch 145/1000\n",
      "188/188 [==============================] - 0s 564us/step - loss: 0.0055 - accuracy: 0.7232 - val_loss: 0.0055 - val_accuracy: 0.7520\n",
      "Epoch 146/1000\n",
      "188/188 [==============================] - 0s 564us/step - loss: 0.0055 - accuracy: 0.7058 - val_loss: 0.0056 - val_accuracy: 0.7285\n",
      "Epoch 147/1000\n",
      "188/188 [==============================] - 0s 575us/step - loss: 0.0055 - accuracy: 0.7190 - val_loss: 0.0058 - val_accuracy: 0.7525\n",
      "Epoch 148/1000\n",
      "188/188 [==============================] - 0s 580us/step - loss: 0.0056 - accuracy: 0.7313 - val_loss: 0.0056 - val_accuracy: 0.6960\n",
      "Epoch 149/1000\n",
      "188/188 [==============================] - 0s 569us/step - loss: 0.0055 - accuracy: 0.7103 - val_loss: 0.0056 - val_accuracy: 0.7170\n",
      "Epoch 150/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0056 - accuracy: 0.7177 - val_loss: 0.0060 - val_accuracy: 0.7270\n",
      "Epoch 151/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0056 - accuracy: 0.7098 - val_loss: 0.0055 - val_accuracy: 0.7625\n",
      "Epoch 152/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0056 - accuracy: 0.7217 - val_loss: 0.0062 - val_accuracy: 0.6955\n",
      "Epoch 153/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0055 - accuracy: 0.7258 - val_loss: 0.0062 - val_accuracy: 0.6665\n",
      "Epoch 154/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0055 - accuracy: 0.7247 - val_loss: 0.0055 - val_accuracy: 0.7685\n",
      "Epoch 155/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0055 - accuracy: 0.7295 - val_loss: 0.0056 - val_accuracy: 0.7215\n",
      "Epoch 156/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7202 - val_loss: 0.0055 - val_accuracy: 0.7225\n",
      "Epoch 157/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0056 - accuracy: 0.7188 - val_loss: 0.0057 - val_accuracy: 0.7250\n",
      "Epoch 158/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7217 - val_loss: 0.0056 - val_accuracy: 0.7300\n",
      "Epoch 159/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7257 - val_loss: 0.0055 - val_accuracy: 0.7530\n",
      "Epoch 160/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0056 - accuracy: 0.7138 - val_loss: 0.0055 - val_accuracy: 0.7160\n",
      "Epoch 161/1000\n",
      "188/188 [==============================] - 0s 622us/step - loss: 0.0055 - accuracy: 0.7218 - val_loss: 0.0056 - val_accuracy: 0.7190\n",
      "Epoch 162/1000\n",
      "188/188 [==============================] - 0s 585us/step - loss: 0.0055 - accuracy: 0.7193 - val_loss: 0.0055 - val_accuracy: 0.7320\n",
      "Epoch 163/1000\n",
      "188/188 [==============================] - 0s 617us/step - loss: 0.0055 - accuracy: 0.7242 - val_loss: 0.0056 - val_accuracy: 0.7380\n",
      "Epoch 164/1000\n",
      "188/188 [==============================] - 0s 564us/step - loss: 0.0055 - accuracy: 0.7223 - val_loss: 0.0055 - val_accuracy: 0.7195\n",
      "Epoch 165/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0055 - accuracy: 0.7138 - val_loss: 0.0058 - val_accuracy: 0.7380\n",
      "Epoch 166/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0055 - accuracy: 0.7153 - val_loss: 0.0058 - val_accuracy: 0.7310\n",
      "Epoch 167/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0055 - accuracy: 0.7255 - val_loss: 0.0055 - val_accuracy: 0.7560\n",
      "Epoch 168/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0055 - accuracy: 0.7298 - val_loss: 0.0057 - val_accuracy: 0.7205\n",
      "Epoch 169/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0056 - accuracy: 0.7093 - val_loss: 0.0069 - val_accuracy: 0.6360\n",
      "Epoch 170/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0055 - accuracy: 0.7155 - val_loss: 0.0057 - val_accuracy: 0.7165\n",
      "Epoch 171/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0056 - accuracy: 0.7097 - val_loss: 0.0057 - val_accuracy: 0.7400\n",
      "Epoch 172/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0055 - accuracy: 0.7357 - val_loss: 0.0055 - val_accuracy: 0.7585\n",
      "Epoch 173/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0055 - accuracy: 0.7277 - val_loss: 0.0055 - val_accuracy: 0.7595\n",
      "Epoch 174/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0055 - accuracy: 0.7330 - val_loss: 0.0055 - val_accuracy: 0.7220\n",
      "Epoch 175/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0055 - accuracy: 0.7233 - val_loss: 0.0055 - val_accuracy: 0.7600\n",
      "Epoch 176/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0055 - accuracy: 0.7293 - val_loss: 0.0055 - val_accuracy: 0.7540\n",
      "Epoch 177/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0055 - accuracy: 0.7147 - val_loss: 0.0060 - val_accuracy: 0.7250\n",
      "Epoch 178/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0056 - accuracy: 0.7110 - val_loss: 0.0055 - val_accuracy: 0.7625\n",
      "Epoch 179/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0055 - accuracy: 0.7325 - val_loss: 0.0057 - val_accuracy: 0.7335\n",
      "Epoch 180/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7175 - val_loss: 0.0056 - val_accuracy: 0.7430\n",
      "Epoch 181/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7178 - val_loss: 0.0055 - val_accuracy: 0.7195\n",
      "Epoch 182/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7272 - val_loss: 0.0055 - val_accuracy: 0.7575\n",
      "Epoch 183/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0055 - accuracy: 0.7307 - val_loss: 0.0056 - val_accuracy: 0.7245\n",
      "Epoch 184/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0055 - accuracy: 0.7175 - val_loss: 0.0056 - val_accuracy: 0.7550\n",
      "Epoch 185/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0055 - accuracy: 0.7287 - val_loss: 0.0056 - val_accuracy: 0.7045\n",
      "Epoch 186/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0055 - accuracy: 0.7235 - val_loss: 0.0055 - val_accuracy: 0.7435\n",
      "Epoch 187/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7312 - val_loss: 0.0055 - val_accuracy: 0.7360\n",
      "Epoch 188/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7232 - val_loss: 0.0055 - val_accuracy: 0.7640\n",
      "Epoch 189/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0056 - accuracy: 0.7093 - val_loss: 0.0056 - val_accuracy: 0.7540\n",
      "Epoch 190/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7257 - val_loss: 0.0055 - val_accuracy: 0.7730\n",
      "Epoch 191/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0055 - accuracy: 0.7333 - val_loss: 0.0055 - val_accuracy: 0.7555\n",
      "Epoch 192/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7275 - val_loss: 0.0055 - val_accuracy: 0.7610\n",
      "Epoch 193/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7307 - val_loss: 0.0055 - val_accuracy: 0.7580\n",
      "Epoch 194/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0055 - accuracy: 0.7340 - val_loss: 0.0055 - val_accuracy: 0.7040\n",
      "Epoch 195/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7182 - val_loss: 0.0055 - val_accuracy: 0.7235\n",
      "Epoch 196/1000\n",
      "188/188 [==============================] - 0s 569us/step - loss: 0.0054 - accuracy: 0.7288 - val_loss: 0.0055 - val_accuracy: 0.7520\n",
      "Epoch 197/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0056 - accuracy: 0.7207 - val_loss: 0.0055 - val_accuracy: 0.7460\n",
      "Epoch 198/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0055 - accuracy: 0.7270 - val_loss: 0.0055 - val_accuracy: 0.7175\n",
      "Epoch 199/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0055 - accuracy: 0.7200 - val_loss: 0.0056 - val_accuracy: 0.7545\n",
      "Epoch 200/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7290 - val_loss: 0.0055 - val_accuracy: 0.7515\n",
      "Epoch 201/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7360 - val_loss: 0.0055 - val_accuracy: 0.7340\n",
      "Epoch 202/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7193 - val_loss: 0.0055 - val_accuracy: 0.7515\n",
      "Epoch 203/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0055 - accuracy: 0.7240 - val_loss: 0.0056 - val_accuracy: 0.7495\n",
      "Epoch 204/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0055 - accuracy: 0.7330 - val_loss: 0.0055 - val_accuracy: 0.7115\n",
      "Epoch 205/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7123 - val_loss: 0.0055 - val_accuracy: 0.7700\n",
      "Epoch 206/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7312 - val_loss: 0.0055 - val_accuracy: 0.7725\n",
      "Epoch 207/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0055 - accuracy: 0.7250 - val_loss: 0.0055 - val_accuracy: 0.7655\n",
      "Epoch 208/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0055 - accuracy: 0.7230 - val_loss: 0.0056 - val_accuracy: 0.7195\n",
      "Epoch 209/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7282 - val_loss: 0.0055 - val_accuracy: 0.7520\n",
      "Epoch 210/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0055 - accuracy: 0.7173 - val_loss: 0.0055 - val_accuracy: 0.7670\n",
      "Epoch 211/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7370 - val_loss: 0.0056 - val_accuracy: 0.6995\n",
      "Epoch 212/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0055 - accuracy: 0.7280 - val_loss: 0.0055 - val_accuracy: 0.7290\n",
      "Epoch 213/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7135 - val_loss: 0.0055 - val_accuracy: 0.7720\n",
      "Epoch 214/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7382 - val_loss: 0.0055 - val_accuracy: 0.7655\n",
      "Epoch 215/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0055 - accuracy: 0.7110 - val_loss: 0.0055 - val_accuracy: 0.7745\n",
      "Epoch 216/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0055 - accuracy: 0.7203 - val_loss: 0.0055 - val_accuracy: 0.7730\n",
      "Epoch 217/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0055 - accuracy: 0.7382 - val_loss: 0.0056 - val_accuracy: 0.7340\n",
      "Epoch 218/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7182 - val_loss: 0.0056 - val_accuracy: 0.7695\n",
      "Epoch 219/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7428 - val_loss: 0.0055 - val_accuracy: 0.7010\n",
      "Epoch 220/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7187 - val_loss: 0.0055 - val_accuracy: 0.7515\n",
      "Epoch 221/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7337 - val_loss: 0.0055 - val_accuracy: 0.7385\n",
      "Epoch 222/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7342 - val_loss: 0.0057 - val_accuracy: 0.7215\n",
      "Epoch 223/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7228 - val_loss: 0.0056 - val_accuracy: 0.7290\n",
      "Epoch 224/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7323 - val_loss: 0.0056 - val_accuracy: 0.7285\n",
      "Epoch 225/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0055 - accuracy: 0.7187 - val_loss: 0.0055 - val_accuracy: 0.7565\n",
      "Epoch 226/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7253 - val_loss: 0.0055 - val_accuracy: 0.7625\n",
      "Epoch 227/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7293 - val_loss: 0.0055 - val_accuracy: 0.7555\n",
      "Epoch 228/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7365 - val_loss: 0.0055 - val_accuracy: 0.7505\n",
      "Epoch 229/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7183 - val_loss: 0.0055 - val_accuracy: 0.7585\n",
      "Epoch 230/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7315 - val_loss: 0.0055 - val_accuracy: 0.7645\n",
      "Epoch 231/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0055 - accuracy: 0.7293 - val_loss: 0.0056 - val_accuracy: 0.7365\n",
      "Epoch 232/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0055 - accuracy: 0.7158 - val_loss: 0.0055 - val_accuracy: 0.7490\n",
      "Epoch 233/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7247 - val_loss: 0.0055 - val_accuracy: 0.7250\n",
      "Epoch 234/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7318 - val_loss: 0.0056 - val_accuracy: 0.7165\n",
      "Epoch 235/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7300 - val_loss: 0.0055 - val_accuracy: 0.7250\n",
      "Epoch 236/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7257 - val_loss: 0.0055 - val_accuracy: 0.7540\n",
      "Epoch 237/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7245 - val_loss: 0.0055 - val_accuracy: 0.7700\n",
      "Epoch 238/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7335 - val_loss: 0.0055 - val_accuracy: 0.7035\n",
      "Epoch 239/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7208 - val_loss: 0.0055 - val_accuracy: 0.7655\n",
      "Epoch 240/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7247 - val_loss: 0.0055 - val_accuracy: 0.7600\n",
      "Epoch 241/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7343 - val_loss: 0.0055 - val_accuracy: 0.7325\n",
      "Epoch 242/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7287 - val_loss: 0.0055 - val_accuracy: 0.7400\n",
      "Epoch 243/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7190 - val_loss: 0.0055 - val_accuracy: 0.7710\n",
      "Epoch 244/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7447 - val_loss: 0.0055 - val_accuracy: 0.7250\n",
      "Epoch 245/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7303 - val_loss: 0.0055 - val_accuracy: 0.7380\n",
      "Epoch 246/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0055 - accuracy: 0.7157 - val_loss: 0.0055 - val_accuracy: 0.7415\n",
      "Epoch 247/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7248 - val_loss: 0.0055 - val_accuracy: 0.7665\n",
      "Epoch 248/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7410 - val_loss: 0.0055 - val_accuracy: 0.7190\n",
      "Epoch 249/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7220 - val_loss: 0.0055 - val_accuracy: 0.7520\n",
      "Epoch 250/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7262 - val_loss: 0.0055 - val_accuracy: 0.7470\n",
      "Epoch 251/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7285 - val_loss: 0.0056 - val_accuracy: 0.7080\n",
      "Epoch 252/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0055 - accuracy: 0.7270 - val_loss: 0.0059 - val_accuracy: 0.7330\n",
      "Epoch 253/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0055 - accuracy: 0.7330 - val_loss: 0.0056 - val_accuracy: 0.7015\n",
      "Epoch 254/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7297 - val_loss: 0.0055 - val_accuracy: 0.7415\n",
      "Epoch 255/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7260 - val_loss: 0.0055 - val_accuracy: 0.7695\n",
      "Epoch 256/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0054 - accuracy: 0.7298 - val_loss: 0.0055 - val_accuracy: 0.7665\n",
      "Epoch 257/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7247 - val_loss: 0.0055 - val_accuracy: 0.7580\n",
      "Epoch 258/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0055 - accuracy: 0.7223 - val_loss: 0.0056 - val_accuracy: 0.7590\n",
      "Epoch 259/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7460 - val_loss: 0.0055 - val_accuracy: 0.7110\n",
      "Epoch 260/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7265 - val_loss: 0.0055 - val_accuracy: 0.7680\n",
      "Epoch 261/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7340 - val_loss: 0.0055 - val_accuracy: 0.7150\n",
      "Epoch 262/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7242 - val_loss: 0.0055 - val_accuracy: 0.7620\n",
      "Epoch 263/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7372 - val_loss: 0.0055 - val_accuracy: 0.7385\n",
      "Epoch 264/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7313 - val_loss: 0.0055 - val_accuracy: 0.7150\n",
      "Epoch 265/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7190 - val_loss: 0.0055 - val_accuracy: 0.7425\n",
      "Epoch 266/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7217 - val_loss: 0.0055 - val_accuracy: 0.7355\n",
      "Epoch 267/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7378 - val_loss: 0.0055 - val_accuracy: 0.7365\n",
      "Epoch 268/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7270 - val_loss: 0.0056 - val_accuracy: 0.7625\n",
      "Epoch 269/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7455 - val_loss: 0.0055 - val_accuracy: 0.7225\n",
      "Epoch 270/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0055 - accuracy: 0.7067 - val_loss: 0.0055 - val_accuracy: 0.7590\n",
      "Epoch 271/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7233 - val_loss: 0.0055 - val_accuracy: 0.7390\n",
      "Epoch 272/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7317 - val_loss: 0.0055 - val_accuracy: 0.7520\n",
      "Epoch 273/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7273 - val_loss: 0.0055 - val_accuracy: 0.7370\n",
      "Epoch 274/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7308 - val_loss: 0.0055 - val_accuracy: 0.7475\n",
      "Epoch 275/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7252 - val_loss: 0.0055 - val_accuracy: 0.7140\n",
      "Epoch 276/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7400 - val_loss: 0.0055 - val_accuracy: 0.7415\n",
      "Epoch 277/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7223 - val_loss: 0.0055 - val_accuracy: 0.7350\n",
      "Epoch 278/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7315 - val_loss: 0.0055 - val_accuracy: 0.7200\n",
      "Epoch 279/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7390 - val_loss: 0.0055 - val_accuracy: 0.7030\n",
      "Epoch 280/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7165 - val_loss: 0.0055 - val_accuracy: 0.7500\n",
      "Epoch 281/1000\n",
      "188/188 [==============================] - 0s 557us/step - loss: 0.0054 - accuracy: 0.7313 - val_loss: 0.0055 - val_accuracy: 0.7430\n",
      "Epoch 282/1000\n",
      "188/188 [==============================] - 0s 566us/step - loss: 0.0054 - accuracy: 0.7292 - val_loss: 0.0055 - val_accuracy: 0.7425\n",
      "Epoch 283/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7238 - val_loss: 0.0055 - val_accuracy: 0.7695\n",
      "Epoch 284/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7307 - val_loss: 0.0055 - val_accuracy: 0.7595\n",
      "Epoch 285/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7335 - val_loss: 0.0055 - val_accuracy: 0.7695\n",
      "Epoch 286/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7308 - val_loss: 0.0057 - val_accuracy: 0.7505\n",
      "Epoch 287/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0055 - accuracy: 0.7368 - val_loss: 0.0055 - val_accuracy: 0.7430\n",
      "Epoch 288/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7218 - val_loss: 0.0056 - val_accuracy: 0.7515\n",
      "Epoch 289/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7417 - val_loss: 0.0055 - val_accuracy: 0.7135\n",
      "Epoch 290/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7285 - val_loss: 0.0055 - val_accuracy: 0.7400\n",
      "Epoch 291/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7402 - val_loss: 0.0055 - val_accuracy: 0.7380\n",
      "Epoch 292/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7252 - val_loss: 0.0055 - val_accuracy: 0.7605\n",
      "Epoch 293/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7323 - val_loss: 0.0055 - val_accuracy: 0.7435\n",
      "Epoch 294/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7432 - val_loss: 0.0055 - val_accuracy: 0.7130\n",
      "Epoch 295/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7193 - val_loss: 0.0055 - val_accuracy: 0.7645\n",
      "Epoch 296/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7343 - val_loss: 0.0055 - val_accuracy: 0.7535\n",
      "Epoch 297/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7240 - val_loss: 0.0055 - val_accuracy: 0.7745\n",
      "Epoch 298/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7450 - val_loss: 0.0055 - val_accuracy: 0.7330\n",
      "Epoch 299/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7283 - val_loss: 0.0055 - val_accuracy: 0.7350\n",
      "Epoch 300/1000\n",
      "188/188 [==============================] - 0s 564us/step - loss: 0.0054 - accuracy: 0.7350 - val_loss: 0.0055 - val_accuracy: 0.7325\n",
      "Epoch 301/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7290 - val_loss: 0.0055 - val_accuracy: 0.7090\n",
      "Epoch 302/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7180 - val_loss: 0.0055 - val_accuracy: 0.7640\n",
      "Epoch 303/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0055 - accuracy: 0.7393 - val_loss: 0.0055 - val_accuracy: 0.7475\n",
      "Epoch 304/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7363 - val_loss: 0.0055 - val_accuracy: 0.7205\n",
      "Epoch 305/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7268 - val_loss: 0.0055 - val_accuracy: 0.7450\n",
      "Epoch 306/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7273 - val_loss: 0.0055 - val_accuracy: 0.7640\n",
      "Epoch 307/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7427 - val_loss: 0.0055 - val_accuracy: 0.7245\n",
      "Epoch 308/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7265 - val_loss: 0.0055 - val_accuracy: 0.7535\n",
      "Epoch 309/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7335 - val_loss: 0.0055 - val_accuracy: 0.7640\n",
      "Epoch 310/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7322 - val_loss: 0.0055 - val_accuracy: 0.7195\n",
      "Epoch 311/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7260 - val_loss: 0.0055 - val_accuracy: 0.7155\n",
      "Epoch 312/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7320 - val_loss: 0.0055 - val_accuracy: 0.7620\n",
      "Epoch 313/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7368 - val_loss: 0.0055 - val_accuracy: 0.7330\n",
      "Epoch 314/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7267 - val_loss: 0.0055 - val_accuracy: 0.7670\n",
      "Epoch 315/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7327 - val_loss: 0.0055 - val_accuracy: 0.7695\n",
      "Epoch 316/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7357 - val_loss: 0.0055 - val_accuracy: 0.7065\n",
      "Epoch 317/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7290 - val_loss: 0.0055 - val_accuracy: 0.7690\n",
      "Epoch 318/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7307 - val_loss: 0.0055 - val_accuracy: 0.7645\n",
      "Epoch 319/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7358 - val_loss: 0.0055 - val_accuracy: 0.7685\n",
      "Epoch 320/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7295 - val_loss: 0.0056 - val_accuracy: 0.7415\n",
      "Epoch 321/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7435 - val_loss: 0.0056 - val_accuracy: 0.7120\n",
      "Epoch 322/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7238 - val_loss: 0.0055 - val_accuracy: 0.7685\n",
      "Epoch 323/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7360 - val_loss: 0.0055 - val_accuracy: 0.7370\n",
      "Epoch 324/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7413 - val_loss: 0.0055 - val_accuracy: 0.7210\n",
      "Epoch 325/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7300 - val_loss: 0.0055 - val_accuracy: 0.7465\n",
      "Epoch 326/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7350 - val_loss: 0.0055 - val_accuracy: 0.7385\n",
      "Epoch 327/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7247 - val_loss: 0.0055 - val_accuracy: 0.7755\n",
      "Epoch 328/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7273 - val_loss: 0.0055 - val_accuracy: 0.7610\n",
      "Epoch 329/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7212 - val_loss: 0.0055 - val_accuracy: 0.7600\n",
      "Epoch 330/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7400 - val_loss: 0.0055 - val_accuracy: 0.7260\n",
      "Epoch 331/1000\n",
      "188/188 [==============================] - 0s 564us/step - loss: 0.0055 - accuracy: 0.7172 - val_loss: 0.0055 - val_accuracy: 0.7630\n",
      "Epoch 332/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7465 - val_loss: 0.0055 - val_accuracy: 0.7255\n",
      "Epoch 333/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7227 - val_loss: 0.0055 - val_accuracy: 0.7455\n",
      "Epoch 334/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7362 - val_loss: 0.0055 - val_accuracy: 0.7135\n",
      "Epoch 335/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7283 - val_loss: 0.0055 - val_accuracy: 0.7735\n",
      "Epoch 336/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7273 - val_loss: 0.0055 - val_accuracy: 0.7635\n",
      "Epoch 337/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7353 - val_loss: 0.0055 - val_accuracy: 0.7345\n",
      "Epoch 338/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7237 - val_loss: 0.0055 - val_accuracy: 0.7675\n",
      "Epoch 339/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7345 - val_loss: 0.0055 - val_accuracy: 0.7590\n",
      "Epoch 340/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7417 - val_loss: 0.0055 - val_accuracy: 0.7405\n",
      "Epoch 341/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7307 - val_loss: 0.0055 - val_accuracy: 0.7335\n",
      "Epoch 342/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7218 - val_loss: 0.0055 - val_accuracy: 0.7540\n",
      "Epoch 343/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7335 - val_loss: 0.0056 - val_accuracy: 0.7545\n",
      "Epoch 344/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7278 - val_loss: 0.0055 - val_accuracy: 0.7315\n",
      "Epoch 345/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7408 - val_loss: 0.0055 - val_accuracy: 0.7605\n",
      "Epoch 346/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7452 - val_loss: 0.0055 - val_accuracy: 0.7280\n",
      "Epoch 347/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7283 - val_loss: 0.0057 - val_accuracy: 0.7100\n",
      "Epoch 348/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7183 - val_loss: 0.0055 - val_accuracy: 0.7780\n",
      "Epoch 349/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7215 - val_loss: 0.0055 - val_accuracy: 0.7695\n",
      "Epoch 350/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7413 - val_loss: 0.0055 - val_accuracy: 0.7565\n",
      "Epoch 351/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7315 - val_loss: 0.0055 - val_accuracy: 0.7670\n",
      "Epoch 352/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7300 - val_loss: 0.0055 - val_accuracy: 0.7760\n",
      "Epoch 353/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7377 - val_loss: 0.0056 - val_accuracy: 0.7515\n",
      "Epoch 354/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7368 - val_loss: 0.0055 - val_accuracy: 0.7390\n",
      "Epoch 355/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7237 - val_loss: 0.0055 - val_accuracy: 0.7725\n",
      "Epoch 356/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7343 - val_loss: 0.0055 - val_accuracy: 0.7630\n",
      "Epoch 357/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7433 - val_loss: 0.0055 - val_accuracy: 0.7340\n",
      "Epoch 358/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7177 - val_loss: 0.0055 - val_accuracy: 0.7640\n",
      "Epoch 359/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7342 - val_loss: 0.0055 - val_accuracy: 0.7670\n",
      "Epoch 360/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0055 - accuracy: 0.7257 - val_loss: 0.0055 - val_accuracy: 0.7510\n",
      "Epoch 361/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7297 - val_loss: 0.0055 - val_accuracy: 0.7510\n",
      "Epoch 362/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0054 - accuracy: 0.7310 - val_loss: 0.0055 - val_accuracy: 0.7615\n",
      "Epoch 363/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7385 - val_loss: 0.0055 - val_accuracy: 0.7625\n",
      "Epoch 364/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7388 - val_loss: 0.0055 - val_accuracy: 0.7255\n",
      "Epoch 365/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7247 - val_loss: 0.0055 - val_accuracy: 0.7550\n",
      "Epoch 366/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7303 - val_loss: 0.0055 - val_accuracy: 0.7570\n",
      "Epoch 367/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7365 - val_loss: 0.0055 - val_accuracy: 0.7465\n",
      "Epoch 368/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7320 - val_loss: 0.0055 - val_accuracy: 0.7425\n",
      "Epoch 369/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7293 - val_loss: 0.0055 - val_accuracy: 0.7445\n",
      "Epoch 370/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7257 - val_loss: 0.0055 - val_accuracy: 0.7780\n",
      "Epoch 371/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7365 - val_loss: 0.0055 - val_accuracy: 0.7630\n",
      "Epoch 372/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7447 - val_loss: 0.0055 - val_accuracy: 0.7705\n",
      "Epoch 373/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7265 - val_loss: 0.0055 - val_accuracy: 0.7490\n",
      "Epoch 374/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7322 - val_loss: 0.0055 - val_accuracy: 0.7210\n",
      "Epoch 375/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7283 - val_loss: 0.0055 - val_accuracy: 0.7310\n",
      "Epoch 376/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7340 - val_loss: 0.0055 - val_accuracy: 0.7410\n",
      "Epoch 377/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7275 - val_loss: 0.0055 - val_accuracy: 0.7660\n",
      "Epoch 378/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7265 - val_loss: 0.0055 - val_accuracy: 0.7740\n",
      "Epoch 379/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7410 - val_loss: 0.0057 - val_accuracy: 0.7245\n",
      "Epoch 380/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7303 - val_loss: 0.0055 - val_accuracy: 0.7540\n",
      "Epoch 381/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7407 - val_loss: 0.0055 - val_accuracy: 0.7270\n",
      "Epoch 382/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7198 - val_loss: 0.0055 - val_accuracy: 0.7765\n",
      "Epoch 383/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7445 - val_loss: 0.0055 - val_accuracy: 0.7650\n",
      "Epoch 384/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7383 - val_loss: 0.0056 - val_accuracy: 0.7075\n",
      "Epoch 385/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7128 - val_loss: 0.0055 - val_accuracy: 0.7600\n",
      "Epoch 386/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7333 - val_loss: 0.0055 - val_accuracy: 0.7725\n",
      "Epoch 387/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7442 - val_loss: 0.0055 - val_accuracy: 0.7220\n",
      "Epoch 388/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7277 - val_loss: 0.0055 - val_accuracy: 0.7480\n",
      "Epoch 389/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7240 - val_loss: 0.0055 - val_accuracy: 0.7425\n",
      "Epoch 390/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7387 - val_loss: 0.0055 - val_accuracy: 0.7505\n",
      "Epoch 391/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7392 - val_loss: 0.0055 - val_accuracy: 0.7670\n",
      "Epoch 392/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7285 - val_loss: 0.0055 - val_accuracy: 0.7655\n",
      "Epoch 393/1000\n",
      "188/188 [==============================] - 0s 569us/step - loss: 0.0054 - accuracy: 0.7250 - val_loss: 0.0055 - val_accuracy: 0.7705\n",
      "Epoch 394/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7355 - val_loss: 0.0055 - val_accuracy: 0.7390\n",
      "Epoch 395/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7305 - val_loss: 0.0055 - val_accuracy: 0.7490\n",
      "Epoch 396/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7313 - val_loss: 0.0055 - val_accuracy: 0.7495\n",
      "Epoch 397/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7328 - val_loss: 0.0055 - val_accuracy: 0.7600\n",
      "Epoch 398/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7427 - val_loss: 0.0056 - val_accuracy: 0.7050\n",
      "Epoch 399/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7235 - val_loss: 0.0055 - val_accuracy: 0.7690\n",
      "Epoch 400/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7438 - val_loss: 0.0055 - val_accuracy: 0.7540\n",
      "Epoch 401/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7278 - val_loss: 0.0055 - val_accuracy: 0.7330\n",
      "Epoch 402/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7297 - val_loss: 0.0055 - val_accuracy: 0.7495\n",
      "Epoch 403/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7487 - val_loss: 0.0055 - val_accuracy: 0.7095\n",
      "Epoch 404/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7215 - val_loss: 0.0055 - val_accuracy: 0.7495\n",
      "Epoch 405/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7248 - val_loss: 0.0055 - val_accuracy: 0.7160\n",
      "Epoch 406/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7227 - val_loss: 0.0057 - val_accuracy: 0.7405\n",
      "Epoch 407/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7320 - val_loss: 0.0055 - val_accuracy: 0.7320\n",
      "Epoch 408/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7438 - val_loss: 0.0055 - val_accuracy: 0.7425\n",
      "Epoch 409/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7330 - val_loss: 0.0055 - val_accuracy: 0.7350\n",
      "Epoch 410/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7313 - val_loss: 0.0055 - val_accuracy: 0.7385\n",
      "Epoch 411/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7413 - val_loss: 0.0055 - val_accuracy: 0.7160\n",
      "Epoch 412/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7108 - val_loss: 0.0055 - val_accuracy: 0.7530\n",
      "Epoch 413/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7325 - val_loss: 0.0055 - val_accuracy: 0.7660\n",
      "Epoch 414/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7440 - val_loss: 0.0055 - val_accuracy: 0.7440\n",
      "Epoch 415/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7255 - val_loss: 0.0055 - val_accuracy: 0.7495\n",
      "Epoch 416/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7380 - val_loss: 0.0055 - val_accuracy: 0.7500\n",
      "Epoch 417/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7248 - val_loss: 0.0055 - val_accuracy: 0.7470\n",
      "Epoch 418/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7427 - val_loss: 0.0055 - val_accuracy: 0.7445\n",
      "Epoch 419/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7275 - val_loss: 0.0055 - val_accuracy: 0.7440\n",
      "Epoch 420/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7367 - val_loss: 0.0057 - val_accuracy: 0.7035\n",
      "Epoch 421/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7127 - val_loss: 0.0055 - val_accuracy: 0.7575\n",
      "Epoch 422/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7218 - val_loss: 0.0055 - val_accuracy: 0.7560\n",
      "Epoch 423/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7343 - val_loss: 0.0055 - val_accuracy: 0.7405\n",
      "Epoch 424/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7338 - val_loss: 0.0055 - val_accuracy: 0.7575\n",
      "Epoch 425/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7375 - val_loss: 0.0055 - val_accuracy: 0.7505\n",
      "Epoch 426/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7327 - val_loss: 0.0055 - val_accuracy: 0.7620\n",
      "Epoch 427/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7322 - val_loss: 0.0055 - val_accuracy: 0.7425\n",
      "Epoch 428/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7273 - val_loss: 0.0055 - val_accuracy: 0.7700\n",
      "Epoch 429/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7295 - val_loss: 0.0055 - val_accuracy: 0.7725\n",
      "Epoch 430/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0055 - accuracy: 0.7335 - val_loss: 0.0055 - val_accuracy: 0.7520\n",
      "Epoch 431/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7332 - val_loss: 0.0055 - val_accuracy: 0.7550\n",
      "Epoch 432/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7383 - val_loss: 0.0055 - val_accuracy: 0.7285\n",
      "Epoch 433/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7278 - val_loss: 0.0055 - val_accuracy: 0.7115\n",
      "Epoch 434/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7297 - val_loss: 0.0055 - val_accuracy: 0.7285\n",
      "Epoch 435/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7138 - val_loss: 0.0055 - val_accuracy: 0.7530\n",
      "Epoch 436/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7303 - val_loss: 0.0055 - val_accuracy: 0.7455\n",
      "Epoch 437/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7363 - val_loss: 0.0055 - val_accuracy: 0.7555\n",
      "Epoch 438/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7393 - val_loss: 0.0055 - val_accuracy: 0.7300\n",
      "Epoch 439/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7243 - val_loss: 0.0055 - val_accuracy: 0.7675\n",
      "Epoch 440/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7343 - val_loss: 0.0055 - val_accuracy: 0.7170\n",
      "Epoch 441/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7290 - val_loss: 0.0055 - val_accuracy: 0.7430\n",
      "Epoch 442/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7273 - val_loss: 0.0055 - val_accuracy: 0.7345\n",
      "Epoch 443/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7375 - val_loss: 0.0055 - val_accuracy: 0.7635\n",
      "Epoch 444/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7218 - val_loss: 0.0055 - val_accuracy: 0.7080\n",
      "Epoch 445/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7217 - val_loss: 0.0055 - val_accuracy: 0.7610\n",
      "Epoch 446/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7238 - val_loss: 0.0055 - val_accuracy: 0.7730\n",
      "Epoch 447/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7388 - val_loss: 0.0055 - val_accuracy: 0.7560\n",
      "Epoch 448/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7383 - val_loss: 0.0055 - val_accuracy: 0.7505\n",
      "Epoch 449/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7375 - val_loss: 0.0056 - val_accuracy: 0.7170\n",
      "Epoch 450/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7268 - val_loss: 0.0055 - val_accuracy: 0.7555\n",
      "Epoch 451/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7303 - val_loss: 0.0055 - val_accuracy: 0.7565\n",
      "Epoch 452/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7372 - val_loss: 0.0055 - val_accuracy: 0.7485\n",
      "Epoch 453/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7363 - val_loss: 0.0056 - val_accuracy: 0.7235\n",
      "Epoch 454/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7298 - val_loss: 0.0055 - val_accuracy: 0.7360\n",
      "Epoch 455/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7320 - val_loss: 0.0055 - val_accuracy: 0.7505\n",
      "Epoch 456/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7333 - val_loss: 0.0055 - val_accuracy: 0.7610\n",
      "Epoch 457/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7313 - val_loss: 0.0055 - val_accuracy: 0.7480\n",
      "Epoch 458/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7343 - val_loss: 0.0055 - val_accuracy: 0.7735\n",
      "Epoch 459/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7435 - val_loss: 0.0055 - val_accuracy: 0.7665\n",
      "Epoch 460/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7248 - val_loss: 0.0055 - val_accuracy: 0.7235\n",
      "Epoch 461/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7325 - val_loss: 0.0055 - val_accuracy: 0.7590\n",
      "Epoch 462/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7353 - val_loss: 0.0055 - val_accuracy: 0.7325\n",
      "Epoch 463/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7170 - val_loss: 0.0055 - val_accuracy: 0.7285\n",
      "Epoch 464/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7402 - val_loss: 0.0055 - val_accuracy: 0.7290\n",
      "Epoch 465/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7278 - val_loss: 0.0056 - val_accuracy: 0.7240\n",
      "Epoch 466/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7290 - val_loss: 0.0055 - val_accuracy: 0.7450\n",
      "Epoch 467/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7307 - val_loss: 0.0055 - val_accuracy: 0.7610\n",
      "Epoch 468/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7317 - val_loss: 0.0055 - val_accuracy: 0.7585\n",
      "Epoch 469/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7323 - val_loss: 0.0055 - val_accuracy: 0.7580\n",
      "Epoch 470/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7323 - val_loss: 0.0055 - val_accuracy: 0.7675\n",
      "Epoch 471/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7267 - val_loss: 0.0055 - val_accuracy: 0.7285\n",
      "Epoch 472/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7338 - val_loss: 0.0055 - val_accuracy: 0.7345\n",
      "Epoch 473/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7405 - val_loss: 0.0055 - val_accuracy: 0.7400\n",
      "Epoch 474/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7358 - val_loss: 0.0055 - val_accuracy: 0.7700\n",
      "Epoch 475/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7337 - val_loss: 0.0055 - val_accuracy: 0.7260\n",
      "Epoch 476/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7235 - val_loss: 0.0055 - val_accuracy: 0.7525\n",
      "Epoch 477/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7272 - val_loss: 0.0055 - val_accuracy: 0.7650\n",
      "Epoch 478/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7347 - val_loss: 0.0055 - val_accuracy: 0.7050\n",
      "Epoch 479/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7280 - val_loss: 0.0055 - val_accuracy: 0.7675\n",
      "Epoch 480/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7385 - val_loss: 0.0055 - val_accuracy: 0.7405\n",
      "Epoch 481/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7268 - val_loss: 0.0055 - val_accuracy: 0.7705\n",
      "Epoch 482/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7457 - val_loss: 0.0055 - val_accuracy: 0.7330\n",
      "Epoch 483/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7360 - val_loss: 0.0055 - val_accuracy: 0.7340\n",
      "Epoch 484/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7302 - val_loss: 0.0055 - val_accuracy: 0.7725\n",
      "Epoch 485/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7350 - val_loss: 0.0055 - val_accuracy: 0.7540\n",
      "Epoch 486/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0054 - accuracy: 0.7305 - val_loss: 0.0055 - val_accuracy: 0.7670\n",
      "Epoch 487/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7412 - val_loss: 0.0055 - val_accuracy: 0.7535\n",
      "Epoch 488/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7285 - val_loss: 0.0055 - val_accuracy: 0.7575\n",
      "Epoch 489/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7357 - val_loss: 0.0055 - val_accuracy: 0.7735\n",
      "Epoch 490/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7317 - val_loss: 0.0055 - val_accuracy: 0.7665\n",
      "Epoch 491/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7377 - val_loss: 0.0055 - val_accuracy: 0.7465\n",
      "Epoch 492/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7375 - val_loss: 0.0055 - val_accuracy: 0.7770\n",
      "Epoch 493/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7415 - val_loss: 0.0055 - val_accuracy: 0.7050\n",
      "Epoch 494/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7258 - val_loss: 0.0055 - val_accuracy: 0.7710\n",
      "Epoch 495/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7368 - val_loss: 0.0055 - val_accuracy: 0.7645\n",
      "Epoch 496/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7343 - val_loss: 0.0055 - val_accuracy: 0.7640\n",
      "Epoch 497/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7362 - val_loss: 0.0055 - val_accuracy: 0.7760\n",
      "Epoch 498/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7397 - val_loss: 0.0055 - val_accuracy: 0.7695\n",
      "Epoch 499/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7313 - val_loss: 0.0055 - val_accuracy: 0.7570\n",
      "Epoch 500/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7322 - val_loss: 0.0055 - val_accuracy: 0.7585\n",
      "Epoch 501/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7398 - val_loss: 0.0055 - val_accuracy: 0.7690\n",
      "Epoch 502/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7340 - val_loss: 0.0055 - val_accuracy: 0.7565\n",
      "Epoch 503/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7223 - val_loss: 0.0055 - val_accuracy: 0.7715\n",
      "Epoch 504/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7385 - val_loss: 0.0055 - val_accuracy: 0.7690\n",
      "Epoch 505/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7343 - val_loss: 0.0055 - val_accuracy: 0.7405\n",
      "Epoch 506/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7283 - val_loss: 0.0055 - val_accuracy: 0.7720\n",
      "Epoch 507/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7433 - val_loss: 0.0055 - val_accuracy: 0.7485\n",
      "Epoch 508/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7287 - val_loss: 0.0055 - val_accuracy: 0.7740\n",
      "Epoch 509/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7395 - val_loss: 0.0055 - val_accuracy: 0.7720\n",
      "Epoch 510/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7293 - val_loss: 0.0055 - val_accuracy: 0.7490\n",
      "Epoch 511/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7272 - val_loss: 0.0055 - val_accuracy: 0.7530\n",
      "Epoch 512/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7202 - val_loss: 0.0055 - val_accuracy: 0.7720\n",
      "Epoch 513/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7387 - val_loss: 0.0055 - val_accuracy: 0.7615\n",
      "Epoch 514/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7378 - val_loss: 0.0055 - val_accuracy: 0.7415\n",
      "Epoch 515/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7280 - val_loss: 0.0055 - val_accuracy: 0.7580\n",
      "Epoch 516/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7420 - val_loss: 0.0055 - val_accuracy: 0.7135\n",
      "Epoch 517/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0054 - accuracy: 0.7305 - val_loss: 0.0055 - val_accuracy: 0.7035\n",
      "Epoch 518/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7265 - val_loss: 0.0055 - val_accuracy: 0.7500\n",
      "Epoch 519/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7308 - val_loss: 0.0055 - val_accuracy: 0.7105\n",
      "Epoch 520/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7390 - val_loss: 0.0055 - val_accuracy: 0.7250\n",
      "Epoch 521/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7255 - val_loss: 0.0055 - val_accuracy: 0.7540\n",
      "Epoch 522/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7275 - val_loss: 0.0055 - val_accuracy: 0.7700\n",
      "Epoch 523/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7408 - val_loss: 0.0055 - val_accuracy: 0.7450\n",
      "Epoch 524/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7198 - val_loss: 0.0055 - val_accuracy: 0.7725\n",
      "Epoch 525/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7425 - val_loss: 0.0055 - val_accuracy: 0.7535\n",
      "Epoch 526/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7332 - val_loss: 0.0055 - val_accuracy: 0.7480\n",
      "Epoch 527/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7402 - val_loss: 0.0056 - val_accuracy: 0.7095\n",
      "Epoch 528/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7277 - val_loss: 0.0055 - val_accuracy: 0.7470\n",
      "Epoch 529/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7395 - val_loss: 0.0055 - val_accuracy: 0.7310\n",
      "Epoch 530/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7315 - val_loss: 0.0055 - val_accuracy: 0.7095\n",
      "Epoch 531/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7335 - val_loss: 0.0055 - val_accuracy: 0.7520\n",
      "Epoch 532/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7492 - val_loss: 0.0055 - val_accuracy: 0.7275\n",
      "Epoch 533/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7183 - val_loss: 0.0055 - val_accuracy: 0.7410\n",
      "Epoch 534/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7387 - val_loss: 0.0055 - val_accuracy: 0.7380\n",
      "Epoch 535/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7447 - val_loss: 0.0055 - val_accuracy: 0.7485\n",
      "Epoch 536/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7430 - val_loss: 0.0055 - val_accuracy: 0.7050\n",
      "Epoch 537/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7242 - val_loss: 0.0055 - val_accuracy: 0.7675\n",
      "Epoch 538/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7508 - val_loss: 0.0055 - val_accuracy: 0.7140\n",
      "Epoch 539/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7278 - val_loss: 0.0055 - val_accuracy: 0.7220\n",
      "Epoch 540/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7290 - val_loss: 0.0055 - val_accuracy: 0.7485\n",
      "Epoch 541/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7482 - val_loss: 0.0055 - val_accuracy: 0.7070\n",
      "Epoch 542/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7257 - val_loss: 0.0055 - val_accuracy: 0.7655\n",
      "Epoch 543/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7292 - val_loss: 0.0055 - val_accuracy: 0.7655\n",
      "Epoch 544/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7330 - val_loss: 0.0055 - val_accuracy: 0.7395\n",
      "Epoch 545/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7462 - val_loss: 0.0055 - val_accuracy: 0.7590\n",
      "Epoch 546/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7252 - val_loss: 0.0055 - val_accuracy: 0.7495\n",
      "Epoch 547/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7362 - val_loss: 0.0055 - val_accuracy: 0.7605\n",
      "Epoch 548/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7367 - val_loss: 0.0055 - val_accuracy: 0.7415\n",
      "Epoch 549/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7318 - val_loss: 0.0055 - val_accuracy: 0.7220\n",
      "Epoch 550/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7317 - val_loss: 0.0055 - val_accuracy: 0.7180\n",
      "Epoch 551/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7335 - val_loss: 0.0055 - val_accuracy: 0.7660\n",
      "Epoch 552/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7390 - val_loss: 0.0055 - val_accuracy: 0.7350\n",
      "Epoch 553/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7360 - val_loss: 0.0055 - val_accuracy: 0.7410\n",
      "Epoch 554/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7283 - val_loss: 0.0055 - val_accuracy: 0.7325\n",
      "Epoch 555/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7283 - val_loss: 0.0055 - val_accuracy: 0.7540\n",
      "Epoch 556/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7285 - val_loss: 0.0055 - val_accuracy: 0.7635\n",
      "Epoch 557/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7308 - val_loss: 0.0055 - val_accuracy: 0.7710\n",
      "Epoch 558/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7470 - val_loss: 0.0055 - val_accuracy: 0.7440\n",
      "Epoch 559/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7337 - val_loss: 0.0055 - val_accuracy: 0.7655\n",
      "Epoch 560/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7303 - val_loss: 0.0055 - val_accuracy: 0.7585\n",
      "Epoch 561/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7367 - val_loss: 0.0055 - val_accuracy: 0.7320\n",
      "Epoch 562/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7420 - val_loss: 0.0055 - val_accuracy: 0.7360\n",
      "Epoch 563/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7262 - val_loss: 0.0055 - val_accuracy: 0.7785\n",
      "Epoch 564/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7295 - val_loss: 0.0055 - val_accuracy: 0.7690\n",
      "Epoch 565/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7380 - val_loss: 0.0055 - val_accuracy: 0.7660\n",
      "Epoch 566/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7350 - val_loss: 0.0055 - val_accuracy: 0.7415\n",
      "Epoch 567/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7243 - val_loss: 0.0055 - val_accuracy: 0.7605\n",
      "Epoch 568/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7443 - val_loss: 0.0055 - val_accuracy: 0.7350\n",
      "Epoch 569/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7390 - val_loss: 0.0055 - val_accuracy: 0.7155\n",
      "Epoch 570/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7223 - val_loss: 0.0055 - val_accuracy: 0.7545\n",
      "Epoch 571/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7338 - val_loss: 0.0055 - val_accuracy: 0.7780\n",
      "Epoch 572/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7375 - val_loss: 0.0055 - val_accuracy: 0.7510\n",
      "Epoch 573/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7430 - val_loss: 0.0055 - val_accuracy: 0.7365\n",
      "Epoch 574/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7392 - val_loss: 0.0055 - val_accuracy: 0.7725\n",
      "Epoch 575/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7270 - val_loss: 0.0055 - val_accuracy: 0.7740\n",
      "Epoch 576/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7457 - val_loss: 0.0055 - val_accuracy: 0.7250\n",
      "Epoch 577/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7258 - val_loss: 0.0055 - val_accuracy: 0.7605\n",
      "Epoch 578/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7408 - val_loss: 0.0055 - val_accuracy: 0.7620\n",
      "Epoch 579/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7322 - val_loss: 0.0055 - val_accuracy: 0.7570\n",
      "Epoch 580/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7275 - val_loss: 0.0055 - val_accuracy: 0.7510\n",
      "Epoch 581/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7420 - val_loss: 0.0055 - val_accuracy: 0.7295\n",
      "Epoch 582/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7307 - val_loss: 0.0055 - val_accuracy: 0.7670\n",
      "Epoch 583/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7378 - val_loss: 0.0055 - val_accuracy: 0.7495\n",
      "Epoch 584/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7245 - val_loss: 0.0055 - val_accuracy: 0.7680\n",
      "Epoch 585/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7415 - val_loss: 0.0055 - val_accuracy: 0.7700\n",
      "Epoch 586/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7328 - val_loss: 0.0055 - val_accuracy: 0.7605\n",
      "Epoch 587/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7320 - val_loss: 0.0055 - val_accuracy: 0.7325\n",
      "Epoch 588/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7418 - val_loss: 0.0055 - val_accuracy: 0.7275\n",
      "Epoch 589/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7378 - val_loss: 0.0055 - val_accuracy: 0.7145\n",
      "Epoch 590/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7135 - val_loss: 0.0055 - val_accuracy: 0.7715\n",
      "Epoch 591/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7357 - val_loss: 0.0055 - val_accuracy: 0.7705\n",
      "Epoch 592/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7355 - val_loss: 0.0055 - val_accuracy: 0.7640\n",
      "Epoch 593/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7355 - val_loss: 0.0055 - val_accuracy: 0.7565\n",
      "Epoch 594/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7268 - val_loss: 0.0055 - val_accuracy: 0.7675\n",
      "Epoch 595/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7452 - val_loss: 0.0056 - val_accuracy: 0.7025\n",
      "Epoch 596/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7350 - val_loss: 0.0055 - val_accuracy: 0.7520\n",
      "Epoch 597/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7390 - val_loss: 0.0055 - val_accuracy: 0.7425\n",
      "Epoch 598/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7273 - val_loss: 0.0055 - val_accuracy: 0.7365\n",
      "Epoch 599/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7353 - val_loss: 0.0055 - val_accuracy: 0.7375\n",
      "Epoch 600/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7245 - val_loss: 0.0055 - val_accuracy: 0.7695\n",
      "Epoch 601/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7388 - val_loss: 0.0055 - val_accuracy: 0.7320\n",
      "Epoch 602/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7278 - val_loss: 0.0055 - val_accuracy: 0.7575\n",
      "Epoch 603/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7447 - val_loss: 0.0055 - val_accuracy: 0.7330\n",
      "Epoch 604/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7302 - val_loss: 0.0055 - val_accuracy: 0.7660\n",
      "Epoch 605/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7262 - val_loss: 0.0055 - val_accuracy: 0.7765\n",
      "Epoch 606/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7487 - val_loss: 0.0055 - val_accuracy: 0.7780\n",
      "Epoch 607/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7452 - val_loss: 0.0055 - val_accuracy: 0.7660\n",
      "Epoch 608/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7327 - val_loss: 0.0055 - val_accuracy: 0.7455\n",
      "Epoch 609/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7238 - val_loss: 0.0055 - val_accuracy: 0.7580\n",
      "Epoch 610/1000\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0054 - accuracy: 0.7368 - val_loss: 0.0055 - val_accuracy: 0.7590\n",
      "Epoch 611/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7382 - val_loss: 0.0055 - val_accuracy: 0.7255\n",
      "Epoch 612/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7295 - val_loss: 0.0055 - val_accuracy: 0.7680\n",
      "Epoch 613/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7310 - val_loss: 0.0055 - val_accuracy: 0.7645\n",
      "Epoch 614/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7367 - val_loss: 0.0055 - val_accuracy: 0.7645\n",
      "Epoch 615/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7335 - val_loss: 0.0055 - val_accuracy: 0.7130\n",
      "Epoch 616/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7328 - val_loss: 0.0056 - val_accuracy: 0.7340\n",
      "Epoch 617/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7390 - val_loss: 0.0055 - val_accuracy: 0.7095\n",
      "Epoch 618/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7402 - val_loss: 0.0055 - val_accuracy: 0.7380\n",
      "Epoch 619/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7370 - val_loss: 0.0055 - val_accuracy: 0.7480\n",
      "Epoch 620/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7242 - val_loss: 0.0055 - val_accuracy: 0.7485\n",
      "Epoch 621/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7268 - val_loss: 0.0055 - val_accuracy: 0.7480\n",
      "Epoch 622/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7327 - val_loss: 0.0055 - val_accuracy: 0.7640\n",
      "Epoch 623/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7463 - val_loss: 0.0055 - val_accuracy: 0.7505\n",
      "Epoch 624/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7342 - val_loss: 0.0055 - val_accuracy: 0.7690\n",
      "Epoch 625/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7448 - val_loss: 0.0055 - val_accuracy: 0.7425\n",
      "Epoch 626/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7340 - val_loss: 0.0055 - val_accuracy: 0.7290\n",
      "Epoch 627/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7370 - val_loss: 0.0055 - val_accuracy: 0.7495\n",
      "Epoch 628/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7258 - val_loss: 0.0055 - val_accuracy: 0.7310\n",
      "Epoch 629/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7322 - val_loss: 0.0055 - val_accuracy: 0.7595\n",
      "Epoch 630/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7483 - val_loss: 0.0055 - val_accuracy: 0.7285\n",
      "Epoch 631/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7300 - val_loss: 0.0055 - val_accuracy: 0.7550\n",
      "Epoch 632/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7407 - val_loss: 0.0055 - val_accuracy: 0.7600\n",
      "Epoch 633/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7408 - val_loss: 0.0055 - val_accuracy: 0.7430\n",
      "Epoch 634/1000\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0054 - accuracy: 0.7362 - val_loss: 0.0055 - val_accuracy: 0.7250\n",
      "Epoch 635/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7368 - val_loss: 0.0055 - val_accuracy: 0.7440\n",
      "Epoch 636/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7302 - val_loss: 0.0055 - val_accuracy: 0.7605\n",
      "Epoch 637/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7412 - val_loss: 0.0055 - val_accuracy: 0.7395\n",
      "Epoch 638/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7292 - val_loss: 0.0055 - val_accuracy: 0.7635\n",
      "Epoch 639/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7347 - val_loss: 0.0055 - val_accuracy: 0.7755\n",
      "Epoch 640/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7470 - val_loss: 0.0055 - val_accuracy: 0.7645\n",
      "Epoch 641/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7337 - val_loss: 0.0055 - val_accuracy: 0.7495\n",
      "Epoch 642/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7252 - val_loss: 0.0055 - val_accuracy: 0.7670\n",
      "Epoch 643/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7423 - val_loss: 0.0055 - val_accuracy: 0.7265\n",
      "Epoch 644/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7290 - val_loss: 0.0055 - val_accuracy: 0.7365\n",
      "Epoch 645/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7332 - val_loss: 0.0055 - val_accuracy: 0.7545\n",
      "Epoch 646/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7383 - val_loss: 0.0055 - val_accuracy: 0.7250\n",
      "Epoch 647/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7208 - val_loss: 0.0055 - val_accuracy: 0.7735\n",
      "Epoch 648/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7370 - val_loss: 0.0055 - val_accuracy: 0.7575\n",
      "Epoch 649/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7455 - val_loss: 0.0055 - val_accuracy: 0.7420\n",
      "Epoch 650/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7213 - val_loss: 0.0055 - val_accuracy: 0.7715\n",
      "Epoch 651/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7318 - val_loss: 0.0055 - val_accuracy: 0.7770\n",
      "Epoch 652/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7427 - val_loss: 0.0055 - val_accuracy: 0.7675\n",
      "Epoch 653/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7460 - val_loss: 0.0056 - val_accuracy: 0.7190\n",
      "Epoch 654/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7303 - val_loss: 0.0055 - val_accuracy: 0.7255\n",
      "Epoch 655/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7193 - val_loss: 0.0055 - val_accuracy: 0.7755\n",
      "Epoch 656/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7362 - val_loss: 0.0055 - val_accuracy: 0.7415\n",
      "Epoch 657/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7422 - val_loss: 0.0055 - val_accuracy: 0.7285\n",
      "Epoch 658/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7380 - val_loss: 0.0055 - val_accuracy: 0.7230\n",
      "Epoch 659/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7305 - val_loss: 0.0055 - val_accuracy: 0.7335\n",
      "Epoch 660/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7265 - val_loss: 0.0055 - val_accuracy: 0.7335\n",
      "Epoch 661/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7327 - val_loss: 0.0055 - val_accuracy: 0.7375\n",
      "Epoch 662/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7273 - val_loss: 0.0055 - val_accuracy: 0.7670\n",
      "Epoch 663/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7440 - val_loss: 0.0055 - val_accuracy: 0.7575\n",
      "Epoch 664/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7377 - val_loss: 0.0055 - val_accuracy: 0.7250\n",
      "Epoch 665/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7248 - val_loss: 0.0055 - val_accuracy: 0.7630\n",
      "Epoch 666/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7322 - val_loss: 0.0055 - val_accuracy: 0.7540\n",
      "Epoch 667/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7380 - val_loss: 0.0055 - val_accuracy: 0.7570\n",
      "Epoch 668/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7215 - val_loss: 0.0055 - val_accuracy: 0.7765\n",
      "Epoch 669/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7413 - val_loss: 0.0055 - val_accuracy: 0.7390\n",
      "Epoch 670/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7333 - val_loss: 0.0055 - val_accuracy: 0.7540\n",
      "Epoch 671/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7395 - val_loss: 0.0055 - val_accuracy: 0.7335\n",
      "Epoch 672/1000\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0054 - accuracy: 0.7357 - val_loss: 0.0055 - val_accuracy: 0.7310\n",
      "Epoch 673/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7318 - val_loss: 0.0055 - val_accuracy: 0.7590\n",
      "Epoch 674/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7362 - val_loss: 0.0055 - val_accuracy: 0.7345\n",
      "Epoch 675/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7235 - val_loss: 0.0055 - val_accuracy: 0.7465\n",
      "Epoch 676/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7305 - val_loss: 0.0055 - val_accuracy: 0.7705\n",
      "Epoch 677/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7290 - val_loss: 0.0055 - val_accuracy: 0.7725\n",
      "Epoch 678/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7412 - val_loss: 0.0055 - val_accuracy: 0.7300\n",
      "Epoch 679/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7297 - val_loss: 0.0055 - val_accuracy: 0.7635\n",
      "Epoch 680/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7280 - val_loss: 0.0055 - val_accuracy: 0.7545\n",
      "Epoch 681/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7305 - val_loss: 0.0055 - val_accuracy: 0.7570\n",
      "Epoch 682/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7378 - val_loss: 0.0055 - val_accuracy: 0.7260\n",
      "Epoch 683/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7277 - val_loss: 0.0055 - val_accuracy: 0.7630\n",
      "Epoch 684/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7408 - val_loss: 0.0055 - val_accuracy: 0.7210\n",
      "Epoch 685/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7283 - val_loss: 0.0055 - val_accuracy: 0.7745\n",
      "Epoch 686/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7417 - val_loss: 0.0055 - val_accuracy: 0.7455\n",
      "Epoch 687/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7382 - val_loss: 0.0055 - val_accuracy: 0.7135\n",
      "Epoch 688/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7232 - val_loss: 0.0055 - val_accuracy: 0.7620\n",
      "Epoch 689/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7418 - val_loss: 0.0055 - val_accuracy: 0.7350\n",
      "Epoch 690/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7367 - val_loss: 0.0055 - val_accuracy: 0.7605\n",
      "Epoch 691/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7307 - val_loss: 0.0055 - val_accuracy: 0.7640\n",
      "Epoch 692/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7443 - val_loss: 0.0055 - val_accuracy: 0.7350\n",
      "Epoch 693/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7267 - val_loss: 0.0055 - val_accuracy: 0.7700\n",
      "Epoch 694/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7402 - val_loss: 0.0055 - val_accuracy: 0.7575\n",
      "Epoch 695/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7392 - val_loss: 0.0055 - val_accuracy: 0.7695\n",
      "Epoch 696/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7388 - val_loss: 0.0055 - val_accuracy: 0.7615\n",
      "Epoch 697/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7287 - val_loss: 0.0055 - val_accuracy: 0.7430\n",
      "Epoch 698/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7237 - val_loss: 0.0055 - val_accuracy: 0.7635\n",
      "Epoch 699/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7353 - val_loss: 0.0055 - val_accuracy: 0.7560\n",
      "Epoch 700/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7290 - val_loss: 0.0055 - val_accuracy: 0.7760\n",
      "Epoch 701/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7347 - val_loss: 0.0055 - val_accuracy: 0.7480\n",
      "Epoch 702/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7385 - val_loss: 0.0055 - val_accuracy: 0.7385\n",
      "Epoch 703/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7435 - val_loss: 0.0055 - val_accuracy: 0.7515\n",
      "Epoch 704/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7253 - val_loss: 0.0055 - val_accuracy: 0.7685\n",
      "Epoch 705/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7375 - val_loss: 0.0055 - val_accuracy: 0.7640\n",
      "Epoch 706/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7382 - val_loss: 0.0055 - val_accuracy: 0.7680\n",
      "Epoch 707/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7357 - val_loss: 0.0055 - val_accuracy: 0.7060\n",
      "Epoch 708/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7293 - val_loss: 0.0055 - val_accuracy: 0.7430\n",
      "Epoch 709/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7272 - val_loss: 0.0055 - val_accuracy: 0.7675\n",
      "Epoch 710/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7282 - val_loss: 0.0055 - val_accuracy: 0.7710\n",
      "Epoch 711/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7473 - val_loss: 0.0055 - val_accuracy: 0.7600\n",
      "Epoch 712/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7375 - val_loss: 0.0055 - val_accuracy: 0.7690\n",
      "Epoch 713/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7410 - val_loss: 0.0055 - val_accuracy: 0.7490\n",
      "Epoch 714/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7302 - val_loss: 0.0055 - val_accuracy: 0.7660\n",
      "Epoch 715/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7412 - val_loss: 0.0055 - val_accuracy: 0.7150\n",
      "Epoch 716/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7303 - val_loss: 0.0055 - val_accuracy: 0.7245\n",
      "Epoch 717/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7188 - val_loss: 0.0055 - val_accuracy: 0.7655\n",
      "Epoch 718/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7418 - val_loss: 0.0055 - val_accuracy: 0.7455\n",
      "Epoch 719/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7407 - val_loss: 0.0055 - val_accuracy: 0.7550\n",
      "Epoch 720/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7315 - val_loss: 0.0055 - val_accuracy: 0.7535\n",
      "Epoch 721/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7202 - val_loss: 0.0055 - val_accuracy: 0.7670\n",
      "Epoch 722/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7458 - val_loss: 0.0055 - val_accuracy: 0.7315\n",
      "Epoch 723/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7363 - val_loss: 0.0055 - val_accuracy: 0.7440\n",
      "Epoch 724/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7212 - val_loss: 0.0055 - val_accuracy: 0.7640\n",
      "Epoch 725/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7302 - val_loss: 0.0055 - val_accuracy: 0.7700\n",
      "Epoch 726/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7265 - val_loss: 0.0055 - val_accuracy: 0.7695\n",
      "Epoch 727/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7508 - val_loss: 0.0055 - val_accuracy: 0.7045\n",
      "Epoch 728/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7252 - val_loss: 0.0055 - val_accuracy: 0.7565\n",
      "Epoch 729/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7365 - val_loss: 0.0055 - val_accuracy: 0.7440\n",
      "Epoch 730/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7333 - val_loss: 0.0055 - val_accuracy: 0.7440\n",
      "Epoch 731/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7350 - val_loss: 0.0055 - val_accuracy: 0.7525\n",
      "Epoch 732/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7367 - val_loss: 0.0055 - val_accuracy: 0.7190\n",
      "Epoch 733/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7247 - val_loss: 0.0055 - val_accuracy: 0.7690\n",
      "Epoch 734/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0054 - accuracy: 0.7398 - val_loss: 0.0055 - val_accuracy: 0.7600\n",
      "Epoch 735/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7317 - val_loss: 0.0055 - val_accuracy: 0.7455\n",
      "Epoch 736/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7452 - val_loss: 0.0055 - val_accuracy: 0.7510\n",
      "Epoch 737/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7328 - val_loss: 0.0055 - val_accuracy: 0.7585\n",
      "Epoch 738/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7442 - val_loss: 0.0055 - val_accuracy: 0.7535\n",
      "Epoch 739/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7283 - val_loss: 0.0055 - val_accuracy: 0.7445\n",
      "Epoch 740/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7385 - val_loss: 0.0055 - val_accuracy: 0.7700\n",
      "Epoch 741/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7368 - val_loss: 0.0055 - val_accuracy: 0.7325\n",
      "Epoch 742/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7373 - val_loss: 0.0055 - val_accuracy: 0.7530\n",
      "Epoch 743/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7235 - val_loss: 0.0055 - val_accuracy: 0.7660\n",
      "Epoch 744/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7400 - val_loss: 0.0055 - val_accuracy: 0.7145\n",
      "Epoch 745/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7295 - val_loss: 0.0055 - val_accuracy: 0.7710\n",
      "Epoch 746/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7423 - val_loss: 0.0055 - val_accuracy: 0.7370\n",
      "Epoch 747/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7298 - val_loss: 0.0055 - val_accuracy: 0.7435\n",
      "Epoch 748/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7367 - val_loss: 0.0055 - val_accuracy: 0.7570\n",
      "Epoch 749/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7222 - val_loss: 0.0055 - val_accuracy: 0.7760\n",
      "Epoch 750/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7378 - val_loss: 0.0055 - val_accuracy: 0.7410\n",
      "Epoch 751/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7347 - val_loss: 0.0055 - val_accuracy: 0.7595\n",
      "Epoch 752/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7308 - val_loss: 0.0055 - val_accuracy: 0.7695\n",
      "Epoch 753/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7397 - val_loss: 0.0055 - val_accuracy: 0.7315\n",
      "Epoch 754/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7315 - val_loss: 0.0055 - val_accuracy: 0.7775\n",
      "Epoch 755/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7347 - val_loss: 0.0055 - val_accuracy: 0.7555\n",
      "Epoch 756/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7353 - val_loss: 0.0055 - val_accuracy: 0.7710\n",
      "Epoch 757/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7297 - val_loss: 0.0055 - val_accuracy: 0.7735\n",
      "Epoch 758/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7393 - val_loss: 0.0055 - val_accuracy: 0.7230\n",
      "Epoch 759/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7363 - val_loss: 0.0055 - val_accuracy: 0.7270\n",
      "Epoch 760/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7400 - val_loss: 0.0055 - val_accuracy: 0.7390\n",
      "Epoch 761/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7240 - val_loss: 0.0055 - val_accuracy: 0.7690\n",
      "Epoch 762/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7315 - val_loss: 0.0055 - val_accuracy: 0.7565\n",
      "Epoch 763/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7317 - val_loss: 0.0055 - val_accuracy: 0.7695\n",
      "Epoch 764/1000\n",
      "188/188 [==============================] - ETA: 0s - loss: 0.0054 - accuracy: 0.74 - 0s 521us/step - loss: 0.0054 - accuracy: 0.7443 - val_loss: 0.0055 - val_accuracy: 0.7320\n",
      "Epoch 765/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7300 - val_loss: 0.0055 - val_accuracy: 0.7515\n",
      "Epoch 766/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7307 - val_loss: 0.0055 - val_accuracy: 0.7730\n",
      "Epoch 767/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7370 - val_loss: 0.0055 - val_accuracy: 0.7375\n",
      "Epoch 768/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7162 - val_loss: 0.0055 - val_accuracy: 0.7650\n",
      "Epoch 769/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7422 - val_loss: 0.0055 - val_accuracy: 0.7305\n",
      "Epoch 770/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7338 - val_loss: 0.0055 - val_accuracy: 0.7615\n",
      "Epoch 771/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7393 - val_loss: 0.0055 - val_accuracy: 0.7485\n",
      "Epoch 772/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7322 - val_loss: 0.0055 - val_accuracy: 0.7625\n",
      "Epoch 773/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7385 - val_loss: 0.0055 - val_accuracy: 0.7585\n",
      "Epoch 774/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7387 - val_loss: 0.0055 - val_accuracy: 0.7625\n",
      "Epoch 775/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7308 - val_loss: 0.0055 - val_accuracy: 0.7325\n",
      "Epoch 776/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7265 - val_loss: 0.0055 - val_accuracy: 0.7685\n",
      "Epoch 777/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7293 - val_loss: 0.0055 - val_accuracy: 0.7690\n",
      "Epoch 778/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7355 - val_loss: 0.0055 - val_accuracy: 0.7495\n",
      "Epoch 779/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7422 - val_loss: 0.0055 - val_accuracy: 0.7630\n",
      "Epoch 780/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7345 - val_loss: 0.0055 - val_accuracy: 0.7740\n",
      "Epoch 781/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7438 - val_loss: 0.0055 - val_accuracy: 0.7410\n",
      "Epoch 782/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7307 - val_loss: 0.0055 - val_accuracy: 0.7300\n",
      "Epoch 783/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7247 - val_loss: 0.0055 - val_accuracy: 0.7320\n",
      "Epoch 784/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7317 - val_loss: 0.0055 - val_accuracy: 0.7575\n",
      "Epoch 785/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7402 - val_loss: 0.0055 - val_accuracy: 0.7650\n",
      "Epoch 786/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7377 - val_loss: 0.0055 - val_accuracy: 0.7705\n",
      "Epoch 787/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7392 - val_loss: 0.0055 - val_accuracy: 0.7365\n",
      "Epoch 788/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7385 - val_loss: 0.0055 - val_accuracy: 0.7325\n",
      "Epoch 789/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7398 - val_loss: 0.0055 - val_accuracy: 0.7580\n",
      "Epoch 790/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7328 - val_loss: 0.0055 - val_accuracy: 0.7595\n",
      "Epoch 791/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7415 - val_loss: 0.0055 - val_accuracy: 0.7570\n",
      "Epoch 792/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7363 - val_loss: 0.0055 - val_accuracy: 0.7130\n",
      "Epoch 793/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7285 - val_loss: 0.0055 - val_accuracy: 0.7605\n",
      "Epoch 794/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7317 - val_loss: 0.0055 - val_accuracy: 0.7405\n",
      "Epoch 795/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7348 - val_loss: 0.0055 - val_accuracy: 0.7375\n",
      "Epoch 796/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0054 - accuracy: 0.7325 - val_loss: 0.0055 - val_accuracy: 0.7630\n",
      "Epoch 797/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7363 - val_loss: 0.0055 - val_accuracy: 0.7430\n",
      "Epoch 798/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7317 - val_loss: 0.0055 - val_accuracy: 0.7545\n",
      "Epoch 799/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7365 - val_loss: 0.0055 - val_accuracy: 0.7500\n",
      "Epoch 800/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7362 - val_loss: 0.0055 - val_accuracy: 0.7200\n",
      "Epoch 801/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7392 - val_loss: 0.0055 - val_accuracy: 0.7110\n",
      "Epoch 802/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7240 - val_loss: 0.0055 - val_accuracy: 0.7550\n",
      "Epoch 803/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7373 - val_loss: 0.0055 - val_accuracy: 0.7630\n",
      "Epoch 804/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7232 - val_loss: 0.0055 - val_accuracy: 0.7625\n",
      "Epoch 805/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7428 - val_loss: 0.0055 - val_accuracy: 0.7665\n",
      "Epoch 806/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7323 - val_loss: 0.0055 - val_accuracy: 0.7555\n",
      "Epoch 807/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7327 - val_loss: 0.0055 - val_accuracy: 0.7660\n",
      "Epoch 808/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7467 - val_loss: 0.0055 - val_accuracy: 0.7185\n",
      "Epoch 809/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7325 - val_loss: 0.0055 - val_accuracy: 0.7505\n",
      "Epoch 810/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7310 - val_loss: 0.0055 - val_accuracy: 0.7075\n",
      "Epoch 811/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7238 - val_loss: 0.0055 - val_accuracy: 0.7730\n",
      "Epoch 812/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7390 - val_loss: 0.0055 - val_accuracy: 0.7260\n",
      "Epoch 813/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7243 - val_loss: 0.0055 - val_accuracy: 0.7255\n",
      "Epoch 814/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7507 - val_loss: 0.0055 - val_accuracy: 0.7295\n",
      "Epoch 815/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7215 - val_loss: 0.0055 - val_accuracy: 0.7545\n",
      "Epoch 816/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7263 - val_loss: 0.0055 - val_accuracy: 0.7630\n",
      "Epoch 817/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7323 - val_loss: 0.0055 - val_accuracy: 0.7665\n",
      "Epoch 818/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7402 - val_loss: 0.0055 - val_accuracy: 0.7175\n",
      "Epoch 819/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7298 - val_loss: 0.0055 - val_accuracy: 0.7720\n",
      "Epoch 820/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7413 - val_loss: 0.0055 - val_accuracy: 0.7660\n",
      "Epoch 821/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7413 - val_loss: 0.0055 - val_accuracy: 0.7670\n",
      "Epoch 822/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7348 - val_loss: 0.0055 - val_accuracy: 0.7155\n",
      "Epoch 823/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7428 - val_loss: 0.0055 - val_accuracy: 0.7520\n",
      "Epoch 824/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7340 - val_loss: 0.0055 - val_accuracy: 0.7140\n",
      "Epoch 825/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7253 - val_loss: 0.0055 - val_accuracy: 0.7185\n",
      "Epoch 826/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7290 - val_loss: 0.0055 - val_accuracy: 0.7735\n",
      "Epoch 827/1000\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0054 - accuracy: 0.7310 - val_loss: 0.0055 - val_accuracy: 0.7760\n",
      "Epoch 828/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7502 - val_loss: 0.0055 - val_accuracy: 0.7425\n",
      "Epoch 829/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7310 - val_loss: 0.0055 - val_accuracy: 0.7415\n",
      "Epoch 830/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7282 - val_loss: 0.0055 - val_accuracy: 0.7040\n",
      "Epoch 831/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7277 - val_loss: 0.0055 - val_accuracy: 0.7620\n",
      "Epoch 832/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7353 - val_loss: 0.0055 - val_accuracy: 0.7290\n",
      "Epoch 833/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7280 - val_loss: 0.0055 - val_accuracy: 0.7705\n",
      "Epoch 834/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7427 - val_loss: 0.0055 - val_accuracy: 0.7585\n",
      "Epoch 835/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7500 - val_loss: 0.0055 - val_accuracy: 0.7360\n",
      "Epoch 836/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7175 - val_loss: 0.0055 - val_accuracy: 0.7330\n",
      "Epoch 837/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7310 - val_loss: 0.0055 - val_accuracy: 0.7600\n",
      "Epoch 838/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7380 - val_loss: 0.0055 - val_accuracy: 0.7565\n",
      "Epoch 839/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7427 - val_loss: 0.0055 - val_accuracy: 0.7525\n",
      "Epoch 840/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7338 - val_loss: 0.0055 - val_accuracy: 0.7440\n",
      "Epoch 841/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7358 - val_loss: 0.0055 - val_accuracy: 0.7625\n",
      "Epoch 842/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7295 - val_loss: 0.0055 - val_accuracy: 0.7355\n",
      "Epoch 843/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7317 - val_loss: 0.0055 - val_accuracy: 0.7080\n",
      "Epoch 844/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7297 - val_loss: 0.0055 - val_accuracy: 0.7695\n",
      "Epoch 845/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7400 - val_loss: 0.0055 - val_accuracy: 0.7385\n",
      "Epoch 846/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7278 - val_loss: 0.0055 - val_accuracy: 0.7185\n",
      "Epoch 847/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7313 - val_loss: 0.0055 - val_accuracy: 0.7665\n",
      "Epoch 848/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7403 - val_loss: 0.0055 - val_accuracy: 0.7500\n",
      "Epoch 849/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7330 - val_loss: 0.0055 - val_accuracy: 0.7490\n",
      "Epoch 850/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7380 - val_loss: 0.0055 - val_accuracy: 0.7515\n",
      "Epoch 851/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7373 - val_loss: 0.0055 - val_accuracy: 0.7170\n",
      "Epoch 852/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7187 - val_loss: 0.0055 - val_accuracy: 0.7760\n",
      "Epoch 853/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7448 - val_loss: 0.0054 - val_accuracy: 0.7650\n",
      "Epoch 854/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7422 - val_loss: 0.0055 - val_accuracy: 0.7365\n",
      "Epoch 855/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7320 - val_loss: 0.0055 - val_accuracy: 0.7385\n",
      "Epoch 856/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7312 - val_loss: 0.0055 - val_accuracy: 0.7505\n",
      "Epoch 857/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7403 - val_loss: 0.0055 - val_accuracy: 0.7385\n",
      "Epoch 858/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7250 - val_loss: 0.0055 - val_accuracy: 0.7375\n",
      "Epoch 859/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7253 - val_loss: 0.0055 - val_accuracy: 0.7565\n",
      "Epoch 860/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7225 - val_loss: 0.0055 - val_accuracy: 0.7735\n",
      "Epoch 861/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7428 - val_loss: 0.0055 - val_accuracy: 0.7610\n",
      "Epoch 862/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7365 - val_loss: 0.0055 - val_accuracy: 0.7585\n",
      "Epoch 863/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7387 - val_loss: 0.0055 - val_accuracy: 0.7120\n",
      "Epoch 864/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7265 - val_loss: 0.0055 - val_accuracy: 0.7345\n",
      "Epoch 865/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7237 - val_loss: 0.0055 - val_accuracy: 0.7570\n",
      "Epoch 866/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7325 - val_loss: 0.0055 - val_accuracy: 0.7460\n",
      "Epoch 867/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7292 - val_loss: 0.0055 - val_accuracy: 0.7195\n",
      "Epoch 868/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7295 - val_loss: 0.0055 - val_accuracy: 0.7555\n",
      "Epoch 869/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7305 - val_loss: 0.0055 - val_accuracy: 0.7670\n",
      "Epoch 870/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7330 - val_loss: 0.0055 - val_accuracy: 0.7755\n",
      "Epoch 871/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7423 - val_loss: 0.0055 - val_accuracy: 0.7400\n",
      "Epoch 872/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7322 - val_loss: 0.0054 - val_accuracy: 0.7770\n",
      "Epoch 873/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7305 - val_loss: 0.0055 - val_accuracy: 0.7735\n",
      "Epoch 874/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7447 - val_loss: 0.0055 - val_accuracy: 0.7745\n",
      "Epoch 875/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7330 - val_loss: 0.0055 - val_accuracy: 0.7600\n",
      "Epoch 876/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7315 - val_loss: 0.0055 - val_accuracy: 0.7500\n",
      "Epoch 877/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7468 - val_loss: 0.0055 - val_accuracy: 0.7330\n",
      "Epoch 878/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7215 - val_loss: 0.0055 - val_accuracy: 0.7320\n",
      "Epoch 879/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7245 - val_loss: 0.0055 - val_accuracy: 0.7595\n",
      "Epoch 880/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7405 - val_loss: 0.0055 - val_accuracy: 0.7685\n",
      "Epoch 881/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7265 - val_loss: 0.0055 - val_accuracy: 0.7700\n",
      "Epoch 882/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7422 - val_loss: 0.0055 - val_accuracy: 0.7485\n",
      "Epoch 883/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7337 - val_loss: 0.0055 - val_accuracy: 0.7330\n",
      "Epoch 884/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7400 - val_loss: 0.0055 - val_accuracy: 0.7170\n",
      "Epoch 885/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7308 - val_loss: 0.0055 - val_accuracy: 0.7575\n",
      "Epoch 886/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7343 - val_loss: 0.0055 - val_accuracy: 0.7665\n",
      "Epoch 887/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7448 - val_loss: 0.0055 - val_accuracy: 0.7335\n",
      "Epoch 888/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7235 - val_loss: 0.0055 - val_accuracy: 0.7665\n",
      "Epoch 889/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7480 - val_loss: 0.0055 - val_accuracy: 0.7155\n",
      "Epoch 890/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7305 - val_loss: 0.0055 - val_accuracy: 0.7205\n",
      "Epoch 891/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7362 - val_loss: 0.0055 - val_accuracy: 0.7665\n",
      "Epoch 892/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7415 - val_loss: 0.0055 - val_accuracy: 0.7555\n",
      "Epoch 893/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7303 - val_loss: 0.0055 - val_accuracy: 0.7420\n",
      "Epoch 894/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7395 - val_loss: 0.0055 - val_accuracy: 0.7670\n",
      "Epoch 895/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7348 - val_loss: 0.0055 - val_accuracy: 0.7555\n",
      "Epoch 896/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7325 - val_loss: 0.0055 - val_accuracy: 0.7755\n",
      "Epoch 897/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7368 - val_loss: 0.0055 - val_accuracy: 0.7570\n",
      "Epoch 898/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7285 - val_loss: 0.0055 - val_accuracy: 0.7735\n",
      "Epoch 899/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7347 - val_loss: 0.0055 - val_accuracy: 0.7645\n",
      "Epoch 900/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7392 - val_loss: 0.0055 - val_accuracy: 0.7460\n",
      "Epoch 901/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7490 - val_loss: 0.0055 - val_accuracy: 0.7370\n",
      "Epoch 902/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7302 - val_loss: 0.0055 - val_accuracy: 0.7275\n",
      "Epoch 903/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7248 - val_loss: 0.0055 - val_accuracy: 0.7510\n",
      "Epoch 904/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7265 - val_loss: 0.0055 - val_accuracy: 0.7710\n",
      "Epoch 905/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7353 - val_loss: 0.0055 - val_accuracy: 0.7395\n",
      "Epoch 906/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7440 - val_loss: 0.0055 - val_accuracy: 0.7405\n",
      "Epoch 907/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7245 - val_loss: 0.0055 - val_accuracy: 0.7725\n",
      "Epoch 908/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7373 - val_loss: 0.0055 - val_accuracy: 0.7385\n",
      "Epoch 909/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7403 - val_loss: 0.0055 - val_accuracy: 0.7505\n",
      "Epoch 910/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7393 - val_loss: 0.0055 - val_accuracy: 0.7220\n",
      "Epoch 911/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7288 - val_loss: 0.0055 - val_accuracy: 0.7695\n",
      "Epoch 912/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7473 - val_loss: 0.0055 - val_accuracy: 0.7195\n",
      "Epoch 913/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7262 - val_loss: 0.0055 - val_accuracy: 0.7315\n",
      "Epoch 914/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7327 - val_loss: 0.0055 - val_accuracy: 0.7645\n",
      "Epoch 915/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7405 - val_loss: 0.0055 - val_accuracy: 0.7355\n",
      "Epoch 916/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7223 - val_loss: 0.0055 - val_accuracy: 0.7515\n",
      "Epoch 917/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7370 - val_loss: 0.0055 - val_accuracy: 0.7720\n",
      "Epoch 918/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7368 - val_loss: 0.0055 - val_accuracy: 0.7505\n",
      "Epoch 919/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7315 - val_loss: 0.0055 - val_accuracy: 0.7430\n",
      "Epoch 920/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7313 - val_loss: 0.0055 - val_accuracy: 0.7560\n",
      "Epoch 921/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7402 - val_loss: 0.0055 - val_accuracy: 0.7340\n",
      "Epoch 922/1000\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0054 - accuracy: 0.7335 - val_loss: 0.0055 - val_accuracy: 0.7305\n",
      "Epoch 923/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7263 - val_loss: 0.0055 - val_accuracy: 0.7705\n",
      "Epoch 924/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7457 - val_loss: 0.0055 - val_accuracy: 0.7455\n",
      "Epoch 925/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7220 - val_loss: 0.0055 - val_accuracy: 0.7575\n",
      "Epoch 926/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7468 - val_loss: 0.0055 - val_accuracy: 0.7510\n",
      "Epoch 927/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7288 - val_loss: 0.0055 - val_accuracy: 0.7690\n",
      "Epoch 928/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7517 - val_loss: 0.0055 - val_accuracy: 0.7480\n",
      "Epoch 929/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7307 - val_loss: 0.0055 - val_accuracy: 0.7605\n",
      "Epoch 930/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7470 - val_loss: 0.0055 - val_accuracy: 0.7615\n",
      "Epoch 931/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7377 - val_loss: 0.0055 - val_accuracy: 0.7535\n",
      "Epoch 932/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7247 - val_loss: 0.0055 - val_accuracy: 0.7485\n",
      "Epoch 933/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7388 - val_loss: 0.0055 - val_accuracy: 0.7345\n",
      "Epoch 934/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7243 - val_loss: 0.0055 - val_accuracy: 0.7340\n",
      "Epoch 935/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7283 - val_loss: 0.0055 - val_accuracy: 0.7270\n",
      "Epoch 936/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7358 - val_loss: 0.0055 - val_accuracy: 0.7325\n",
      "Epoch 937/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7222 - val_loss: 0.0055 - val_accuracy: 0.7765\n",
      "Epoch 938/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7425 - val_loss: 0.0055 - val_accuracy: 0.7625\n",
      "Epoch 939/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7437 - val_loss: 0.0055 - val_accuracy: 0.7615\n",
      "Epoch 940/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7328 - val_loss: 0.0055 - val_accuracy: 0.7290\n",
      "Epoch 941/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7352 - val_loss: 0.0055 - val_accuracy: 0.7580\n",
      "Epoch 942/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7308 - val_loss: 0.0055 - val_accuracy: 0.7760\n",
      "Epoch 943/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7317 - val_loss: 0.0055 - val_accuracy: 0.7435\n",
      "Epoch 944/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7263 - val_loss: 0.0055 - val_accuracy: 0.7630\n",
      "Epoch 945/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7510 - val_loss: 0.0055 - val_accuracy: 0.7460\n",
      "Epoch 946/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7408 - val_loss: 0.0055 - val_accuracy: 0.7475\n",
      "Epoch 947/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7325 - val_loss: 0.0055 - val_accuracy: 0.7525\n",
      "Epoch 948/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7380 - val_loss: 0.0055 - val_accuracy: 0.7310\n",
      "Epoch 949/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7350 - val_loss: 0.0055 - val_accuracy: 0.7080\n",
      "Epoch 950/1000\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0054 - accuracy: 0.7255 - val_loss: 0.0055 - val_accuracy: 0.7350\n",
      "Epoch 951/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7345 - val_loss: 0.0055 - val_accuracy: 0.7470\n",
      "Epoch 952/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7338 - val_loss: 0.0055 - val_accuracy: 0.7440\n",
      "Epoch 953/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7330 - val_loss: 0.0055 - val_accuracy: 0.7680\n",
      "Epoch 954/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7323 - val_loss: 0.0055 - val_accuracy: 0.7650\n",
      "Epoch 955/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7335 - val_loss: 0.0055 - val_accuracy: 0.7750\n",
      "Epoch 956/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7382 - val_loss: 0.0055 - val_accuracy: 0.7700\n",
      "Epoch 957/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7483 - val_loss: 0.0055 - val_accuracy: 0.7160\n",
      "Epoch 958/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7248 - val_loss: 0.0055 - val_accuracy: 0.7740\n",
      "Epoch 959/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7382 - val_loss: 0.0055 - val_accuracy: 0.7455\n",
      "Epoch 960/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7310 - val_loss: 0.0055 - val_accuracy: 0.7740\n",
      "Epoch 961/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7438 - val_loss: 0.0055 - val_accuracy: 0.7285\n",
      "Epoch 962/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7367 - val_loss: 0.0055 - val_accuracy: 0.7160\n",
      "Epoch 963/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7270 - val_loss: 0.0055 - val_accuracy: 0.7370\n",
      "Epoch 964/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7282 - val_loss: 0.0055 - val_accuracy: 0.7680\n",
      "Epoch 965/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7412 - val_loss: 0.0055 - val_accuracy: 0.7560\n",
      "Epoch 966/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7278 - val_loss: 0.0055 - val_accuracy: 0.7710\n",
      "Epoch 967/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7350 - val_loss: 0.0055 - val_accuracy: 0.7490\n",
      "Epoch 968/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7343 - val_loss: 0.0055 - val_accuracy: 0.7550\n",
      "Epoch 969/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7447 - val_loss: 0.0055 - val_accuracy: 0.7155\n",
      "Epoch 970/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7232 - val_loss: 0.0055 - val_accuracy: 0.7685\n",
      "Epoch 971/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7407 - val_loss: 0.0055 - val_accuracy: 0.7525\n",
      "Epoch 972/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7327 - val_loss: 0.0055 - val_accuracy: 0.7535\n",
      "Epoch 973/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7318 - val_loss: 0.0055 - val_accuracy: 0.7670\n",
      "Epoch 974/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7387 - val_loss: 0.0055 - val_accuracy: 0.7550\n",
      "Epoch 975/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7422 - val_loss: 0.0055 - val_accuracy: 0.7085\n",
      "Epoch 976/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7257 - val_loss: 0.0055 - val_accuracy: 0.7095\n",
      "Epoch 977/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7340 - val_loss: 0.0055 - val_accuracy: 0.7510\n",
      "Epoch 978/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7257 - val_loss: 0.0055 - val_accuracy: 0.7600\n",
      "Epoch 979/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7365 - val_loss: 0.0055 - val_accuracy: 0.7610\n",
      "Epoch 980/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7348 - val_loss: 0.0055 - val_accuracy: 0.7405\n",
      "Epoch 981/1000\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0054 - accuracy: 0.7383 - val_loss: 0.0055 - val_accuracy: 0.7550\n",
      "Epoch 982/1000\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0054 - accuracy: 0.7335 - val_loss: 0.0055 - val_accuracy: 0.7665\n",
      "Epoch 983/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7443 - val_loss: 0.0055 - val_accuracy: 0.7420\n",
      "Epoch 984/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7317 - val_loss: 0.0055 - val_accuracy: 0.7725\n",
      "Epoch 985/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7377 - val_loss: 0.0055 - val_accuracy: 0.7605\n",
      "Epoch 986/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7380 - val_loss: 0.0055 - val_accuracy: 0.7425\n",
      "Epoch 987/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7370 - val_loss: 0.0055 - val_accuracy: 0.7455\n",
      "Epoch 988/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7295 - val_loss: 0.0055 - val_accuracy: 0.7625\n",
      "Epoch 989/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7438 - val_loss: 0.0055 - val_accuracy: 0.7640\n",
      "Epoch 990/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7400 - val_loss: 0.0055 - val_accuracy: 0.7475\n",
      "Epoch 991/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7317 - val_loss: 0.0055 - val_accuracy: 0.7160\n",
      "Epoch 992/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7335 - val_loss: 0.0055 - val_accuracy: 0.7270\n",
      "Epoch 993/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7287 - val_loss: 0.0055 - val_accuracy: 0.7765\n",
      "Epoch 994/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7452 - val_loss: 0.0055 - val_accuracy: 0.7330\n",
      "Epoch 995/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7365 - val_loss: 0.0055 - val_accuracy: 0.7660\n",
      "Epoch 996/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7348 - val_loss: 0.0055 - val_accuracy: 0.7720\n",
      "Epoch 997/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7407 - val_loss: 0.0055 - val_accuracy: 0.7595\n",
      "Epoch 998/1000\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0054 - accuracy: 0.7405 - val_loss: 0.0055 - val_accuracy: 0.7435\n",
      "Epoch 999/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7318 - val_loss: 0.0055 - val_accuracy: 0.7495\n",
      "Epoch 1000/1000\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0054 - accuracy: 0.7235 - val_loss: 0.0055 - val_accuracy: 0.7715\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential() #Sequentioal\n",
    "\n",
    "model.add(keras.layers.Dense(input_dim = 10, units = 10, activation= \"tanh\",kernel_initializer =\"HeNormal\" )) \n",
    "model.add(keras.layers.Dense(20, activation= \"tanh\")) \n",
    "model.add(keras.layers.Dense(50, activation= \"tanh\"))  \n",
    "model.add(keras.layers.Dense(100, activation= \"tanh\")) \n",
    "model.add(keras.layers.Dense(120, activation= \"tanh\")) \n",
    "model.add(keras.layers.Dense(50, activation= \"tanh\"))\n",
    "model.add(keras.layers.Dense(10, activation= \"tanh\"))\n",
    "\n",
    "model.compile(loss = \"mse\",\n",
    "              optimizer = \"adam\",\n",
    "              metrics = [\"accuracy\"])\n",
    "history = model.fit(x = nF_train, y = Q_train, validation_data=(nF_val, Q_val),epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3b64e573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 286us/step - loss: 0.0053 - accuracy: 0.7605\n"
     ]
    }
   ],
   "source": [
    "#nF 학습 후 nF accuracy\n",
    "result = model.evaluate(nF_test, Q_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1b2a57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "2021.10.26.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
