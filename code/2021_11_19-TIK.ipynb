{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6nP75H4DiluS"
   },
   "source": [
    "# 이해를 위한 정리\n",
    "\n",
    "* $AQ = F$\n",
    "* $Q = A^{-1}F$\n",
    "* $A^TAQ = A^TF  \\to Q = (A^TA)^{-1}A^TF$\n",
    "* $\\alpha Q_\\alpha + A^TAQ_\\alpha = A^TF \\to Q_\\alpha = (\\alpha I + A^TA)^{-1} A^TF$\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " ## $Q_\\alpha = (\\alpha I + A^TA)^{-1} A^TF$\n",
    "\n",
    " or\n",
    "\n",
    " ## $Q_n = \\frac{F_n}{\\alpha e^{n^2T} + e^{-n^2T}}, \\quad\\quad n = 1, 2, \\cdots , N$\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "invA = np.diag(1/(alpha*np.exp((np.arange(1, N+1))**2*T)+np.exp(-(np.arange(1, N+1))**2*T)))\n",
    "hatQ = invA@F\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JtyAoVp059M6"
   },
   "source": [
    "# Generate Data \n",
    "\n",
    "\n",
    "*   generate_Q\n",
    "*   sol_act\n",
    "*   noise_data\n",
    "*   sol_Tik\n",
    "*   result_gen_data\n",
    "*   result_Lcurve\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "f459TdI-52dT"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "T = 1\n",
    "delta = 0.01\n",
    "N = 5\n",
    "M = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "qzywCujn5793"
   },
   "outputs": [],
   "source": [
    "def generate_Q(N,  M, tau):\n",
    "    ii = 0\n",
    "    tore = tau*np.sqrt(2/np.pi)\n",
    "    Q = []\n",
    "    while ii < M:\n",
    "        tempQ = 2*tore*np.random.rand(N) - tore\n",
    "        tempQ = np.array(tempQ)\n",
    "        if np.linalg.norm(tempQ) <= tore:\n",
    "            Q = np.append(Q, tempQ)\n",
    "            ii += 1\n",
    "    return (Q.reshape(-1, N))\n",
    "\n",
    "def sol_act(Q, T):\n",
    "    N = len(Q[0])\n",
    "    A = np.diag(np.exp(-(np.arange(1, N+1))**2*T))\n",
    "    F = A@Q.T #A = NxN, Q = MxN, Q.T = NxM , F = NxM\n",
    "    return F\n",
    "\n",
    "def noise_data(F, delta):\n",
    "    e = 2*np.random.rand(len(F[:,0]), len(F[0])) - 1\n",
    "    N = len(F[:])\n",
    "    for m in range(len(F[0])):\n",
    "        norm = np.linalg.norm(F[:,m])\n",
    "        e[:, m] = e[:, 0]*norm*delta\n",
    "    nF = F+e\n",
    "    return nF\n",
    "\n",
    "def sol_Tik(alpha, T, F):\n",
    "    N = len(F[:])\n",
    "    invA = np.diag(1/(alpha*np.exp((np.arange(1, N+1))**2*T)+np.exp(-(np.arange(1, N+1))**2*T))) # A = NxN\n",
    "    hatQ = invA@F \n",
    "    return hatQ\n",
    "\n",
    "def result_gen_data(N, M, tau, Q, delta):\n",
    "    #Q = generate_Q(N, M, tau)\n",
    "    T = 1\n",
    "    F = sol_act(Q, T)\n",
    "    nF = noise_data(F, delta)\n",
    "    np.savetxt('Q.txt', Q.T, fmt='%8f', delimiter = ',', header='')\n",
    "    np.savetxt('F.txt', F, fmt='%8f', delimiter = ',', header='')\n",
    "    np.savetxt('nF.txt', nF, fmt='%8f', delimiter = ',', header='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ajr9blR56SX6",
    "outputId": "ab004730-a04d-4d99-b08a-6c01effd4919"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.13293172, -0.08752146, -0.27657753, -0.29722228, -0.21239982],\n",
       "       [ 0.32852912, -0.19568233,  0.28826068,  0.1796691 ,  0.54488975],\n",
       "       [-0.51237417,  0.16819993,  0.09193486,  0.11643878,  0.03872003],\n",
       "       ...,\n",
       "       [-0.38019025,  0.03641237, -0.11992313, -0.27102483, -0.50392846],\n",
       "       [-0.03856122, -0.37432907,  0.32256312,  0.4006487 ,  0.19789026],\n",
       "       [ 0.18281638, -0.31691364, -0.51616166, -0.35331218, -0.32940261]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = generate_Q(N, M, tau = 1)\n",
    "F = sol_act(Q, T)\n",
    "nF = noise_data(F, delta)\n",
    "result_gen_data(N, M, tau = 1, Q = Q, delta = 0.01)\n",
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Qym6LRUM6S0q"
   },
   "outputs": [],
   "source": [
    "def each_data_bestAlpha(Q, N, M, tau, delta, min_al):\n",
    "    #get data\n",
    "    for i in range(M):\n",
    "    Q_i = Q[i, :]\n",
    "    \n",
    "    T = 1\n",
    "    F = sol_act(Q, T)\n",
    "    nF = noise_data(F, delta)\n",
    "    \n",
    "    al = np.linspace(0, min_al, 100)\n",
    "    q1 = []\n",
    "    q2 = []\n",
    "    for ii in range(len(al)):\n",
    "        q1.append(sol_Tik(10**al[ii], T, F))\n",
    "        q2.append(sol_Tik(10**al[ii], T, nF))\n",
    "    q1 = np.array(q1) \n",
    "    q2 = np.array(q2)\n",
    "    \n",
    "    n = np.arange(1, N+1)\n",
    "    A = np.diag(np.exp(-n**2*T))\n",
    "    \n",
    "    x1 = []\n",
    "    x2 = []\n",
    "    y1 = []\n",
    "    y2 = []\n",
    "\n",
    "    for i in range(len(al)):\n",
    "        x1.append(np.linalg.norm(A@q1[i]-F))\n",
    "        y1.append(np.linalg.norm(q1[i]))\n",
    "        x2.append(np.linalg.norm(A@q2[i]-nF))\n",
    "        y2.append(np.linalg.norm(q2[i]))\n",
    "    \n",
    "    fig = plt.figure(figsize = (10,10))\n",
    "    fig.add_subplot(2, 1, 1)\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"log\")\n",
    "    #plt.xlabel(\"$\\||Aq-F\\||$\")\n",
    "    plt.plot(x1, y1)\n",
    "    plt.title(\"without noise\")\n",
    "\n",
    "    \n",
    "    fig.add_subplot(2, 1, 2)\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.plot(x2, y2)\n",
    "    plt.title(\"with noise\")     \n",
    "\n",
    "    \n",
    "    plt.savefig('L-curve1')\n",
    "    return np.flip(np.array(x1)), np.flip(np.array(y1)), np.flip(np.array(x2)), np.flip(np.array(y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 611
    },
    "id": "wC2YcpV-6lPL",
    "outputId": "0b2c817b-aec3-4002-f375-9fbc56af8912"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1, y1, x2, y2 = result_Lcurve(10, 1, 0.01, -20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrSjfJSM6u8q"
   },
   "source": [
    "* Find corner of L-curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "w1_y5K_25yj3",
    "outputId": "6e0e58b1-5211-48e0-eace-24563dd2779b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1f17ebd3400>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (6,4)\n",
    "plt.scatter(x2, y2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "cpVuKsxJ4UlB",
    "outputId": "b4c426c8-3113-4632-e633-f366e4520ef1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (6,4)\n",
    "plt.scatter(x2, y2)\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 863
    },
    "id": "GM2b2JDG3va2",
    "outputId": "0d39d662-b425-4f10-e2f2-4c323291e7e8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_x2 = np.log10(x2)\n",
    "log_y2 = np.log10(y2)\n",
    "plt.rcParams[\"figure.figsize\"] = (15,15)\n",
    "plt.scatter(log_x2, log_y2, s = 10)\n",
    "\n",
    "\n",
    "plt.savefig(\"log_x2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M3qikAahMGp0"
   },
   "source": [
    "### 동일한 linspace로 자른 후 cos 값 구하기 --> 정밀성이 너무 떨어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NfSK29NYFLEg"
   },
   "outputs": [],
   "source": [
    "#def find_nearest(array,value):\n",
    "#    idx = np.searchsorted(array, value, side=\"left\")\n",
    "#    if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
    "#        return idx-1\n",
    "#    else:\n",
    "#        return idx\n",
    "#O1 = []\n",
    "#max_log_x2 = np.max(log_x2)\n",
    "#min_log_x2 = np.min(log_x2)\n",
    "#log_al = np.linspace(min_log_x2, max_log_x2, 500)\n",
    "#for i in range(500):\n",
    "#    idx = find_nearest(log_x2, log_al[i])\n",
    "#    O1.append([log_x2[idx], log_y2[idx]])\n",
    "#O1 = np.array(O1)\n",
    "#v = []\n",
    "#for i in range(len(O1) - 1):\n",
    "#    v.append(O1[i+1]-O1[i])\n",
    "#v = np.array(v)\n",
    "#\n",
    "#cos = []\n",
    "#\n",
    "#for i in range(len(v)-1):\n",
    "#    v1_norm = np.linalg.norm(v[i])\n",
    "#    v2_norm = np.linalg.norm(v[i+1])\n",
    "#    v_cos = np.dot(v[i], v[i+1])\n",
    "#    cos.append(v_cos)\n",
    "#a = np.argmin(cos)\n",
    "#cos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CTYxfdpuM67t"
   },
   "source": [
    "## v[i]$\\bullet$v[i+k] 사용하여 cos 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y1xiROiWHjDP",
    "outputId": "a86c58cb-ade0-42ff-88d8-2c678f543012"
   },
   "outputs": [],
   "source": [
    "def find_best_idx(log_x2, log_y2):\n",
    "    O = np.column_stack((log_x2, log_y2))\n",
    "    v = []\n",
    "    k = 10\n",
    "    for i in range(len(O) - 1 - k):\n",
    "        v.append(O[i+k]-O[i])\n",
    "    v\n",
    "\n",
    "    cos = []\n",
    "\n",
    "    for i in range(len(v)-1-k):\n",
    "        v1_norm = np.linalg.norm(v[i])\n",
    "        v2_norm = np.linalg.norm(v[i+k])\n",
    "        v_cos = np.dot(v[i], v[i+k])/(v1_norm*v2_norm)\n",
    "        cos.append(v_cos)\n",
    "    a = np.argmin(cos) + k\n",
    "    return a   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Di5v1yGcNpz1",
    "outputId": "697c3d77-c633-443e-9827-3bad3f667727"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8480358684358048e-15"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = find_best_idx(log_x2, log_y2)\n",
    "al = np.linspace(0, -20, 100)\n",
    "alpha = 10**al[a]\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpha_target\n",
    "#[1.1233240329780266e-15,\n",
    "# 3.4304692863149193e-07,\n",
    "# 1.2915496650148826e-09,\n",
    "# 9.111627561154887e-05,\n",
    "# 1.3219411484660288e-08,\n",
    "# 8.302175681319736e-09,\n",
    "# 5.214008287999695e-09,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.32852912, -0.19568233,  0.28826068,  0.1796691 ,  0.54488975])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모든 Q의 데이터 (M개)에 대하여 alpha값 뽑아내기\n",
    "Q[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.89028461e-02,  1.20859110e-01, -1.88491925e-01, ...,\n",
       "        -1.39864175e-01, -1.41858798e-02,  6.72543868e-02],\n",
       "       [-1.60301151e-03, -3.58404681e-03,  3.08068921e-03, ...,\n",
       "         6.66915778e-04, -6.85607613e-03, -5.80447582e-03],\n",
       "       [-3.41323794e-05,  3.55741939e-05,  1.13456629e-05, ...,\n",
       "        -1.47996894e-05,  3.98074519e-05, -6.36994097e-05],\n",
       "       [-3.34479614e-08,  2.02190931e-08,  1.31034583e-08, ...,\n",
       "        -3.04998268e-08,  4.50870719e-08, -3.97600475e-08],\n",
       "       [-2.94979682e-12,  7.56739832e-12,  5.37741538e-13, ...,\n",
       "        -6.99853018e-12,  2.74828887e-12, -4.57472492e-12]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4G78S8Id7By6"
   },
   "outputs": [],
   "source": [
    "hatQ = sol_Tik(alpha, T, F)\n",
    "nF = noise_data(F, delta = delta)\n",
    "\n",
    "np.savetxt('hatQ.txt', hatQ, fmt='%8f', delimiter = ',', header='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Ev3P8uWXXa8P"
   },
   "outputs": [],
   "source": [
    "arr = []\n",
    "for i in range(M):\n",
    "    arr.append(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "CE_ORsOJncVq"
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "#column name에 data가 들어가있기 때문에 \"names = arr\" 로 처리해 줍니다. arr은 1 ~ len(F)의 숫자가 담겨있습니다.\n",
    "dataF = pd.read_csv('C:/Users/Administrator/F.txt', sep = ',', names = arr)\n",
    "#dataQ = pd.read_csv('C:/Users/Administrator/Q.txt', sep = ',', names = arr).to_numpy().T\n",
    "dataQ = pd.read_csv('C:/Users/Administrator/hatQ.txt', sep = ',', names = arr)\n",
    "data_nF = pd.read_csv('C:/Users/Administrator/nF.txt', sep = ',', names = arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_arr(A):\n",
    "    arA = []\n",
    "    for j in range(len(A.iloc[0, :])):\n",
    "        arA1 = []\n",
    "        for i in range(len(A.iloc[:,0])):\n",
    "            tmpA = A.iloc[:,j][i]\n",
    "            arA1.append(tmpA)\n",
    "        arA.append(arA1)\n",
    "    return arA\n",
    "\n",
    "#make array\n",
    "arrF = make_arr(dataF)\n",
    "dataF = np.array(arrF)\n",
    "\n",
    "arrQ = make_arr(dataQ)\n",
    "dataQ = np.array(arrQ)\n",
    "\n",
    "arr_nF = make_arr(data_nF)\n",
    "data_nF = np.array(arr_nF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iaFCQA-SojWq",
    "outputId": "06bdd489-aae1-4bc7-a7f5-b39e0b82add5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 5), (2000, 5), (2000, 5)\n",
      "(6000, 5), (2000, 5), (2000, 5)\n",
      "(6000, 5), (2000, 5), (2000, 5)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "train_size = math.floor(len(dataF)*0.6) # train : 60%\n",
    "val_size = math.floor(len(dataF)*0.2) #val : 20%\n",
    "test_size = math.floor(len(dataF)*0.2) #test : 20%\n",
    "#generate F_data, F_val, F_test\n",
    "F_data = dataF[:train_size, :]\n",
    "F_val = dataF[train_size:(val_size + train_size), :]\n",
    "F_test = dataF[(val_size + train_size):(val_size + train_size + test_size), :]\n",
    "\n",
    "#generate Q_data, Q_val, Q_test\n",
    "Q_data = dataQ[:train_size, :]\n",
    "Q_val = dataQ[train_size:(val_size + train_size), :]\n",
    "Q_test = dataQ[(val_size + train_size):(val_size + train_size + test_size), :]\n",
    "\n",
    "#generate nF_data, nF_val, nF_test\n",
    "nF_data = data_nF[:train_size, :]\n",
    "nF_val = data_nF[train_size:(val_size + train_size), :]\n",
    "nF_test = data_nF[(val_size + train_size):(val_size + train_size + test_size), :]\n",
    "\n",
    "print(f'{F_data.shape}, {F_test.shape}, {F_val.shape}')\n",
    "print(f'{Q_data.shape}, {Q_test.shape}, {Q_val.shape}')\n",
    "print(f'{nF_data.shape}, {nF_test.shape}, {nF_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "lYFPm85VU_8m"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.Sequential() #Sequential\n",
    "\n",
    "model.add(keras.layers.Dense(input_dim = N, units = 10, activation= \"tanh\",kernel_initializer =\"HeNormal\" )) \n",
    "model.add(keras.layers.Dense(20, activation= \"tanh\")) \n",
    "model.add(keras.layers.Dense(50, activation= \"tanh\"))  \n",
    "model.add(keras.layers.Dense(100, activation= \"tanh\")) \n",
    "model.add(keras.layers.Dense(120, activation= \"tanh\")) \n",
    "model.add(keras.layers.Dense(50, activation= \"tanh\"))\n",
    "model.add(keras.layers.Dense(N, activation= \"tanh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ktp8oE6nYauf",
    "outputId": "99777f50-04f5-4d53-dff7-fd6b0f54b552"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.EarlyStopping at 0x1f135b375b0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    F_train = tf.constant(F_data)\n",
    "    Q_train = tf.constant(Q_data)\n",
    "    nF_train = tf.constant(nF_data)\n",
    "tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', min_delta=0, patience=0, verbose=0,\n",
    "    mode='auto', baseline=None, restore_best_weights=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 494
    },
    "id": "tUW16hZZYecK",
    "outputId": "21a2d7ce-2945-419f-f3df-5c09ec4872da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "188/188 [==============================] - 0s 922us/step - loss: 0.0359 - accuracy: 0.5292 - val_loss: 0.0293 - val_accuracy: 0.5840\n",
      "Epoch 2/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0305 - accuracy: 0.5713 - val_loss: 0.0294 - val_accuracy: 0.5905\n",
      "Epoch 3/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0306 - accuracy: 0.5755 - val_loss: 0.0292 - val_accuracy: 0.5840\n",
      "Epoch 4/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0303 - accuracy: 0.5688 - val_loss: 0.0294 - val_accuracy: 0.5620\n",
      "Epoch 5/500\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0303 - accuracy: 0.5782 - val_loss: 0.0292 - val_accuracy: 0.5905\n",
      "Epoch 6/500\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0303 - accuracy: 0.5717 - val_loss: 0.0292 - val_accuracy: 0.5920\n",
      "Epoch 7/500\n",
      "188/188 [==============================] - 0s 580us/step - loss: 0.0304 - accuracy: 0.5795 - val_loss: 0.0293 - val_accuracy: 0.5990\n",
      "Epoch 8/500\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0303 - accuracy: 0.5705 - val_loss: 0.0293 - val_accuracy: 0.5745\n",
      "Epoch 9/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0303 - accuracy: 0.5747 - val_loss: 0.0293 - val_accuracy: 0.5960\n",
      "Epoch 10/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0303 - accuracy: 0.5740 - val_loss: 0.0292 - val_accuracy: 0.5925\n",
      "Epoch 11/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0303 - accuracy: 0.5742 - val_loss: 0.0293 - val_accuracy: 0.5900\n",
      "Epoch 12/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0303 - accuracy: 0.5652 - val_loss: 0.0292 - val_accuracy: 0.6045\n",
      "Epoch 13/500\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0303 - accuracy: 0.5715 - val_loss: 0.0292 - val_accuracy: 0.5970\n",
      "Epoch 14/500\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0303 - accuracy: 0.5698 - val_loss: 0.0291 - val_accuracy: 0.6085\n",
      "Epoch 15/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0303 - accuracy: 0.5705 - val_loss: 0.0292 - val_accuracy: 0.6090\n",
      "Epoch 16/500\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0303 - accuracy: 0.5747 - val_loss: 0.0292 - val_accuracy: 0.5905\n",
      "Epoch 17/500\n",
      "188/188 [==============================] - 0s 575us/step - loss: 0.0303 - accuracy: 0.5733 - val_loss: 0.0292 - val_accuracy: 0.5545\n",
      "Epoch 18/500\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0303 - accuracy: 0.5760 - val_loss: 0.0292 - val_accuracy: 0.5845\n",
      "Epoch 19/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0303 - accuracy: 0.5600 - val_loss: 0.0292 - val_accuracy: 0.6040\n",
      "Epoch 20/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0303 - accuracy: 0.5740 - val_loss: 0.0291 - val_accuracy: 0.6075\n",
      "Epoch 21/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0302 - accuracy: 0.5662 - val_loss: 0.0292 - val_accuracy: 0.6020\n",
      "Epoch 22/500\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0303 - accuracy: 0.5772 - val_loss: 0.0292 - val_accuracy: 0.6045\n",
      "Epoch 23/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0303 - accuracy: 0.5753 - val_loss: 0.0292 - val_accuracy: 0.5900\n",
      "Epoch 24/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0303 - accuracy: 0.5747 - val_loss: 0.0293 - val_accuracy: 0.5975\n",
      "Epoch 25/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0303 - accuracy: 0.5770 - val_loss: 0.0291 - val_accuracy: 0.6070\n",
      "Epoch 26/500\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0303 - accuracy: 0.5757 - val_loss: 0.0296 - val_accuracy: 0.5490\n",
      "Epoch 27/500\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0302 - accuracy: 0.5767 - val_loss: 0.0291 - val_accuracy: 0.5740\n",
      "Epoch 28/500\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0302 - accuracy: 0.5770 - val_loss: 0.0294 - val_accuracy: 0.5545\n",
      "Epoch 29/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0303 - accuracy: 0.5752 - val_loss: 0.0289 - val_accuracy: 0.6035\n",
      "Epoch 30/500\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0303 - accuracy: 0.5765 - val_loss: 0.0283 - val_accuracy: 0.6035\n",
      "Epoch 31/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0301 - accuracy: 0.5805 - val_loss: 0.0285 - val_accuracy: 0.5555\n",
      "Epoch 32/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0299 - accuracy: 0.5800 - val_loss: 0.0313 - val_accuracy: 0.5775\n",
      "Epoch 33/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0303 - accuracy: 0.5838 - val_loss: 0.0288 - val_accuracy: 0.6010\n",
      "Epoch 34/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0290 - accuracy: 0.5967 - val_loss: 0.0258 - val_accuracy: 0.6600\n",
      "Epoch 35/500\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0278 - accuracy: 0.6150 - val_loss: 0.0367 - val_accuracy: 0.5540\n",
      "Epoch 36/500\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0271 - accuracy: 0.6218 - val_loss: 0.0278 - val_accuracy: 0.6100\n",
      "Epoch 37/500\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0250 - accuracy: 0.6408 - val_loss: 0.0247 - val_accuracy: 0.5915\n",
      "Epoch 38/500\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0232 - accuracy: 0.6540 - val_loss: 0.0233 - val_accuracy: 0.6530\n",
      "Epoch 39/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0206 - accuracy: 0.6838 - val_loss: 0.0242 - val_accuracy: 0.6260\n",
      "Epoch 40/500\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0187 - accuracy: 0.6983 - val_loss: 0.0142 - val_accuracy: 0.7400\n",
      "Epoch 41/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0162 - accuracy: 0.7207 - val_loss: 0.0145 - val_accuracy: 0.7695\n",
      "Epoch 42/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0164 - accuracy: 0.7212 - val_loss: 0.0146 - val_accuracy: 0.7310\n",
      "Epoch 43/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0156 - accuracy: 0.7297 - val_loss: 0.0149 - val_accuracy: 0.7435\n",
      "Epoch 44/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0157 - accuracy: 0.7278 - val_loss: 0.0177 - val_accuracy: 0.6975\n",
      "Epoch 45/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0158 - accuracy: 0.7230 - val_loss: 0.0153 - val_accuracy: 0.7240\n",
      "Epoch 46/500\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0150 - accuracy: 0.7407 - val_loss: 0.0138 - val_accuracy: 0.7430\n",
      "Epoch 47/500\n",
      "188/188 [==============================] - 0s 564us/step - loss: 0.0153 - accuracy: 0.7317 - val_loss: 0.0133 - val_accuracy: 0.7580\n",
      "Epoch 48/500\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0148 - accuracy: 0.7432 - val_loss: 0.0168 - val_accuracy: 0.7055\n",
      "Epoch 49/500\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0143 - accuracy: 0.7437 - val_loss: 0.0131 - val_accuracy: 0.7580\n",
      "Epoch 50/500\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0144 - accuracy: 0.7445 - val_loss: 0.0131 - val_accuracy: 0.7650\n",
      "Epoch 51/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0143 - accuracy: 0.7425 - val_loss: 0.0145 - val_accuracy: 0.7560\n",
      "Epoch 52/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0135 - accuracy: 0.7505 - val_loss: 0.0135 - val_accuracy: 0.7525\n",
      "Epoch 53/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0127 - accuracy: 0.7660 - val_loss: 0.0122 - val_accuracy: 0.7850\n",
      "Epoch 54/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0125 - accuracy: 0.7725 - val_loss: 0.0121 - val_accuracy: 0.7935\n",
      "Epoch 55/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0126 - accuracy: 0.7687 - val_loss: 0.0125 - val_accuracy: 0.7785\n",
      "Epoch 56/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0129 - accuracy: 0.7668 - val_loss: 0.0123 - val_accuracy: 0.7880\n",
      "Epoch 57/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 548us/step - loss: 0.0127 - accuracy: 0.7653 - val_loss: 0.0140 - val_accuracy: 0.7485\n",
      "Epoch 58/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0130 - accuracy: 0.7610 - val_loss: 0.0120 - val_accuracy: 0.7835\n",
      "Epoch 59/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0127 - accuracy: 0.7663 - val_loss: 0.0120 - val_accuracy: 0.7795\n",
      "Epoch 60/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0127 - accuracy: 0.7630 - val_loss: 0.0121 - val_accuracy: 0.7940\n",
      "Epoch 61/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0127 - accuracy: 0.7670 - val_loss: 0.0121 - val_accuracy: 0.7980\n",
      "Epoch 62/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0129 - accuracy: 0.7592 - val_loss: 0.0126 - val_accuracy: 0.7745\n",
      "Epoch 63/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0126 - accuracy: 0.7703 - val_loss: 0.0123 - val_accuracy: 0.7780\n",
      "Epoch 64/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0125 - accuracy: 0.7730 - val_loss: 0.0122 - val_accuracy: 0.7745\n",
      "Epoch 65/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0126 - accuracy: 0.7677 - val_loss: 0.0127 - val_accuracy: 0.7890\n",
      "Epoch 66/500\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0126 - accuracy: 0.7697 - val_loss: 0.0122 - val_accuracy: 0.7855\n",
      "Epoch 67/500\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0125 - accuracy: 0.7702 - val_loss: 0.0125 - val_accuracy: 0.7675\n",
      "Epoch 68/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0128 - accuracy: 0.7590 - val_loss: 0.0149 - val_accuracy: 0.7635\n",
      "Epoch 69/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0130 - accuracy: 0.7613 - val_loss: 0.0120 - val_accuracy: 0.7995\n",
      "Epoch 70/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0125 - accuracy: 0.7713 - val_loss: 0.0119 - val_accuracy: 0.8025\n",
      "Epoch 71/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0125 - accuracy: 0.7678 - val_loss: 0.0120 - val_accuracy: 0.7995\n",
      "Epoch 72/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0126 - accuracy: 0.7695 - val_loss: 0.0124 - val_accuracy: 0.7875\n",
      "Epoch 73/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0126 - accuracy: 0.7667 - val_loss: 0.0129 - val_accuracy: 0.7735\n",
      "Epoch 74/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0125 - accuracy: 0.7703 - val_loss: 0.0120 - val_accuracy: 0.7865\n",
      "Epoch 75/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0125 - accuracy: 0.7772 - val_loss: 0.0123 - val_accuracy: 0.7695\n",
      "Epoch 76/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0126 - accuracy: 0.7648 - val_loss: 0.0121 - val_accuracy: 0.7825\n",
      "Epoch 77/500\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0127 - accuracy: 0.7695 - val_loss: 0.0119 - val_accuracy: 0.7965\n",
      "Epoch 78/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0126 - accuracy: 0.7662 - val_loss: 0.0120 - val_accuracy: 0.7890\n",
      "Epoch 79/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0125 - accuracy: 0.7743 - val_loss: 0.0121 - val_accuracy: 0.7940\n",
      "Epoch 80/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0123 - accuracy: 0.7753 - val_loss: 0.0124 - val_accuracy: 0.7925\n",
      "Epoch 81/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0124 - accuracy: 0.7728 - val_loss: 0.0127 - val_accuracy: 0.7570\n",
      "Epoch 82/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0128 - accuracy: 0.7597 - val_loss: 0.0133 - val_accuracy: 0.7560\n",
      "Epoch 83/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0124 - accuracy: 0.7758 - val_loss: 0.0120 - val_accuracy: 0.7890\n",
      "Epoch 84/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0126 - accuracy: 0.7653 - val_loss: 0.0120 - val_accuracy: 0.8000\n",
      "Epoch 85/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0123 - accuracy: 0.7848 - val_loss: 0.0119 - val_accuracy: 0.8000\n",
      "Epoch 86/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0124 - accuracy: 0.7745 - val_loss: 0.0118 - val_accuracy: 0.8020\n",
      "Epoch 87/500\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0124 - accuracy: 0.7755 - val_loss: 0.0120 - val_accuracy: 0.7980\n",
      "Epoch 88/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0125 - accuracy: 0.7708 - val_loss: 0.0120 - val_accuracy: 0.7950\n",
      "Epoch 89/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0124 - accuracy: 0.7710 - val_loss: 0.0121 - val_accuracy: 0.7975\n",
      "Epoch 90/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0125 - accuracy: 0.7695 - val_loss: 0.0135 - val_accuracy: 0.7730\n",
      "Epoch 91/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0129 - accuracy: 0.7630 - val_loss: 0.0120 - val_accuracy: 0.7830\n",
      "Epoch 92/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0124 - accuracy: 0.7760 - val_loss: 0.0121 - val_accuracy: 0.7805\n",
      "Epoch 93/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0123 - accuracy: 0.7782 - val_loss: 0.0122 - val_accuracy: 0.7985\n",
      "Epoch 94/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0125 - accuracy: 0.7675 - val_loss: 0.0123 - val_accuracy: 0.7815\n",
      "Epoch 95/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0124 - accuracy: 0.7697 - val_loss: 0.0121 - val_accuracy: 0.7745\n",
      "Epoch 96/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0123 - accuracy: 0.7743 - val_loss: 0.0119 - val_accuracy: 0.8005\n",
      "Epoch 97/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0123 - accuracy: 0.7758 - val_loss: 0.0122 - val_accuracy: 0.7910\n",
      "Epoch 98/500\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0124 - accuracy: 0.7727 - val_loss: 0.0119 - val_accuracy: 0.7990\n",
      "Epoch 99/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0125 - accuracy: 0.7713 - val_loss: 0.0124 - val_accuracy: 0.7735\n",
      "Epoch 100/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0126 - accuracy: 0.7693 - val_loss: 0.0133 - val_accuracy: 0.7600\n",
      "Epoch 101/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0125 - accuracy: 0.7728 - val_loss: 0.0124 - val_accuracy: 0.7810\n",
      "Epoch 102/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0127 - accuracy: 0.7665 - val_loss: 0.0121 - val_accuracy: 0.7795\n",
      "Epoch 103/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0123 - accuracy: 0.7758 - val_loss: 0.0119 - val_accuracy: 0.7980\n",
      "Epoch 104/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0122 - accuracy: 0.7825 - val_loss: 0.0121 - val_accuracy: 0.7985\n",
      "Epoch 105/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0125 - accuracy: 0.7718 - val_loss: 0.0119 - val_accuracy: 0.7875\n",
      "Epoch 106/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0123 - accuracy: 0.7775 - val_loss: 0.0125 - val_accuracy: 0.7735\n",
      "Epoch 107/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0124 - accuracy: 0.7710 - val_loss: 0.0122 - val_accuracy: 0.7840\n",
      "Epoch 108/500\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0124 - accuracy: 0.7748 - val_loss: 0.0119 - val_accuracy: 0.7970\n",
      "Epoch 109/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7818 - val_loss: 0.0118 - val_accuracy: 0.7925\n",
      "Epoch 110/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0123 - accuracy: 0.7842 - val_loss: 0.0119 - val_accuracy: 0.7905\n",
      "Epoch 111/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0125 - accuracy: 0.7688 - val_loss: 0.0119 - val_accuracy: 0.7890\n",
      "Epoch 112/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0123 - accuracy: 0.7728 - val_loss: 0.0119 - val_accuracy: 0.7885\n",
      "Epoch 113/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188/188 [==============================] - 0s 527us/step - loss: 0.0122 - accuracy: 0.7807 - val_loss: 0.0120 - val_accuracy: 0.7840\n",
      "Epoch 114/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0123 - accuracy: 0.7738 - val_loss: 0.0120 - val_accuracy: 0.7925\n",
      "Epoch 115/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0123 - accuracy: 0.7738 - val_loss: 0.0118 - val_accuracy: 0.8060\n",
      "Epoch 116/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0124 - accuracy: 0.7728 - val_loss: 0.0120 - val_accuracy: 0.7825\n",
      "Epoch 117/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0123 - accuracy: 0.7748 - val_loss: 0.0119 - val_accuracy: 0.7930\n",
      "Epoch 118/500\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0124 - accuracy: 0.7737 - val_loss: 0.0119 - val_accuracy: 0.8035\n",
      "Epoch 119/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0123 - accuracy: 0.7770 - val_loss: 0.0119 - val_accuracy: 0.8040\n",
      "Epoch 120/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0124 - accuracy: 0.7740 - val_loss: 0.0122 - val_accuracy: 0.7935\n",
      "Epoch 121/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7773 - val_loss: 0.0121 - val_accuracy: 0.7905\n",
      "Epoch 122/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0123 - accuracy: 0.7785 - val_loss: 0.0123 - val_accuracy: 0.7715\n",
      "Epoch 123/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0125 - accuracy: 0.7750 - val_loss: 0.0127 - val_accuracy: 0.7805\n",
      "Epoch 124/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0123 - accuracy: 0.7760 - val_loss: 0.0123 - val_accuracy: 0.7925\n",
      "Epoch 125/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0124 - accuracy: 0.7690 - val_loss: 0.0119 - val_accuracy: 0.7955\n",
      "Epoch 126/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0124 - accuracy: 0.7735 - val_loss: 0.0122 - val_accuracy: 0.7680\n",
      "Epoch 127/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7820 - val_loss: 0.0120 - val_accuracy: 0.7990\n",
      "Epoch 128/500\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0123 - accuracy: 0.7795 - val_loss: 0.0118 - val_accuracy: 0.8020\n",
      "Epoch 129/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0122 - accuracy: 0.7788 - val_loss: 0.0120 - val_accuracy: 0.7900\n",
      "Epoch 130/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7813 - val_loss: 0.0119 - val_accuracy: 0.8005\n",
      "Epoch 131/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0125 - accuracy: 0.7760 - val_loss: 0.0118 - val_accuracy: 0.8075\n",
      "Epoch 132/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0123 - accuracy: 0.7768 - val_loss: 0.0119 - val_accuracy: 0.8095\n",
      "Epoch 133/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7790 - val_loss: 0.0119 - val_accuracy: 0.7910\n",
      "Epoch 134/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7790 - val_loss: 0.0120 - val_accuracy: 0.7990\n",
      "Epoch 135/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0123 - accuracy: 0.7773 - val_loss: 0.0120 - val_accuracy: 0.7930\n",
      "Epoch 136/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0123 - accuracy: 0.7780 - val_loss: 0.0122 - val_accuracy: 0.7855\n",
      "Epoch 137/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0124 - accuracy: 0.7755 - val_loss: 0.0118 - val_accuracy: 0.8040\n",
      "Epoch 138/500\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0124 - accuracy: 0.7737 - val_loss: 0.0118 - val_accuracy: 0.7995\n",
      "Epoch 139/500\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0123 - accuracy: 0.7782 - val_loss: 0.0118 - val_accuracy: 0.8020\n",
      "Epoch 140/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7772 - val_loss: 0.0118 - val_accuracy: 0.8015\n",
      "Epoch 141/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0123 - accuracy: 0.7717 - val_loss: 0.0119 - val_accuracy: 0.7955\n",
      "Epoch 142/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0122 - accuracy: 0.7807 - val_loss: 0.0121 - val_accuracy: 0.7790\n",
      "Epoch 143/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0123 - accuracy: 0.7805 - val_loss: 0.0123 - val_accuracy: 0.7825\n",
      "Epoch 144/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0125 - accuracy: 0.7693 - val_loss: 0.0119 - val_accuracy: 0.7945\n",
      "Epoch 145/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7802 - val_loss: 0.0120 - val_accuracy: 0.7975\n",
      "Epoch 146/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0125 - accuracy: 0.7722 - val_loss: 0.0118 - val_accuracy: 0.7920\n",
      "Epoch 147/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7797 - val_loss: 0.0119 - val_accuracy: 0.8040\n",
      "Epoch 148/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0122 - accuracy: 0.7787 - val_loss: 0.0120 - val_accuracy: 0.7810\n",
      "Epoch 149/500\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0122 - accuracy: 0.7820 - val_loss: 0.0118 - val_accuracy: 0.8040\n",
      "Epoch 150/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7818 - val_loss: 0.0119 - val_accuracy: 0.8005\n",
      "Epoch 151/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7793 - val_loss: 0.0120 - val_accuracy: 0.7890\n",
      "Epoch 152/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0124 - accuracy: 0.7687 - val_loss: 0.0119 - val_accuracy: 0.8025\n",
      "Epoch 153/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7800 - val_loss: 0.0123 - val_accuracy: 0.7785\n",
      "Epoch 154/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0123 - accuracy: 0.7845 - val_loss: 0.0119 - val_accuracy: 0.7980\n",
      "Epoch 155/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0124 - accuracy: 0.7742 - val_loss: 0.0123 - val_accuracy: 0.7745\n",
      "Epoch 156/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0123 - accuracy: 0.7798 - val_loss: 0.0119 - val_accuracy: 0.7805\n",
      "Epoch 157/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7807 - val_loss: 0.0119 - val_accuracy: 0.7860\n",
      "Epoch 158/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7752 - val_loss: 0.0118 - val_accuracy: 0.8030\n",
      "Epoch 159/500\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0121 - accuracy: 0.7852 - val_loss: 0.0120 - val_accuracy: 0.7835\n",
      "Epoch 160/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0130 - accuracy: 0.7603 - val_loss: 0.0125 - val_accuracy: 0.7755\n",
      "Epoch 161/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7768 - val_loss: 0.0119 - val_accuracy: 0.8025\n",
      "Epoch 162/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0122 - accuracy: 0.7797 - val_loss: 0.0120 - val_accuracy: 0.7955\n",
      "Epoch 163/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7818 - val_loss: 0.0119 - val_accuracy: 0.7940\n",
      "Epoch 164/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7802 - val_loss: 0.0118 - val_accuracy: 0.8030\n",
      "Epoch 165/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7792 - val_loss: 0.0120 - val_accuracy: 0.7790\n",
      "Epoch 166/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7782 - val_loss: 0.0119 - val_accuracy: 0.7975\n",
      "Epoch 167/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0123 - accuracy: 0.7785 - val_loss: 0.0119 - val_accuracy: 0.7910\n",
      "Epoch 168/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0124 - accuracy: 0.7723 - val_loss: 0.0120 - val_accuracy: 0.7970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/500\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0123 - accuracy: 0.7790 - val_loss: 0.0119 - val_accuracy: 0.7945\n",
      "Epoch 170/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0122 - accuracy: 0.7835 - val_loss: 0.0118 - val_accuracy: 0.8050\n",
      "Epoch 171/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7778 - val_loss: 0.0119 - val_accuracy: 0.7920\n",
      "Epoch 172/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7855 - val_loss: 0.0120 - val_accuracy: 0.8035\n",
      "Epoch 173/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0122 - accuracy: 0.7817 - val_loss: 0.0119 - val_accuracy: 0.7880\n",
      "Epoch 174/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0125 - accuracy: 0.7728 - val_loss: 0.0118 - val_accuracy: 0.8060\n",
      "Epoch 175/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7847 - val_loss: 0.0122 - val_accuracy: 0.7725\n",
      "Epoch 176/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7810 - val_loss: 0.0119 - val_accuracy: 0.8020\n",
      "Epoch 177/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7838 - val_loss: 0.0119 - val_accuracy: 0.7950\n",
      "Epoch 178/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7807 - val_loss: 0.0119 - val_accuracy: 0.8085\n",
      "Epoch 179/500\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0122 - accuracy: 0.7802 - val_loss: 0.0121 - val_accuracy: 0.7790\n",
      "Epoch 180/500\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0122 - accuracy: 0.7770 - val_loss: 0.0120 - val_accuracy: 0.7885\n",
      "Epoch 181/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7845 - val_loss: 0.0119 - val_accuracy: 0.8035\n",
      "Epoch 182/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0123 - accuracy: 0.7750 - val_loss: 0.0122 - val_accuracy: 0.7845\n",
      "Epoch 183/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7795 - val_loss: 0.0119 - val_accuracy: 0.7945\n",
      "Epoch 184/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0122 - accuracy: 0.7820 - val_loss: 0.0119 - val_accuracy: 0.7905\n",
      "Epoch 185/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0123 - accuracy: 0.7818 - val_loss: 0.0121 - val_accuracy: 0.7985\n",
      "Epoch 186/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0123 - accuracy: 0.7815 - val_loss: 0.0118 - val_accuracy: 0.8040\n",
      "Epoch 187/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7803 - val_loss: 0.0142 - val_accuracy: 0.7385\n",
      "Epoch 188/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0123 - accuracy: 0.7750 - val_loss: 0.0119 - val_accuracy: 0.8060\n",
      "Epoch 189/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0122 - accuracy: 0.7795 - val_loss: 0.0118 - val_accuracy: 0.7995\n",
      "Epoch 190/500\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0121 - accuracy: 0.7860 - val_loss: 0.0118 - val_accuracy: 0.7925\n",
      "Epoch 191/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7810 - val_loss: 0.0120 - val_accuracy: 0.7910\n",
      "Epoch 192/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0123 - accuracy: 0.7755 - val_loss: 0.0120 - val_accuracy: 0.7850\n",
      "Epoch 193/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7795 - val_loss: 0.0119 - val_accuracy: 0.7910\n",
      "Epoch 194/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7798 - val_loss: 0.0120 - val_accuracy: 0.7930\n",
      "Epoch 195/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7807 - val_loss: 0.0119 - val_accuracy: 0.7985\n",
      "Epoch 196/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0125 - accuracy: 0.7697 - val_loss: 0.0125 - val_accuracy: 0.7705\n",
      "Epoch 197/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7830 - val_loss: 0.0119 - val_accuracy: 0.7940\n",
      "Epoch 198/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7840 - val_loss: 0.0118 - val_accuracy: 0.7920\n",
      "Epoch 199/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0122 - accuracy: 0.7823 - val_loss: 0.0119 - val_accuracy: 0.8070\n",
      "Epoch 200/500\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0123 - accuracy: 0.7777 - val_loss: 0.0122 - val_accuracy: 0.7805\n",
      "Epoch 201/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7785 - val_loss: 0.0119 - val_accuracy: 0.7950\n",
      "Epoch 202/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7810 - val_loss: 0.0118 - val_accuracy: 0.8030\n",
      "Epoch 203/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7795 - val_loss: 0.0118 - val_accuracy: 0.8085\n",
      "Epoch 204/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0122 - accuracy: 0.7833 - val_loss: 0.0118 - val_accuracy: 0.8015\n",
      "Epoch 205/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0123 - accuracy: 0.7775 - val_loss: 0.0119 - val_accuracy: 0.7875\n",
      "Epoch 206/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7818 - val_loss: 0.0118 - val_accuracy: 0.8085\n",
      "Epoch 207/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0123 - accuracy: 0.7762 - val_loss: 0.0119 - val_accuracy: 0.7985\n",
      "Epoch 208/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7827 - val_loss: 0.0119 - val_accuracy: 0.7895\n",
      "Epoch 209/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0123 - accuracy: 0.7832 - val_loss: 0.0120 - val_accuracy: 0.8030\n",
      "Epoch 210/500\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0122 - accuracy: 0.7812 - val_loss: 0.0119 - val_accuracy: 0.7940\n",
      "Epoch 211/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0122 - accuracy: 0.7755 - val_loss: 0.0119 - val_accuracy: 0.7905\n",
      "Epoch 212/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7787 - val_loss: 0.0120 - val_accuracy: 0.7855\n",
      "Epoch 213/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7790 - val_loss: 0.0118 - val_accuracy: 0.7970\n",
      "Epoch 214/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0122 - accuracy: 0.7808 - val_loss: 0.0119 - val_accuracy: 0.7945\n",
      "Epoch 215/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7773 - val_loss: 0.0119 - val_accuracy: 0.8005\n",
      "Epoch 216/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7793 - val_loss: 0.0120 - val_accuracy: 0.7955\n",
      "Epoch 217/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0125 - accuracy: 0.7697 - val_loss: 0.0119 - val_accuracy: 0.7900\n",
      "Epoch 218/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7813 - val_loss: 0.0118 - val_accuracy: 0.8045\n",
      "Epoch 219/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7818 - val_loss: 0.0118 - val_accuracy: 0.8040\n",
      "Epoch 220/500\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0122 - accuracy: 0.7818 - val_loss: 0.0119 - val_accuracy: 0.7885\n",
      "Epoch 221/500\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0122 - accuracy: 0.7872 - val_loss: 0.0119 - val_accuracy: 0.7975\n",
      "Epoch 222/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7793 - val_loss: 0.0121 - val_accuracy: 0.7915\n",
      "Epoch 223/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7790 - val_loss: 0.0118 - val_accuracy: 0.8045\n",
      "Epoch 224/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7782 - val_loss: 0.0119 - val_accuracy: 0.7950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7832 - val_loss: 0.0119 - val_accuracy: 0.8005\n",
      "Epoch 226/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7872 - val_loss: 0.0118 - val_accuracy: 0.7950\n",
      "Epoch 227/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7795 - val_loss: 0.0119 - val_accuracy: 0.7965\n",
      "Epoch 228/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7843 - val_loss: 0.0128 - val_accuracy: 0.7770\n",
      "Epoch 229/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7843 - val_loss: 0.0118 - val_accuracy: 0.7890\n",
      "Epoch 230/500\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0122 - accuracy: 0.7815 - val_loss: 0.0119 - val_accuracy: 0.7955\n",
      "Epoch 231/500\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0122 - accuracy: 0.7778 - val_loss: 0.0119 - val_accuracy: 0.7915\n",
      "Epoch 232/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0123 - accuracy: 0.7752 - val_loss: 0.0119 - val_accuracy: 0.7925\n",
      "Epoch 233/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0123 - accuracy: 0.7797 - val_loss: 0.0120 - val_accuracy: 0.7920\n",
      "Epoch 234/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7818 - val_loss: 0.0118 - val_accuracy: 0.8045\n",
      "Epoch 235/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7822 - val_loss: 0.0119 - val_accuracy: 0.7885\n",
      "Epoch 236/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0121 - accuracy: 0.7888 - val_loss: 0.0119 - val_accuracy: 0.7870\n",
      "Epoch 237/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7755 - val_loss: 0.0118 - val_accuracy: 0.8100\n",
      "Epoch 238/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0123 - accuracy: 0.7775 - val_loss: 0.0126 - val_accuracy: 0.7790\n",
      "Epoch 239/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7837 - val_loss: 0.0118 - val_accuracy: 0.7985\n",
      "Epoch 240/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0122 - accuracy: 0.7790 - val_loss: 0.0119 - val_accuracy: 0.8030\n",
      "Epoch 241/500\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0122 - accuracy: 0.7810 - val_loss: 0.0120 - val_accuracy: 0.7790\n",
      "Epoch 242/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7785 - val_loss: 0.0119 - val_accuracy: 0.8085\n",
      "Epoch 243/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7813 - val_loss: 0.0121 - val_accuracy: 0.7945\n",
      "Epoch 244/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0123 - accuracy: 0.7760 - val_loss: 0.0119 - val_accuracy: 0.7955\n",
      "Epoch 245/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7833 - val_loss: 0.0118 - val_accuracy: 0.7940\n",
      "Epoch 246/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0122 - accuracy: 0.7787 - val_loss: 0.0119 - val_accuracy: 0.7900\n",
      "Epoch 247/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7813 - val_loss: 0.0118 - val_accuracy: 0.8040\n",
      "Epoch 248/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7862 - val_loss: 0.0119 - val_accuracy: 0.7850\n",
      "Epoch 249/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7813 - val_loss: 0.0118 - val_accuracy: 0.7995\n",
      "Epoch 250/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7838 - val_loss: 0.0120 - val_accuracy: 0.7940\n",
      "Epoch 251/500\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0122 - accuracy: 0.7805 - val_loss: 0.0120 - val_accuracy: 0.7870\n",
      "Epoch 252/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0122 - accuracy: 0.7777 - val_loss: 0.0120 - val_accuracy: 0.7910\n",
      "Epoch 253/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7798 - val_loss: 0.0119 - val_accuracy: 0.7910\n",
      "Epoch 254/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7807 - val_loss: 0.0119 - val_accuracy: 0.8045\n",
      "Epoch 255/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7797 - val_loss: 0.0119 - val_accuracy: 0.7950\n",
      "Epoch 256/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7853 - val_loss: 0.0118 - val_accuracy: 0.8000\n",
      "Epoch 257/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0121 - accuracy: 0.7823 - val_loss: 0.0120 - val_accuracy: 0.7895\n",
      "Epoch 258/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0122 - accuracy: 0.7835 - val_loss: 0.0118 - val_accuracy: 0.8055\n",
      "Epoch 259/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7803 - val_loss: 0.0119 - val_accuracy: 0.7985\n",
      "Epoch 260/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7822 - val_loss: 0.0125 - val_accuracy: 0.7760\n",
      "Epoch 261/500\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0124 - accuracy: 0.7757 - val_loss: 0.0119 - val_accuracy: 0.7930\n",
      "Epoch 262/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0121 - accuracy: 0.7802 - val_loss: 0.0118 - val_accuracy: 0.8025\n",
      "Epoch 263/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0121 - accuracy: 0.7863 - val_loss: 0.0118 - val_accuracy: 0.8025\n",
      "Epoch 264/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7845 - val_loss: 0.0119 - val_accuracy: 0.7995\n",
      "Epoch 265/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7803 - val_loss: 0.0120 - val_accuracy: 0.7935\n",
      "Epoch 266/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7823 - val_loss: 0.0119 - val_accuracy: 0.7955\n",
      "Epoch 267/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0122 - accuracy: 0.7808 - val_loss: 0.0119 - val_accuracy: 0.7940\n",
      "Epoch 268/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7808 - val_loss: 0.0119 - val_accuracy: 0.7940\n",
      "Epoch 269/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7818 - val_loss: 0.0119 - val_accuracy: 0.8055\n",
      "Epoch 270/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0122 - accuracy: 0.7822 - val_loss: 0.0118 - val_accuracy: 0.8005\n",
      "Epoch 271/500\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0121 - accuracy: 0.7832 - val_loss: 0.0119 - val_accuracy: 0.7865\n",
      "Epoch 272/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0122 - accuracy: 0.7780 - val_loss: 0.0118 - val_accuracy: 0.8075\n",
      "Epoch 273/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0121 - accuracy: 0.7832 - val_loss: 0.0119 - val_accuracy: 0.8045\n",
      "Epoch 274/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7820 - val_loss: 0.0119 - val_accuracy: 0.7930\n",
      "Epoch 275/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7802 - val_loss: 0.0119 - val_accuracy: 0.8000\n",
      "Epoch 276/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7835 - val_loss: 0.0119 - val_accuracy: 0.8040\n",
      "Epoch 277/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7765 - val_loss: 0.0119 - val_accuracy: 0.7930\n",
      "Epoch 278/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7813 - val_loss: 0.0118 - val_accuracy: 0.8020\n",
      "Epoch 279/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7853 - val_loss: 0.0118 - val_accuracy: 0.8090\n",
      "Epoch 280/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7830 - val_loss: 0.0120 - val_accuracy: 0.7805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0122 - accuracy: 0.7795 - val_loss: 0.0122 - val_accuracy: 0.7785\n",
      "Epoch 282/500\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0121 - accuracy: 0.7850 - val_loss: 0.0119 - val_accuracy: 0.7925\n",
      "Epoch 283/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7835 - val_loss: 0.0120 - val_accuracy: 0.7835\n",
      "Epoch 284/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7825 - val_loss: 0.0118 - val_accuracy: 0.7970\n",
      "Epoch 285/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7840 - val_loss: 0.0120 - val_accuracy: 0.7865\n",
      "Epoch 286/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0122 - accuracy: 0.7847 - val_loss: 0.0121 - val_accuracy: 0.7850\n",
      "Epoch 287/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7793 - val_loss: 0.0119 - val_accuracy: 0.7905\n",
      "Epoch 288/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7792 - val_loss: 0.0120 - val_accuracy: 0.7915\n",
      "Epoch 289/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0123 - accuracy: 0.7757 - val_loss: 0.0123 - val_accuracy: 0.7805\n",
      "Epoch 290/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7848 - val_loss: 0.0118 - val_accuracy: 0.7920\n",
      "Epoch 291/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7837 - val_loss: 0.0118 - val_accuracy: 0.8085\n",
      "Epoch 292/500\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0121 - accuracy: 0.7830 - val_loss: 0.0118 - val_accuracy: 0.8015\n",
      "Epoch 293/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0122 - accuracy: 0.7813 - val_loss: 0.0119 - val_accuracy: 0.7975\n",
      "Epoch 294/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0122 - accuracy: 0.7795 - val_loss: 0.0118 - val_accuracy: 0.8085\n",
      "Epoch 295/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7843 - val_loss: 0.0118 - val_accuracy: 0.8075\n",
      "Epoch 296/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7772 - val_loss: 0.0119 - val_accuracy: 0.7865\n",
      "Epoch 297/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7843 - val_loss: 0.0118 - val_accuracy: 0.8080\n",
      "Epoch 298/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0122 - accuracy: 0.7802 - val_loss: 0.0118 - val_accuracy: 0.8010\n",
      "Epoch 299/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0122 - accuracy: 0.7855 - val_loss: 0.0121 - val_accuracy: 0.7805\n",
      "Epoch 300/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0122 - accuracy: 0.7840 - val_loss: 0.0118 - val_accuracy: 0.8110\n",
      "Epoch 301/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0123 - accuracy: 0.7785 - val_loss: 0.0121 - val_accuracy: 0.7830\n",
      "Epoch 302/500\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0121 - accuracy: 0.7863 - val_loss: 0.0118 - val_accuracy: 0.8030\n",
      "Epoch 303/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0122 - accuracy: 0.7820 - val_loss: 0.0119 - val_accuracy: 0.7955\n",
      "Epoch 304/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7852 - val_loss: 0.0120 - val_accuracy: 0.7830\n",
      "Epoch 305/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7815 - val_loss: 0.0118 - val_accuracy: 0.8005\n",
      "Epoch 306/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7893 - val_loss: 0.0118 - val_accuracy: 0.7955\n",
      "Epoch 307/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0121 - accuracy: 0.7860 - val_loss: 0.0121 - val_accuracy: 0.7900\n",
      "Epoch 308/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0123 - accuracy: 0.7765 - val_loss: 0.0123 - val_accuracy: 0.7820\n",
      "Epoch 309/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7825 - val_loss: 0.0119 - val_accuracy: 0.7970\n",
      "Epoch 310/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7843 - val_loss: 0.0119 - val_accuracy: 0.8005\n",
      "Epoch 311/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0121 - accuracy: 0.7862 - val_loss: 0.0118 - val_accuracy: 0.8085\n",
      "Epoch 312/500\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0121 - accuracy: 0.7863 - val_loss: 0.0120 - val_accuracy: 0.7940\n",
      "Epoch 313/500\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0121 - accuracy: 0.7818 - val_loss: 0.0118 - val_accuracy: 0.7950\n",
      "Epoch 314/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7775 - val_loss: 0.0119 - val_accuracy: 0.7865\n",
      "Epoch 315/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7840 - val_loss: 0.0118 - val_accuracy: 0.7980\n",
      "Epoch 316/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7790 - val_loss: 0.0118 - val_accuracy: 0.8055\n",
      "Epoch 317/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7852 - val_loss: 0.0118 - val_accuracy: 0.7965\n",
      "Epoch 318/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0125 - accuracy: 0.7710 - val_loss: 0.0118 - val_accuracy: 0.7965\n",
      "Epoch 319/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0121 - accuracy: 0.7850 - val_loss: 0.0118 - val_accuracy: 0.8070\n",
      "Epoch 320/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7857 - val_loss: 0.0118 - val_accuracy: 0.7990\n",
      "Epoch 321/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7818 - val_loss: 0.0119 - val_accuracy: 0.8005\n",
      "Epoch 322/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0122 - accuracy: 0.7830 - val_loss: 0.0119 - val_accuracy: 0.8025\n",
      "Epoch 323/500\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0121 - accuracy: 0.7857 - val_loss: 0.0118 - val_accuracy: 0.7995\n",
      "Epoch 324/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7805 - val_loss: 0.0118 - val_accuracy: 0.8025\n",
      "Epoch 325/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7798 - val_loss: 0.0120 - val_accuracy: 0.7905\n",
      "Epoch 326/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7823 - val_loss: 0.0120 - val_accuracy: 0.7925\n",
      "Epoch 327/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0123 - accuracy: 0.7780 - val_loss: 0.0118 - val_accuracy: 0.8065\n",
      "Epoch 328/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7823 - val_loss: 0.0119 - val_accuracy: 0.7870\n",
      "Epoch 329/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0121 - accuracy: 0.7798 - val_loss: 0.0118 - val_accuracy: 0.8025\n",
      "Epoch 330/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0122 - accuracy: 0.7842 - val_loss: 0.0118 - val_accuracy: 0.7985\n",
      "Epoch 331/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0122 - accuracy: 0.7835 - val_loss: 0.0120 - val_accuracy: 0.7895\n",
      "Epoch 332/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7823 - val_loss: 0.0118 - val_accuracy: 0.7940\n",
      "Epoch 333/500\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0122 - accuracy: 0.7840 - val_loss: 0.0120 - val_accuracy: 0.7835\n",
      "Epoch 334/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7812 - val_loss: 0.0119 - val_accuracy: 0.7980\n",
      "Epoch 335/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7797 - val_loss: 0.0119 - val_accuracy: 0.7990\n",
      "Epoch 336/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7858 - val_loss: 0.0119 - val_accuracy: 0.7875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7802 - val_loss: 0.0119 - val_accuracy: 0.8085\n",
      "Epoch 338/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7775 - val_loss: 0.0118 - val_accuracy: 0.7920\n",
      "Epoch 339/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7822 - val_loss: 0.0119 - val_accuracy: 0.7895\n",
      "Epoch 340/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7835 - val_loss: 0.0120 - val_accuracy: 0.7920\n",
      "Epoch 341/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0121 - accuracy: 0.7870 - val_loss: 0.0119 - val_accuracy: 0.7995\n",
      "Epoch 342/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7773 - val_loss: 0.0120 - val_accuracy: 0.7965\n",
      "Epoch 343/500\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0122 - accuracy: 0.7840 - val_loss: 0.0120 - val_accuracy: 0.7925\n",
      "Epoch 344/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0122 - accuracy: 0.7832 - val_loss: 0.0119 - val_accuracy: 0.7925\n",
      "Epoch 345/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7858 - val_loss: 0.0118 - val_accuracy: 0.7985\n",
      "Epoch 346/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7898 - val_loss: 0.0118 - val_accuracy: 0.7985\n",
      "Epoch 347/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0122 - accuracy: 0.7838 - val_loss: 0.0119 - val_accuracy: 0.7965\n",
      "Epoch 348/500\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0123 - accuracy: 0.7755 - val_loss: 0.0118 - val_accuracy: 0.8060\n",
      "Epoch 349/500\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0121 - accuracy: 0.7833 - val_loss: 0.0120 - val_accuracy: 0.7735\n",
      "Epoch 350/500\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0121 - accuracy: 0.7828 - val_loss: 0.0118 - val_accuracy: 0.8025\n",
      "Epoch 351/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0122 - accuracy: 0.7853 - val_loss: 0.0119 - val_accuracy: 0.8040\n",
      "Epoch 352/500\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0121 - accuracy: 0.7868 - val_loss: 0.0118 - val_accuracy: 0.7990\n",
      "Epoch 353/500\n",
      "188/188 [==============================] - 0s 575us/step - loss: 0.0122 - accuracy: 0.7763 - val_loss: 0.0118 - val_accuracy: 0.8010\n",
      "Epoch 354/500\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0121 - accuracy: 0.7857 - val_loss: 0.0118 - val_accuracy: 0.7900\n",
      "Epoch 355/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0122 - accuracy: 0.7815 - val_loss: 0.0118 - val_accuracy: 0.7965\n",
      "Epoch 356/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7817 - val_loss: 0.0120 - val_accuracy: 0.7955\n",
      "Epoch 357/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0123 - accuracy: 0.7803 - val_loss: 0.0126 - val_accuracy: 0.7750\n",
      "Epoch 358/500\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0122 - accuracy: 0.7810 - val_loss: 0.0119 - val_accuracy: 0.7900\n",
      "Epoch 359/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0121 - accuracy: 0.7850 - val_loss: 0.0119 - val_accuracy: 0.7880\n",
      "Epoch 360/500\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0121 - accuracy: 0.7843 - val_loss: 0.0118 - val_accuracy: 0.7940\n",
      "Epoch 361/500\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0121 - accuracy: 0.7837 - val_loss: 0.0121 - val_accuracy: 0.7890\n",
      "Epoch 362/500\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0121 - accuracy: 0.7825 - val_loss: 0.0118 - val_accuracy: 0.7935\n",
      "Epoch 363/500\n",
      "188/188 [==============================] - 0s 564us/step - loss: 0.0122 - accuracy: 0.7795 - val_loss: 0.0118 - val_accuracy: 0.7960\n",
      "Epoch 364/500\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0121 - accuracy: 0.7855 - val_loss: 0.0118 - val_accuracy: 0.8020\n",
      "Epoch 365/500\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0122 - accuracy: 0.7820 - val_loss: 0.0119 - val_accuracy: 0.7905\n",
      "Epoch 366/500\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0121 - accuracy: 0.7868 - val_loss: 0.0118 - val_accuracy: 0.8030\n",
      "Epoch 367/500\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0122 - accuracy: 0.7835 - val_loss: 0.0118 - val_accuracy: 0.8025\n",
      "Epoch 368/500\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0121 - accuracy: 0.7843 - val_loss: 0.0119 - val_accuracy: 0.7955\n",
      "Epoch 369/500\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0121 - accuracy: 0.7845 - val_loss: 0.0118 - val_accuracy: 0.7870\n",
      "Epoch 370/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7825 - val_loss: 0.0118 - val_accuracy: 0.7965\n",
      "Epoch 371/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0121 - accuracy: 0.7828 - val_loss: 0.0118 - val_accuracy: 0.8020\n",
      "Epoch 372/500\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0121 - accuracy: 0.7832 - val_loss: 0.0119 - val_accuracy: 0.7905\n",
      "Epoch 373/500\n",
      "188/188 [==============================] - 0s 569us/step - loss: 0.0122 - accuracy: 0.7767 - val_loss: 0.0119 - val_accuracy: 0.8035\n",
      "Epoch 374/500\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0121 - accuracy: 0.7822 - val_loss: 0.0119 - val_accuracy: 0.7925\n",
      "Epoch 375/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0122 - accuracy: 0.7855 - val_loss: 0.0118 - val_accuracy: 0.8035\n",
      "Epoch 376/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0122 - accuracy: 0.7808 - val_loss: 0.0119 - val_accuracy: 0.8020\n",
      "Epoch 377/500\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0121 - accuracy: 0.7837 - val_loss: 0.0118 - val_accuracy: 0.8105\n",
      "Epoch 378/500\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0121 - accuracy: 0.7828 - val_loss: 0.0118 - val_accuracy: 0.7925\n",
      "Epoch 379/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0122 - accuracy: 0.7827 - val_loss: 0.0119 - val_accuracy: 0.7940\n",
      "Epoch 380/500\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0122 - accuracy: 0.7807 - val_loss: 0.0119 - val_accuracy: 0.8010\n",
      "Epoch 381/500\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0121 - accuracy: 0.7863 - val_loss: 0.0118 - val_accuracy: 0.7970\n",
      "Epoch 382/500\n",
      "188/188 [==============================] - 0s 564us/step - loss: 0.0121 - accuracy: 0.7830 - val_loss: 0.0118 - val_accuracy: 0.8075\n",
      "Epoch 383/500\n",
      "188/188 [==============================] - 0s 564us/step - loss: 0.0122 - accuracy: 0.7843 - val_loss: 0.0118 - val_accuracy: 0.8045\n",
      "Epoch 384/500\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0121 - accuracy: 0.7855 - val_loss: 0.0118 - val_accuracy: 0.8060\n",
      "Epoch 385/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7850 - val_loss: 0.0118 - val_accuracy: 0.8035\n",
      "Epoch 386/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0121 - accuracy: 0.7813 - val_loss: 0.0118 - val_accuracy: 0.8040\n",
      "Epoch 387/500\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0121 - accuracy: 0.7820 - val_loss: 0.0118 - val_accuracy: 0.7975\n",
      "Epoch 388/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0122 - accuracy: 0.7808 - val_loss: 0.0124 - val_accuracy: 0.7835\n",
      "Epoch 389/500\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0122 - accuracy: 0.7813 - val_loss: 0.0118 - val_accuracy: 0.8030\n",
      "Epoch 390/500\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0121 - accuracy: 0.7783 - val_loss: 0.0120 - val_accuracy: 0.7995\n",
      "Epoch 391/500\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0121 - accuracy: 0.7840 - val_loss: 0.0118 - val_accuracy: 0.8030\n",
      "Epoch 392/500\n",
      "188/188 [==============================] - 0s 564us/step - loss: 0.0121 - accuracy: 0.7857 - val_loss: 0.0119 - val_accuracy: 0.7985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/500\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0121 - accuracy: 0.7828 - val_loss: 0.0119 - val_accuracy: 0.7985\n",
      "Epoch 394/500\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0122 - accuracy: 0.7837 - val_loss: 0.0118 - val_accuracy: 0.8040\n",
      "Epoch 395/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0123 - accuracy: 0.7810 - val_loss: 0.0120 - val_accuracy: 0.7875\n",
      "Epoch 396/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0121 - accuracy: 0.7812 - val_loss: 0.0118 - val_accuracy: 0.7995\n",
      "Epoch 397/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7783 - val_loss: 0.0118 - val_accuracy: 0.8010\n",
      "Epoch 398/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7823 - val_loss: 0.0123 - val_accuracy: 0.7910\n",
      "Epoch 399/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7835 - val_loss: 0.0118 - val_accuracy: 0.7885\n",
      "Epoch 400/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0121 - accuracy: 0.7855 - val_loss: 0.0118 - val_accuracy: 0.8040\n",
      "Epoch 401/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7847 - val_loss: 0.0118 - val_accuracy: 0.8015\n",
      "Epoch 402/500\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0121 - accuracy: 0.7805 - val_loss: 0.0119 - val_accuracy: 0.7895\n",
      "Epoch 403/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0123 - accuracy: 0.7802 - val_loss: 0.0120 - val_accuracy: 0.7985\n",
      "Epoch 404/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7872 - val_loss: 0.0119 - val_accuracy: 0.7955\n",
      "Epoch 405/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0121 - accuracy: 0.7845 - val_loss: 0.0119 - val_accuracy: 0.8000\n",
      "Epoch 406/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0121 - accuracy: 0.7867 - val_loss: 0.0118 - val_accuracy: 0.7975\n",
      "Epoch 407/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0121 - accuracy: 0.7858 - val_loss: 0.0118 - val_accuracy: 0.7960\n",
      "Epoch 408/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7828 - val_loss: 0.0118 - val_accuracy: 0.8030\n",
      "Epoch 409/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7822 - val_loss: 0.0120 - val_accuracy: 0.7980\n",
      "Epoch 410/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0123 - accuracy: 0.7815 - val_loss: 0.0118 - val_accuracy: 0.7985\n",
      "Epoch 411/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7807 - val_loss: 0.0118 - val_accuracy: 0.8010\n",
      "Epoch 412/500\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0122 - accuracy: 0.7842 - val_loss: 0.0118 - val_accuracy: 0.7985\n",
      "Epoch 413/500\n",
      "188/188 [==============================] - 0s 564us/step - loss: 0.0121 - accuracy: 0.7848 - val_loss: 0.0119 - val_accuracy: 0.7885\n",
      "Epoch 414/500\n",
      "188/188 [==============================] - 0s 500us/step - loss: 0.0121 - accuracy: 0.7853 - val_loss: 0.0119 - val_accuracy: 0.8080\n",
      "Epoch 415/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7795 - val_loss: 0.0118 - val_accuracy: 0.7995\n",
      "Epoch 416/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7822 - val_loss: 0.0119 - val_accuracy: 0.7840\n",
      "Epoch 417/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7810 - val_loss: 0.0118 - val_accuracy: 0.8020\n",
      "Epoch 418/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7832 - val_loss: 0.0119 - val_accuracy: 0.7935\n",
      "Epoch 419/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7828 - val_loss: 0.0119 - val_accuracy: 0.7940\n",
      "Epoch 420/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7872 - val_loss: 0.0119 - val_accuracy: 0.7970\n",
      "Epoch 421/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0121 - accuracy: 0.7858 - val_loss: 0.0118 - val_accuracy: 0.8095\n",
      "Epoch 422/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0121 - accuracy: 0.7857 - val_loss: 0.0118 - val_accuracy: 0.7965\n",
      "Epoch 423/500\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0121 - accuracy: 0.7847 - val_loss: 0.0120 - val_accuracy: 0.7885\n",
      "Epoch 424/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7808 - val_loss: 0.0118 - val_accuracy: 0.8050\n",
      "Epoch 425/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0122 - accuracy: 0.7800 - val_loss: 0.0119 - val_accuracy: 0.7930\n",
      "Epoch 426/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7835 - val_loss: 0.0118 - val_accuracy: 0.7965\n",
      "Epoch 427/500\n",
      "188/188 [==============================] - 0s 505us/step - loss: 0.0121 - accuracy: 0.7838 - val_loss: 0.0118 - val_accuracy: 0.8040\n",
      "Epoch 428/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7810 - val_loss: 0.0118 - val_accuracy: 0.8025\n",
      "Epoch 429/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7822 - val_loss: 0.0118 - val_accuracy: 0.8035\n",
      "Epoch 430/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0121 - accuracy: 0.7840 - val_loss: 0.0118 - val_accuracy: 0.7940\n",
      "Epoch 431/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0122 - accuracy: 0.7808 - val_loss: 0.0118 - val_accuracy: 0.8020\n",
      "Epoch 432/500\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0121 - accuracy: 0.7850 - val_loss: 0.0120 - val_accuracy: 0.7790\n",
      "Epoch 433/500\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0122 - accuracy: 0.7867 - val_loss: 0.0119 - val_accuracy: 0.7925\n",
      "Epoch 434/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0121 - accuracy: 0.7853 - val_loss: 0.0120 - val_accuracy: 0.7875\n",
      "Epoch 435/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0122 - accuracy: 0.7780 - val_loss: 0.0118 - val_accuracy: 0.7925\n",
      "Epoch 436/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0121 - accuracy: 0.7845 - val_loss: 0.0119 - val_accuracy: 0.7905\n",
      "Epoch 437/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7875 - val_loss: 0.0118 - val_accuracy: 0.7980\n",
      "Epoch 438/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0121 - accuracy: 0.7853 - val_loss: 0.0118 - val_accuracy: 0.7975\n",
      "Epoch 439/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0122 - accuracy: 0.7803 - val_loss: 0.0119 - val_accuracy: 0.8055\n",
      "Epoch 440/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7847 - val_loss: 0.0119 - val_accuracy: 0.7920\n",
      "Epoch 441/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0121 - accuracy: 0.7833 - val_loss: 0.0118 - val_accuracy: 0.8075\n",
      "Epoch 442/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0121 - accuracy: 0.7803 - val_loss: 0.0119 - val_accuracy: 0.7885\n",
      "Epoch 443/500\n",
      "188/188 [==============================] - 0s 564us/step - loss: 0.0121 - accuracy: 0.7843 - val_loss: 0.0119 - val_accuracy: 0.7885\n",
      "Epoch 444/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7848 - val_loss: 0.0118 - val_accuracy: 0.7985\n",
      "Epoch 445/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7807 - val_loss: 0.0118 - val_accuracy: 0.7960\n",
      "Epoch 446/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7858 - val_loss: 0.0118 - val_accuracy: 0.7930\n",
      "Epoch 447/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7838 - val_loss: 0.0119 - val_accuracy: 0.8035\n",
      "Epoch 448/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0122 - accuracy: 0.7810 - val_loss: 0.0118 - val_accuracy: 0.7970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 449/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7850 - val_loss: 0.0119 - val_accuracy: 0.7900\n",
      "Epoch 450/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7817 - val_loss: 0.0119 - val_accuracy: 0.7995\n",
      "Epoch 451/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0121 - accuracy: 0.7818 - val_loss: 0.0118 - val_accuracy: 0.7965\n",
      "Epoch 452/500\n",
      "188/188 [==============================] - 0s 569us/step - loss: 0.0121 - accuracy: 0.7822 - val_loss: 0.0118 - val_accuracy: 0.8065\n",
      "Epoch 453/500\n",
      "188/188 [==============================] - 0s 585us/step - loss: 0.0121 - accuracy: 0.7890 - val_loss: 0.0118 - val_accuracy: 0.8035\n",
      "Epoch 454/500\n",
      "188/188 [==============================] - 0s 548us/step - loss: 0.0122 - accuracy: 0.7797 - val_loss: 0.0119 - val_accuracy: 0.7980\n",
      "Epoch 455/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7813 - val_loss: 0.0118 - val_accuracy: 0.8000\n",
      "Epoch 456/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7848 - val_loss: 0.0118 - val_accuracy: 0.7915\n",
      "Epoch 457/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7827 - val_loss: 0.0120 - val_accuracy: 0.7945\n",
      "Epoch 458/500\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0121 - accuracy: 0.7805 - val_loss: 0.0120 - val_accuracy: 0.7980\n",
      "Epoch 459/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0121 - accuracy: 0.7837 - val_loss: 0.0120 - val_accuracy: 0.7815\n",
      "Epoch 460/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0121 - accuracy: 0.7838 - val_loss: 0.0119 - val_accuracy: 0.8005\n",
      "Epoch 461/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0121 - accuracy: 0.7863 - val_loss: 0.0118 - val_accuracy: 0.8080\n",
      "Epoch 462/500\n",
      "188/188 [==============================] - 0s 532us/step - loss: 0.0121 - accuracy: 0.7860 - val_loss: 0.0118 - val_accuracy: 0.8055\n",
      "Epoch 463/500\n",
      "188/188 [==============================] - 0s 553us/step - loss: 0.0122 - accuracy: 0.7833 - val_loss: 0.0119 - val_accuracy: 0.7810\n",
      "Epoch 464/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7828 - val_loss: 0.0119 - val_accuracy: 0.7900\n",
      "Epoch 465/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0122 - accuracy: 0.7785 - val_loss: 0.0122 - val_accuracy: 0.7720\n",
      "Epoch 466/500\n",
      "188/188 [==============================] - 0s 527us/step - loss: 0.0121 - accuracy: 0.7833 - val_loss: 0.0119 - val_accuracy: 0.8010\n",
      "Epoch 467/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0121 - accuracy: 0.7827 - val_loss: 0.0118 - val_accuracy: 0.8030\n",
      "Epoch 468/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0122 - accuracy: 0.7822 - val_loss: 0.0119 - val_accuracy: 0.8015\n",
      "Epoch 469/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7853 - val_loss: 0.0118 - val_accuracy: 0.8065\n",
      "Epoch 470/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0121 - accuracy: 0.7855 - val_loss: 0.0119 - val_accuracy: 0.7930\n",
      "Epoch 471/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0122 - accuracy: 0.7828 - val_loss: 0.0118 - val_accuracy: 0.8055\n",
      "Epoch 472/500\n",
      "188/188 [==============================] - 0s 537us/step - loss: 0.0121 - accuracy: 0.7877 - val_loss: 0.0118 - val_accuracy: 0.7915\n",
      "Epoch 473/500\n",
      "188/188 [==============================] - 0s 569us/step - loss: 0.0122 - accuracy: 0.7808 - val_loss: 0.0118 - val_accuracy: 0.7915\n",
      "Epoch 474/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7818 - val_loss: 0.0118 - val_accuracy: 0.8080\n",
      "Epoch 475/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7830 - val_loss: 0.0118 - val_accuracy: 0.7990\n",
      "Epoch 476/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7887 - val_loss: 0.0118 - val_accuracy: 0.8085\n",
      "Epoch 477/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0121 - accuracy: 0.7807 - val_loss: 0.0120 - val_accuracy: 0.7865\n",
      "Epoch 478/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7843 - val_loss: 0.0118 - val_accuracy: 0.8030\n",
      "Epoch 479/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7848 - val_loss: 0.0119 - val_accuracy: 0.8040\n",
      "Epoch 480/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0121 - accuracy: 0.7870 - val_loss: 0.0118 - val_accuracy: 0.8055\n",
      "Epoch 481/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0122 - accuracy: 0.7787 - val_loss: 0.0118 - val_accuracy: 0.7985\n",
      "Epoch 482/500\n",
      "188/188 [==============================] - 0s 543us/step - loss: 0.0122 - accuracy: 0.7818 - val_loss: 0.0120 - val_accuracy: 0.7975\n",
      "Epoch 483/500\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0121 - accuracy: 0.7822 - val_loss: 0.0119 - val_accuracy: 0.8015\n",
      "Epoch 484/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0121 - accuracy: 0.7873 - val_loss: 0.0118 - val_accuracy: 0.7985\n",
      "Epoch 485/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7867 - val_loss: 0.0118 - val_accuracy: 0.8010\n",
      "Epoch 486/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7818 - val_loss: 0.0118 - val_accuracy: 0.7995\n",
      "Epoch 487/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7835 - val_loss: 0.0118 - val_accuracy: 0.8010\n",
      "Epoch 488/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7847 - val_loss: 0.0119 - val_accuracy: 0.8010\n",
      "Epoch 489/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0121 - accuracy: 0.7820 - val_loss: 0.0118 - val_accuracy: 0.7980\n",
      "Epoch 490/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0122 - accuracy: 0.7782 - val_loss: 0.0120 - val_accuracy: 0.7860\n",
      "Epoch 491/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7843 - val_loss: 0.0120 - val_accuracy: 0.7845\n",
      "Epoch 492/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0122 - accuracy: 0.7823 - val_loss: 0.0118 - val_accuracy: 0.7940\n",
      "Epoch 493/500\n",
      "188/188 [==============================] - 0s 559us/step - loss: 0.0121 - accuracy: 0.7882 - val_loss: 0.0118 - val_accuracy: 0.7990\n",
      "Epoch 494/500\n",
      "188/188 [==============================] - 0s 521us/step - loss: 0.0121 - accuracy: 0.7870 - val_loss: 0.0119 - val_accuracy: 0.7985\n",
      "Epoch 495/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7855 - val_loss: 0.0118 - val_accuracy: 0.7925\n",
      "Epoch 496/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0121 - accuracy: 0.7853 - val_loss: 0.0118 - val_accuracy: 0.7900\n",
      "Epoch 497/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7897 - val_loss: 0.0118 - val_accuracy: 0.8020\n",
      "Epoch 498/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0122 - accuracy: 0.7795 - val_loss: 0.0120 - val_accuracy: 0.7815\n",
      "Epoch 499/500\n",
      "188/188 [==============================] - 0s 516us/step - loss: 0.0121 - accuracy: 0.7833 - val_loss: 0.0119 - val_accuracy: 0.8000\n",
      "Epoch 500/500\n",
      "188/188 [==============================] - 0s 511us/step - loss: 0.0121 - accuracy: 0.7867 - val_loss: 0.0118 - val_accuracy: 0.7975\n",
      "training Runtime: 0.83 Minutes\n"
     ]
    }
   ],
   "source": [
    "start_vect=time.time()\n",
    "\n",
    "model.compile(loss = \"mse\",\n",
    "              optimizer = \"ADAM\",\n",
    "              metrics = [\"accuracy\"])\n",
    "history = model.fit(x = F_train, y = Q_train, validation_data=(F_val, Q_val),epochs = 500)\n",
    "\n",
    "\n",
    "print(\"training Runtime: %0.2f Minutes\"%((time.time() - start_vect)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_4nRWiJzYn6S"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "2021.11.19.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
