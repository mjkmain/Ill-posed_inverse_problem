{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36076719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#print(len(gpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64f67c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d5d5474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.07770158</th>\n",
       "      <th>-0.13003277</th>\n",
       "      <th>0.26838016</th>\n",
       "      <th>0.17627985</th>\n",
       "      <th>-0.04593009</th>\n",
       "      <th>0.09142768</th>\n",
       "      <th>0.10492659</th>\n",
       "      <th>0.14273107</th>\n",
       "      <th>0.09127340</th>\n",
       "      <th>0.11437427</th>\n",
       "      <th>...</th>\n",
       "      <th>0.07962369</th>\n",
       "      <th>-0.01639117</th>\n",
       "      <th>0.08893843</th>\n",
       "      <th>0.00350364</th>\n",
       "      <th>0.12996323</th>\n",
       "      <th>0.22611569</th>\n",
       "      <th>-0.12767046</th>\n",
       "      <th>0.10300189</th>\n",
       "      <th>0.17066372</th>\n",
       "      <th>0.13421567</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.011763</td>\n",
       "      <td>0.00137</td>\n",
       "      <td>-0.000427</td>\n",
       "      <td>-0.010467</td>\n",
       "      <td>0.012151</td>\n",
       "      <td>-0.01357</td>\n",
       "      <td>0.007533</td>\n",
       "      <td>-0.00315</td>\n",
       "      <td>-0.00961</td>\n",
       "      <td>-0.005346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008841</td>\n",
       "      <td>0.005438</td>\n",
       "      <td>-0.000925</td>\n",
       "      <td>0.012573</td>\n",
       "      <td>-0.003485</td>\n",
       "      <td>-0.000879</td>\n",
       "      <td>0.009161</td>\n",
       "      <td>0.010373</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>-0.009546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 100000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.07770158  -0.13003277  0.26838016  0.17627985  -0.04593009  0.09142768  \\\n",
       "0   -0.011763      0.00137   -0.000427   -0.010467     0.012151    -0.01357   \n",
       "\n",
       "   0.10492659  0.14273107  0.09127340  0.11437427  ...  0.07962369  \\\n",
       "0    0.007533    -0.00315    -0.00961   -0.005346  ...   -0.008841   \n",
       "\n",
       "   -0.01639117  0.08893843  0.00350364  0.12996323  0.22611569  -0.12767046  \\\n",
       "0     0.005438   -0.000925    0.012573   -0.003485   -0.000879     0.009161   \n",
       "\n",
       "   0.10300189  0.17066372  0.13421567  \n",
       "0    0.010373    0.001752   -0.009546  \n",
       "\n",
       "[1 rows x 100000 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data load, F.txt 파일이 있는 절대 경로를 입력하시면 됩니다.\n",
    "#data 확인을 위하여 출력해봅니다. column name에 데이터가 들어가있어서 처리해주어야 합니다.\n",
    "# N = 5\n",
    "data = pd.read_csv('C:/Users/Administrator/Documents/MATLAB/Data set/F.txt', sep = '\\t')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aaecaead",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "for i in range(len(data.iloc[0,:])):\n",
    "    arr.append(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "130e80da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "#column name에 data가 들어가있기 때문에 \"names = arr\" 로 처리해 줍니다. arr은 1 ~ len(F)의 숫자가 담겨있습니다.\n",
    "dataF = pd.read_csv('C:/Users/Administrator/Documents/MATLAB/Data set/F.txt', sep = '\\t', names = arr)\n",
    "dataQ = pd.read_csv('C:/Users/Administrator/Documents/MATLAB/Data set/Q.txt', sep = '\\t', names = arr)\n",
    "data_nF = pd.read_csv('C:/Users/Administrator/Documents/MATLAB/Data set/nF.txt', sep = '\\t', names = arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e41b12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_arr(A):\n",
    "    arA = []\n",
    "    for j in range(len(A.iloc[0, :])):\n",
    "        arA1 = []\n",
    "        for i in range(len(A.iloc[:,0])):\n",
    "            tmpA = A.iloc[:,j][i]\n",
    "            arA1.append(tmpA)\n",
    "        arA.append(arA1)\n",
    "    return arA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "06b62f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make array\n",
    "arrF = make_arr(dataF)\n",
    "dataF = np.array(arrF)\n",
    "\n",
    "arrQ = make_arr(dataQ)\n",
    "dataQ = np.array(arrQ)\n",
    "\n",
    "arr_nF = make_arr(data_nF)\n",
    "data_nF = np.array(arr_nF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bebffb63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# N = 5\n",
    "A = []\n",
    "for n in range(1,6):\n",
    "    x = np.exp(-(n**2))\n",
    "    A.append(x)\n",
    "A = np.diag(A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01383513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 2), (20000, 2), (20000, 2)\n",
      "(60000, 2), (20000, 2), (20000, 2)\n",
      "(60000, 2), (20000, 2), (20000, 2)\n"
     ]
    }
   ],
   "source": [
    "# data 분할\n",
    "\n",
    "import math\n",
    "train_size = math.floor(len(dataF)*0.6) # train : 60%\n",
    "val_size = math.floor(len(dataF)*0.2) #val : 20%\n",
    "test_size = math.floor(len(dataF)*0.2) #test : 20%\n",
    "#generate F_data, F_val, F_test\n",
    "F_data = dataF[:train_size, :]\n",
    "F_val = dataF[train_size:(val_size + train_size), :]\n",
    "F_test = dataF[(val_size + train_size):(val_size + train_size + test_size), :]\n",
    "\n",
    "#generate Q_data, Q_val, Q_test\n",
    "Q_data = dataQ[:train_size, :]\n",
    "Q_val = dataQ[train_size:(val_size + train_size), :]\n",
    "Q_test = dataQ[(val_size + train_size):(val_size + train_size + test_size), :]\n",
    "\n",
    "#generate nF_data, nF_val, nF_test\n",
    "nF_data = data_nF[:train_size, :]\n",
    "nF_val = data_nF[train_size:(val_size + train_size), :]\n",
    "nF_test = data_nF[(val_size + train_size):(val_size + train_size + test_size), :]\n",
    "\n",
    "print(f'{F_data.shape}, {F_test.shape}, {F_val.shape}')\n",
    "print(f'{Q_data.shape}, {Q_test.shape}, {Q_val.shape}')\n",
    "print(f'{nF_data.shape}, {nF_test.shape}, {nF_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4e02b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.Sequential() #Sequentioal\n",
    "\n",
    "model.add(keras.layers.Dense(input_dim = 2, units = 10, activation= \"tanh\",kernel_initializer =\"HeNormal\" )) \n",
    "model.add(keras.layers.Dense(20, activation= \"tanh\")) \n",
    "model.add(keras.layers.Dense(50, activation= \"tanh\"))  \n",
    "model.add(keras.layers.Dense(100, activation= \"tanh\")) \n",
    "model.add(keras.layers.Dense(120, activation= \"tanh\")) \n",
    "model.add(keras.layers.Dense(50, activation= \"tanh\"))\n",
    "model.add(keras.layers.Dense(2, activation= \"tanh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b02072db",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    F_train = tf.constant(F_data)\n",
    "    Q_train = tf.constant(Q_data)\n",
    "    nF_train = tf.constant(nF_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ea283d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 1s 481us/step - loss: 3.3644e-04 - accuracy: 0.9906 - val_loss: 3.3327e-04 - val_accuracy: 0.9908\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 1s 464us/step - loss: 3.1978e-04 - accuracy: 0.9913 - val_loss: 4.6369e-04 - val_accuracy: 0.9863\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 1s 467us/step - loss: 3.2122e-04 - accuracy: 0.9911 - val_loss: 2.6021e-04 - val_accuracy: 0.9924\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 1s 461us/step - loss: 3.1749e-04 - accuracy: 0.9911 - val_loss: 3.1363e-04 - val_accuracy: 0.9925\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 1s 467us/step - loss: 3.1207e-04 - accuracy: 0.9909 - val_loss: 3.1763e-04 - val_accuracy: 0.9916\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 1s 460us/step - loss: 3.0891e-04 - accuracy: 0.9910 - val_loss: 2.8009e-04 - val_accuracy: 0.9919\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 1s 460us/step - loss: 3.2063e-04 - accuracy: 0.9908 - val_loss: 2.5290e-04 - val_accuracy: 0.9922\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 1s 469us/step - loss: 3.1304e-04 - accuracy: 0.9912 - val_loss: 4.5564e-04 - val_accuracy: 0.9904\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 1s 464us/step - loss: 3.0993e-04 - accuracy: 0.9912 - val_loss: 2.8672e-04 - val_accuracy: 0.9902\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 1s 460us/step - loss: 3.1317e-04 - accuracy: 0.9908 - val_loss: 3.5282e-04 - val_accuracy: 0.9873\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 1s 485us/step - loss: 3.1073e-04 - accuracy: 0.9910 - val_loss: 3.0054e-04 - val_accuracy: 0.9917\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 1s 478us/step - loss: 3.1257e-04 - accuracy: 0.9909 - val_loss: 2.9276e-04 - val_accuracy: 0.9912\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 1s 486us/step - loss: 3.1096e-04 - accuracy: 0.9911 - val_loss: 2.8637e-04 - val_accuracy: 0.9895\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 1s 476us/step - loss: 3.0488e-04 - accuracy: 0.9912 - val_loss: 3.3196e-04 - val_accuracy: 0.9925\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 1s 477us/step - loss: 3.1298e-04 - accuracy: 0.9909 - val_loss: 2.6872e-04 - val_accuracy: 0.9919\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 1s 488us/step - loss: 3.0272e-04 - accuracy: 0.9909 - val_loss: 2.4503e-04 - val_accuracy: 0.9903\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 1s 477us/step - loss: 3.1271e-04 - accuracy: 0.9910 - val_loss: 3.3034e-04 - val_accuracy: 0.9896\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 1s 474us/step - loss: 3.0451e-04 - accuracy: 0.9909 - val_loss: 3.6691e-04 - val_accuracy: 0.9882\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 1s 477us/step - loss: 3.0598e-04 - accuracy: 0.9913 - val_loss: 3.9897e-04 - val_accuracy: 0.9853\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 1s 457us/step - loss: 3.0751e-04 - accuracy: 0.9908 - val_loss: 2.9118e-04 - val_accuracy: 0.9928\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 1s 476us/step - loss: 3.0702e-04 - accuracy: 0.9911 - val_loss: 2.5002e-04 - val_accuracy: 0.9917\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 1s 501us/step - loss: 3.0295e-04 - accuracy: 0.9910 - val_loss: 2.7770e-04 - val_accuracy: 0.9924\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 1s 465us/step - loss: 3.0548e-04 - accuracy: 0.9907 - val_loss: 2.7166e-04 - val_accuracy: 0.9919\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 1s 465us/step - loss: 3.0163e-04 - accuracy: 0.9908 - val_loss: 3.3807e-04 - val_accuracy: 0.9898\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 1s 474us/step - loss: 3.0752e-04 - accuracy: 0.9908 - val_loss: 3.7903e-04 - val_accuracy: 0.9913\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 1s 480us/step - loss: 3.0979e-04 - accuracy: 0.9912 - val_loss: 3.3901e-04 - val_accuracy: 0.9882\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 1s 468us/step - loss: 2.9578e-04 - accuracy: 0.9911 - val_loss: 3.1649e-04 - val_accuracy: 0.9922\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 1s 490us/step - loss: 3.0624e-04 - accuracy: 0.9909 - val_loss: 2.4646e-04 - val_accuracy: 0.9912\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 1s 505us/step - loss: 2.9027e-04 - accuracy: 0.9916 - val_loss: 2.2354e-04 - val_accuracy: 0.9952\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 1s 484us/step - loss: 1.0289e-04 - accuracy: 0.9959 - val_loss: 5.4324e-05 - val_accuracy: 0.9974\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 1s 471us/step - loss: 5.7192e-05 - accuracy: 0.9960 - val_loss: 3.0608e-05 - val_accuracy: 0.9972\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 1s 477us/step - loss: 5.4773e-05 - accuracy: 0.9964 - val_loss: 4.9389e-05 - val_accuracy: 0.9973\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 1s 473us/step - loss: 4.6386e-05 - accuracy: 0.9966 - val_loss: 5.2875e-05 - val_accuracy: 0.9948\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 1s 466us/step - loss: 3.9521e-05 - accuracy: 0.9967 - val_loss: 1.2049e-04 - val_accuracy: 0.9919\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 1s 464us/step - loss: 3.9512e-05 - accuracy: 0.9969 - val_loss: 2.7601e-05 - val_accuracy: 0.9966\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 1s 466us/step - loss: 3.7830e-05 - accuracy: 0.9971 - val_loss: 3.2867e-05 - val_accuracy: 0.9973\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 1s 484us/step - loss: 3.7096e-05 - accuracy: 0.9972 - val_loss: 2.7910e-05 - val_accuracy: 0.9970\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 1s 468us/step - loss: 3.6695e-05 - accuracy: 0.9969 - val_loss: 2.6463e-05 - val_accuracy: 0.9964\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 1s 462us/step - loss: 3.5243e-05 - accuracy: 0.9969 - val_loss: 3.3376e-05 - val_accuracy: 0.9972\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 1s 460us/step - loss: 3.5158e-05 - accuracy: 0.9968 - val_loss: 4.3284e-05 - val_accuracy: 0.9969\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 1s 461us/step - loss: 3.4476e-05 - accuracy: 0.9968 - val_loss: 6.6388e-05 - val_accuracy: 0.9947\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 1s 460us/step - loss: 3.4168e-05 - accuracy: 0.9969 - val_loss: 2.3519e-05 - val_accuracy: 0.9972\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 1s 467us/step - loss: 3.3557e-05 - accuracy: 0.9970 - val_loss: 2.8808e-05 - val_accuracy: 0.9966\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 1s 464us/step - loss: 3.5388e-05 - accuracy: 0.9970 - val_loss: 2.3029e-05 - val_accuracy: 0.9984\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 1s 464us/step - loss: 3.5195e-05 - accuracy: 0.9971 - val_loss: 3.4125e-05 - val_accuracy: 0.9977\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 1s 464us/step - loss: 3.3434e-05 - accuracy: 0.9970 - val_loss: 2.1388e-05 - val_accuracy: 0.9977\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 1s 461us/step - loss: 3.3221e-05 - accuracy: 0.9969 - val_loss: 2.8414e-05 - val_accuracy: 0.9979\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 1s 463us/step - loss: 3.1629e-05 - accuracy: 0.9971 - val_loss: 4.4157e-05 - val_accuracy: 0.9975\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 1s 460us/step - loss: 3.1698e-05 - accuracy: 0.9969 - val_loss: 3.2556e-05 - val_accuracy: 0.9952\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 1s 460us/step - loss: 3.2367e-05 - accuracy: 0.9972 - val_loss: 1.6409e-05 - val_accuracy: 0.9985\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = \"mse\",\n",
    "              optimizer = \"ADAM\",\n",
    "              metrics = [\"accuracy\"])\n",
    "history = model.fit(x = F_train, y = Q_train, validation_data=(F_val, Q_val),epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95f045bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 0s 254us/step - loss: 1.6590e-05 - accuracy: 0.9984\n"
     ]
    }
   ],
   "source": [
    "#F 학습 후 F accuracy\n",
    "result = model.evaluate(F_test, Q_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7a22dfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 0s 253us/step - loss: 0.0011 - accuracy: 0.9840\n"
     ]
    }
   ],
   "source": [
    "#F 학습 후 nF accuracy\n",
    "result = model.evaluate(nF_test, Q_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e08999e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 1s 495us/step - loss: 0.0012 - accuracy: 0.9824 - val_loss: 0.0012 - val_accuracy: 0.9822\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 1s 468us/step - loss: 0.0012 - accuracy: 0.9821 - val_loss: 0.0011 - val_accuracy: 0.9825\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 1s 468us/step - loss: 0.0012 - accuracy: 0.9831 - val_loss: 0.0011 - val_accuracy: 0.9841\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 1s 471us/step - loss: 0.0012 - accuracy: 0.9823 - val_loss: 0.0011 - val_accuracy: 0.9840\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 1s 472us/step - loss: 0.0012 - accuracy: 0.9827 - val_loss: 0.0011 - val_accuracy: 0.9837\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 1s 467us/step - loss: 0.0012 - accuracy: 0.9824 - val_loss: 0.0012 - val_accuracy: 0.9821\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 1s 472us/step - loss: 0.0011 - accuracy: 0.9826 - val_loss: 0.0011 - val_accuracy: 0.9834\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 1s 473us/step - loss: 0.0012 - accuracy: 0.9828 - val_loss: 0.0011 - val_accuracy: 0.9836\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 1s 474us/step - loss: 0.0011 - accuracy: 0.9831 - val_loss: 0.0011 - val_accuracy: 0.9829\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 1s 483us/step - loss: 0.0011 - accuracy: 0.9821 - val_loss: 0.0011 - val_accuracy: 0.9826\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 1s 490us/step - loss: 0.0011 - accuracy: 0.9829 - val_loss: 0.0011 - val_accuracy: 0.9837\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 1s 481us/step - loss: 0.0011 - accuracy: 0.9828 - val_loss: 0.0012 - val_accuracy: 0.9804\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 1s 482us/step - loss: 0.0011 - accuracy: 0.9830 - val_loss: 0.0011 - val_accuracy: 0.9830\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 1s 479us/step - loss: 0.0011 - accuracy: 0.9828 - val_loss: 0.0011 - val_accuracy: 0.9834\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 1s 475us/step - loss: 0.0011 - accuracy: 0.9825 - val_loss: 0.0010 - val_accuracy: 0.9842\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 1s 480us/step - loss: 0.0011 - accuracy: 0.9825 - val_loss: 0.0011 - val_accuracy: 0.9833\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 1s 479us/step - loss: 0.0011 - accuracy: 0.9835 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 1s 508us/step - loss: 0.0011 - accuracy: 0.9828 - val_loss: 0.0011 - val_accuracy: 0.9833\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 1s 472us/step - loss: 0.0011 - accuracy: 0.9831 - val_loss: 0.0011 - val_accuracy: 0.9831\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 1s 466us/step - loss: 0.0011 - accuracy: 0.9831 - val_loss: 0.0012 - val_accuracy: 0.9830\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 1s 464us/step - loss: 0.0011 - accuracy: 0.9830 - val_loss: 0.0011 - val_accuracy: 0.9824\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 1s 464us/step - loss: 0.0011 - accuracy: 0.9829 - val_loss: 0.0010 - val_accuracy: 0.9844\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 1s 468us/step - loss: 0.0011 - accuracy: 0.9830 - val_loss: 0.0010 - val_accuracy: 0.9844\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 1s 467us/step - loss: 0.0011 - accuracy: 0.9827 - val_loss: 0.0010 - val_accuracy: 0.9848\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 1s 492us/step - loss: 0.0011 - accuracy: 0.9829 - val_loss: 0.0011 - val_accuracy: 0.9830\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 1s 507us/step - loss: 0.0011 - accuracy: 0.9830 - val_loss: 0.0011 - val_accuracy: 0.9833\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 1s 507us/step - loss: 0.0011 - accuracy: 0.9835 - val_loss: 0.0012 - val_accuracy: 0.9786\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 1s 475us/step - loss: 0.0011 - accuracy: 0.9834 - val_loss: 0.0011 - val_accuracy: 0.9843\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 1s 490us/step - loss: 0.0011 - accuracy: 0.9829 - val_loss: 0.0014 - val_accuracy: 0.9796\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 1s 477us/step - loss: 0.0011 - accuracy: 0.9825 - val_loss: 0.0012 - val_accuracy: 0.9823\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 1s 475us/step - loss: 0.0011 - accuracy: 0.9831 - val_loss: 0.0012 - val_accuracy: 0.9834\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 1s 482us/step - loss: 0.0011 - accuracy: 0.9835 - val_loss: 0.0013 - val_accuracy: 0.9801\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 1s 480us/step - loss: 0.0011 - accuracy: 0.9830 - val_loss: 0.0011 - val_accuracy: 0.9809\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 1s 468us/step - loss: 0.0011 - accuracy: 0.9828 - val_loss: 0.0013 - val_accuracy: 0.9791\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 1s 467us/step - loss: 0.0011 - accuracy: 0.9829 - val_loss: 0.0013 - val_accuracy: 0.9792\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 1s 466us/step - loss: 0.0011 - accuracy: 0.9834 - val_loss: 0.0011 - val_accuracy: 0.9820\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 1s 469us/step - loss: 0.0011 - accuracy: 0.9832 - val_loss: 0.0013 - val_accuracy: 0.9833\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 1s 465us/step - loss: 0.0011 - accuracy: 0.9833 - val_loss: 0.0011 - val_accuracy: 0.9836\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 1s 466us/step - loss: 0.0011 - accuracy: 0.9829 - val_loss: 0.0011 - val_accuracy: 0.9845\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 1s 466us/step - loss: 0.0011 - accuracy: 0.9836 - val_loss: 0.0012 - val_accuracy: 0.9827\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 1s 469us/step - loss: 0.0011 - accuracy: 0.9832 - val_loss: 0.0011 - val_accuracy: 0.9834\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 1s 466us/step - loss: 0.0011 - accuracy: 0.9832 - val_loss: 0.0011 - val_accuracy: 0.9838\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 1s 465us/step - loss: 0.0011 - accuracy: 0.9827 - val_loss: 0.0011 - val_accuracy: 0.9844\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 1s 467us/step - loss: 0.0011 - accuracy: 0.9834 - val_loss: 0.0012 - val_accuracy: 0.9828\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 1s 466us/step - loss: 0.0011 - accuracy: 0.9832 - val_loss: 0.0011 - val_accuracy: 0.9826\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 1s 465us/step - loss: 0.0011 - accuracy: 0.9830 - val_loss: 0.0011 - val_accuracy: 0.9841\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 1s 466us/step - loss: 0.0011 - accuracy: 0.9831 - val_loss: 0.0011 - val_accuracy: 0.9841\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 1s 463us/step - loss: 0.0011 - accuracy: 0.9830 - val_loss: 0.0011 - val_accuracy: 0.9837\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 1s 464us/step - loss: 0.0011 - accuracy: 0.9835 - val_loss: 0.0010 - val_accuracy: 0.9844\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 1s 463us/step - loss: 0.0011 - accuracy: 0.9836 - val_loss: 0.0010 - val_accuracy: 0.9840\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = \"mse\",\n",
    "              optimizer = \"adam\",\n",
    "              metrics = [\"accuracy\"])\n",
    "history = model.fit(x = nF_train, y = Q_train, validation_data=(nF_val, Q_val),epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e80a0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 0s 259us/step - loss: 0.0010 - accuracy: 0.9832\n"
     ]
    }
   ],
   "source": [
    "#nF 학습 후 nF accuracy\n",
    "result = model.evaluate(nF_test, Q_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd712eab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
