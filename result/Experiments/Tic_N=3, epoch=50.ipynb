{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "36076719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "#gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#print(len(gpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "64f67c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1d5d5474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>-0.07554167</th>\n",
       "      <th>0.15564174</th>\n",
       "      <th>0.17413366</th>\n",
       "      <th>0.13918874</th>\n",
       "      <th>0.14987264</th>\n",
       "      <th>-0.02049801</th>\n",
       "      <th>0.09800520</th>\n",
       "      <th>-0.06676333</th>\n",
       "      <th>-0.08714528</th>\n",
       "      <th>0.08003181</th>\n",
       "      <th>...</th>\n",
       "      <th>0.17935742</th>\n",
       "      <th>-0.05583790</th>\n",
       "      <th>-0.06579545</th>\n",
       "      <th>0.06183800</th>\n",
       "      <th>-0.20620972</th>\n",
       "      <th>0.05911842</th>\n",
       "      <th>-0.05977414</th>\n",
       "      <th>-0.02171137</th>\n",
       "      <th>0.10180243</th>\n",
       "      <th>-0.14521111</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.005535</td>\n",
       "      <td>0.006658</td>\n",
       "      <td>-0.000676</td>\n",
       "      <td>0.001881</td>\n",
       "      <td>-0.008176</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>-0.002526</td>\n",
       "      <td>-0.003462</td>\n",
       "      <td>0.008640</td>\n",
       "      <td>-0.013094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004038</td>\n",
       "      <td>0.006765</td>\n",
       "      <td>-0.004190</td>\n",
       "      <td>-0.006789</td>\n",
       "      <td>0.009556</td>\n",
       "      <td>0.002606</td>\n",
       "      <td>0.005746</td>\n",
       "      <td>-0.005756</td>\n",
       "      <td>-0.001540</td>\n",
       "      <td>-0.007515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000074</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000040</td>\n",
       "      <td>-0.000058</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 100000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   -0.07554167  0.15564174  0.17413366  0.13918874  0.14987264  -0.02049801  \\\n",
       "0    -0.005535    0.006658   -0.000676    0.001881   -0.008176     0.000366   \n",
       "1     0.000074   -0.000047    0.000003   -0.000040   -0.000058     0.000076   \n",
       "\n",
       "   0.09800520  -0.06676333  -0.08714528  0.08003181  ...  0.17935742  \\\n",
       "0   -0.002526    -0.003462     0.008640   -0.013094  ...   -0.004038   \n",
       "1   -0.000033    -0.000008     0.000031   -0.000016  ...    0.000021   \n",
       "\n",
       "   -0.05583790  -0.06579545  0.06183800  -0.20620972  0.05911842  -0.05977414  \\\n",
       "0     0.006765    -0.004190   -0.006789     0.009556    0.002606     0.005746   \n",
       "1     0.000052     0.000009   -0.000076     0.000007   -0.000007    -0.000038   \n",
       "\n",
       "   -0.02171137  0.10180243  -0.14521111  \n",
       "0    -0.005756   -0.001540    -0.007515  \n",
       "1    -0.000061   -0.000087     0.000012  \n",
       "\n",
       "[2 rows x 100000 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data load, F.txt 파일이 있는 절대 경로를 입력하시면 됩니다.\n",
    "#data 확인을 위하여 출력해봅니다. column name에 데이터가 들어가있어서 처리해주어야 합니다.\n",
    "# N = 5\n",
    "data = pd.read_csv('C:/Users/Administrator/Documents/MATLAB/Data set/F.txt', sep = '\\t')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aaecaead",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "for i in range(len(data.iloc[0,:])):\n",
    "    arr.append(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "130e80da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data\n",
    "#column name에 data가 들어가있기 때문에 \"names = arr\" 로 처리해 줍니다. arr은 1 ~ len(F)의 숫자가 담겨있습니다.\n",
    "dataF = pd.read_csv('C:/Users/Administrator/Documents/MATLAB/Data set/F.txt', sep = '\\t', names = arr)\n",
    "dataQ = pd.read_csv('C:/Users/Administrator/Documents/MATLAB/Data set/Q.txt', sep = '\\t', names = arr)\n",
    "data_nF = pd.read_csv('C:/Users/Administrator/Documents/MATLAB/Data set/nF.txt', sep = '\\t', names = arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e41b12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_arr(A):\n",
    "    arA = []\n",
    "    for j in range(len(A.iloc[0, :])):\n",
    "        arA1 = []\n",
    "        for i in range(len(A.iloc[:,0])):\n",
    "            tmpA = A.iloc[:,j][i]\n",
    "            arA1.append(tmpA)\n",
    "        arA.append(arA1)\n",
    "    return arA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "06b62f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make array\n",
    "arrF = make_arr(dataF)\n",
    "dataF = np.array(arrF)\n",
    "\n",
    "arrQ = make_arr(dataQ)\n",
    "dataQ = np.array(arrQ)\n",
    "\n",
    "arr_nF = make_arr(data_nF)\n",
    "data_nF = np.array(arr_nF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bebffb63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# N = 5\n",
    "A = []\n",
    "for n in range(1,6):\n",
    "    x = np.exp(-(n**2))\n",
    "    A.append(x)\n",
    "A = np.diag(A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "01383513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 3), (20000, 3), (20000, 3)\n",
      "(60000, 3), (20000, 3), (20000, 3)\n",
      "(60000, 3), (20000, 3), (20000, 3)\n"
     ]
    }
   ],
   "source": [
    "# data 분할\n",
    "\n",
    "import math\n",
    "train_size = math.floor(len(dataF)*0.6) # train : 60%\n",
    "val_size = math.floor(len(dataF)*0.2) #val : 20%\n",
    "test_size = math.floor(len(dataF)*0.2) #test : 20%\n",
    "#generate F_data, F_val, F_test\n",
    "F_data = dataF[:train_size, :]\n",
    "F_val = dataF[train_size:(val_size + train_size), :]\n",
    "F_test = dataF[(val_size + train_size):(val_size + train_size + test_size), :]\n",
    "\n",
    "#generate Q_data, Q_val, Q_test\n",
    "Q_data = dataQ[:train_size, :]\n",
    "Q_val = dataQ[train_size:(val_size + train_size), :]\n",
    "Q_test = dataQ[(val_size + train_size):(val_size + train_size + test_size), :]\n",
    "\n",
    "#generate nF_data, nF_val, nF_test\n",
    "nF_data = data_nF[:train_size, :]\n",
    "nF_val = data_nF[train_size:(val_size + train_size), :]\n",
    "nF_test = data_nF[(val_size + train_size):(val_size + train_size + test_size), :]\n",
    "\n",
    "print(f'{F_data.shape}, {F_test.shape}, {F_val.shape}')\n",
    "print(f'{Q_data.shape}, {Q_test.shape}, {Q_val.shape}')\n",
    "print(f'{nF_data.shape}, {nF_test.shape}, {nF_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d4e02b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.Sequential() #Sequentioal\n",
    "\n",
    "model.add(keras.layers.Dense(input_dim = 3, units = 10, activation= \"tanh\",kernel_initializer =\"HeNormal\" )) \n",
    "model.add(keras.layers.Dense(20, activation= \"tanh\")) \n",
    "model.add(keras.layers.Dense(50, activation= \"tanh\"))  \n",
    "model.add(keras.layers.Dense(100, activation= \"tanh\")) \n",
    "model.add(keras.layers.Dense(120, activation= \"tanh\")) \n",
    "model.add(keras.layers.Dense(50, activation= \"tanh\"))\n",
    "model.add(keras.layers.Dense(3, activation= \"tanh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b02072db",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    F_train = tf.constant(F_data)\n",
    "    Q_train = tf.constant(Q_data)\n",
    "    nF_train = tf.constant(nF_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3ea283d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 1s 514us/step - loss: 0.0438 - accuracy: 0.7424 - val_loss: 0.0434 - val_accuracy: 0.7491\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 1s 495us/step - loss: 0.0426 - accuracy: 0.7463 - val_loss: 0.0432 - val_accuracy: 0.7471\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 1s 491us/step - loss: 0.0425 - accuracy: 0.7482 - val_loss: 0.0432 - val_accuracy: 0.7510\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 1s 486us/step - loss: 0.0425 - accuracy: 0.7486 - val_loss: 0.0431 - val_accuracy: 0.7501\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 1s 493us/step - loss: 0.0424 - accuracy: 0.7520 - val_loss: 0.0426 - val_accuracy: 0.7553\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 1s 489us/step - loss: 0.0221 - accuracy: 0.8559 - val_loss: 0.0025 - val_accuracy: 0.9603\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 1s 489us/step - loss: 0.0015 - accuracy: 0.9672 - val_loss: 7.1097e-04 - val_accuracy: 0.9744\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 1s 488us/step - loss: 0.0012 - accuracy: 0.9685 - val_loss: 5.1423e-04 - val_accuracy: 0.9742\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 1s 493us/step - loss: 0.0012 - accuracy: 0.9696 - val_loss: 0.0019 - val_accuracy: 0.9549\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 1s 488us/step - loss: 8.1942e-04 - accuracy: 0.9742 - val_loss: 0.0017 - val_accuracy: 0.9530\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 1s 499us/step - loss: 9.8124e-04 - accuracy: 0.9734 - val_loss: 3.2003e-04 - val_accuracy: 0.9868\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 1s 491us/step - loss: 7.3830e-04 - accuracy: 0.9764 - val_loss: 7.3687e-04 - val_accuracy: 0.9798\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 1s 513us/step - loss: 7.7703e-04 - accuracy: 0.9750 - val_loss: 3.0429e-04 - val_accuracy: 0.9883\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 1s 498us/step - loss: 7.1688e-04 - accuracy: 0.9757 - val_loss: 3.2171e-04 - val_accuracy: 0.9798\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 1s 507us/step - loss: 6.3101e-04 - accuracy: 0.9781 - val_loss: 3.0155e-04 - val_accuracy: 0.9882\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 1s 491us/step - loss: 5.4545e-04 - accuracy: 0.9791 - val_loss: 6.9307e-04 - val_accuracy: 0.9681\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 1s 501us/step - loss: 5.5102e-04 - accuracy: 0.9786 - val_loss: 0.0013 - val_accuracy: 0.9625\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 1s 491us/step - loss: 5.5906e-04 - accuracy: 0.9790 - val_loss: 5.0041e-04 - val_accuracy: 0.9807\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 1s 493us/step - loss: 5.6097e-04 - accuracy: 0.9788 - val_loss: 3.0148e-04 - val_accuracy: 0.9852\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 1s 498us/step - loss: 5.2894e-04 - accuracy: 0.9795 - val_loss: 3.2687e-04 - val_accuracy: 0.9843\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 1s 502us/step - loss: 4.1580e-04 - accuracy: 0.9819 - val_loss: 9.0486e-04 - val_accuracy: 0.9692\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 1s 501us/step - loss: 3.9190e-04 - accuracy: 0.9825 - val_loss: 1.7033e-04 - val_accuracy: 0.9898\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 1s 490us/step - loss: 3.8133e-04 - accuracy: 0.9831 - val_loss: 9.7868e-04 - val_accuracy: 0.9664\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 1s 497us/step - loss: 3.4255e-04 - accuracy: 0.9837 - val_loss: 4.4536e-04 - val_accuracy: 0.9821\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 1s 497us/step - loss: 3.5369e-04 - accuracy: 0.9837 - val_loss: 1.4341e-04 - val_accuracy: 0.9908\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 1s 492us/step - loss: 3.4451e-04 - accuracy: 0.9827 - val_loss: 1.9765e-04 - val_accuracy: 0.9857\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 1s 506us/step - loss: 3.1862e-04 - accuracy: 0.9844 - val_loss: 3.2743e-04 - val_accuracy: 0.9812\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 1s 498us/step - loss: 3.5288e-04 - accuracy: 0.9834 - val_loss: 2.3132e-04 - val_accuracy: 0.9916\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 1s 495us/step - loss: 3.0885e-04 - accuracy: 0.9837 - val_loss: 5.2931e-04 - val_accuracy: 0.9731\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 1s 486us/step - loss: 3.3154e-04 - accuracy: 0.9836 - val_loss: 1.4971e-04 - val_accuracy: 0.9857\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 1s 490us/step - loss: 2.8611e-04 - accuracy: 0.9850 - val_loss: 6.4479e-04 - val_accuracy: 0.9750\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 1s 497us/step - loss: 2.8811e-04 - accuracy: 0.9841 - val_loss: 2.5009e-04 - val_accuracy: 0.9844\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 1s 487us/step - loss: 2.6644e-04 - accuracy: 0.9847 - val_loss: 3.4267e-04 - val_accuracy: 0.9804\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 1s 489us/step - loss: 3.1232e-04 - accuracy: 0.9833 - val_loss: 1.2596e-04 - val_accuracy: 0.9931\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 1s 495us/step - loss: 2.4122e-04 - accuracy: 0.9856 - val_loss: 6.7541e-04 - val_accuracy: 0.9681\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 1s 486us/step - loss: 2.8820e-04 - accuracy: 0.9844 - val_loss: 1.5149e-04 - val_accuracy: 0.9905\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 1s 489us/step - loss: 2.5158e-04 - accuracy: 0.9853 - val_loss: 1.2320e-04 - val_accuracy: 0.9910\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 1s 488us/step - loss: 2.7798e-04 - accuracy: 0.9856 - val_loss: 3.1012e-04 - val_accuracy: 0.9825\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 1s 488us/step - loss: 2.4322e-04 - accuracy: 0.9853 - val_loss: 1.9994e-04 - val_accuracy: 0.9855\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 1s 487us/step - loss: 2.6858e-04 - accuracy: 0.9850 - val_loss: 1.4851e-04 - val_accuracy: 0.9884\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 1s 485us/step - loss: 2.3984e-04 - accuracy: 0.9860 - val_loss: 1.2143e-04 - val_accuracy: 0.9917\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 1s 502us/step - loss: 2.5881e-04 - accuracy: 0.9854 - val_loss: 7.1574e-04 - val_accuracy: 0.9760\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 1s 491us/step - loss: 2.5003e-04 - accuracy: 0.9856 - val_loss: 1.4520e-04 - val_accuracy: 0.9938\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 1s 492us/step - loss: 2.5031e-04 - accuracy: 0.9859 - val_loss: 2.1237e-04 - val_accuracy: 0.9884\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 1s 495us/step - loss: 2.4809e-04 - accuracy: 0.9856 - val_loss: 2.1045e-04 - val_accuracy: 0.9916\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 1s 491us/step - loss: 2.4691e-04 - accuracy: 0.9856 - val_loss: 1.2562e-04 - val_accuracy: 0.9895\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 1s 495us/step - loss: 2.3535e-04 - accuracy: 0.9863 - val_loss: 7.1792e-04 - val_accuracy: 0.9700\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 1s 489us/step - loss: 2.3755e-04 - accuracy: 0.9861 - val_loss: 2.6973e-04 - val_accuracy: 0.9879\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 1s 488us/step - loss: 2.2867e-04 - accuracy: 0.9862 - val_loss: 1.9602e-04 - val_accuracy: 0.9851\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 1s 490us/step - loss: 2.3577e-04 - accuracy: 0.9860 - val_loss: 1.2383e-04 - val_accuracy: 0.9936\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = \"mse\",\n",
    "              optimizer = \"ADAM\",\n",
    "              metrics = [\"accuracy\"])\n",
    "history = model.fit(x = F_train, y = Q_train, validation_data=(F_val, Q_val),epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "95f045bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 0s 261us/step - loss: 1.2018e-04 - accuracy: 0.9918\n"
     ]
    }
   ],
   "source": [
    "#F 학습 후 F accuracy\n",
    "result = model.evaluate(F_test, Q_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7a22dfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 0s 267us/step - loss: 0.3131 - accuracy: 0.5096\n"
     ]
    }
   ],
   "source": [
    "#F 학습 후 nF accuracy\n",
    "result = model.evaluate(nF_test, Q_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6e08999e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 1s 531us/step - loss: 0.0484 - accuracy: 0.7368 - val_loss: 0.0449 - val_accuracy: 0.7385\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 1s 500us/step - loss: 0.0430 - accuracy: 0.7452 - val_loss: 0.0439 - val_accuracy: 0.7350\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 1s 498us/step - loss: 0.0427 - accuracy: 0.7502 - val_loss: 0.0425 - val_accuracy: 0.7564\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 1s 501us/step - loss: 0.0418 - accuracy: 0.7526 - val_loss: 0.0417 - val_accuracy: 0.7606\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 1s 514us/step - loss: 0.0412 - accuracy: 0.7557 - val_loss: 0.0418 - val_accuracy: 0.7513\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 1s 500us/step - loss: 0.0410 - accuracy: 0.7591 - val_loss: 0.0413 - val_accuracy: 0.7560\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 1s 496us/step - loss: 0.0406 - accuracy: 0.7605 - val_loss: 0.0407 - val_accuracy: 0.7575\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 1s 498us/step - loss: 0.0406 - accuracy: 0.7594 - val_loss: 0.0404 - val_accuracy: 0.7635\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 1s 497us/step - loss: 0.0404 - accuracy: 0.7606 - val_loss: 0.0403 - val_accuracy: 0.7620\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 1s 502us/step - loss: 0.0403 - accuracy: 0.7610 - val_loss: 0.0407 - val_accuracy: 0.7603\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 1s 517us/step - loss: 0.0402 - accuracy: 0.7611 - val_loss: 0.0401 - val_accuracy: 0.7638\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 1s 494us/step - loss: 0.0400 - accuracy: 0.7615 - val_loss: 0.0398 - val_accuracy: 0.7643\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 1s 492us/step - loss: 0.0400 - accuracy: 0.7615 - val_loss: 0.0399 - val_accuracy: 0.7656\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 1s 498us/step - loss: 0.0398 - accuracy: 0.7623 - val_loss: 0.0401 - val_accuracy: 0.7631\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 1s 492us/step - loss: 0.0399 - accuracy: 0.7618 - val_loss: 0.0400 - val_accuracy: 0.7660\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 1s 493us/step - loss: 0.0398 - accuracy: 0.7617 - val_loss: 0.0409 - val_accuracy: 0.7559\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 1s 500us/step - loss: 0.0397 - accuracy: 0.7628 - val_loss: 0.0417 - val_accuracy: 0.7553\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 1s 494us/step - loss: 0.0396 - accuracy: 0.7638 - val_loss: 0.0401 - val_accuracy: 0.7637\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 1s 493us/step - loss: 0.0397 - accuracy: 0.7635 - val_loss: 0.0400 - val_accuracy: 0.7653\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 1s 492us/step - loss: 0.0397 - accuracy: 0.7630 - val_loss: 0.0401 - val_accuracy: 0.7655\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 1s 495us/step - loss: 0.0395 - accuracy: 0.7632 - val_loss: 0.0392 - val_accuracy: 0.7681\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 1s 494us/step - loss: 0.0395 - accuracy: 0.7619 - val_loss: 0.0396 - val_accuracy: 0.7652\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 1s 492us/step - loss: 0.0396 - accuracy: 0.7633 - val_loss: 0.0400 - val_accuracy: 0.7620\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 1s 496us/step - loss: 0.0395 - accuracy: 0.7626 - val_loss: 0.0401 - val_accuracy: 0.7619\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 1s 490us/step - loss: 0.0395 - accuracy: 0.7637 - val_loss: 0.0404 - val_accuracy: 0.7617\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 1s 491us/step - loss: 0.0394 - accuracy: 0.7636 - val_loss: 0.0395 - val_accuracy: 0.7649\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 1s 500us/step - loss: 0.0394 - accuracy: 0.7634 - val_loss: 0.0397 - val_accuracy: 0.7663\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 1s 493us/step - loss: 0.0394 - accuracy: 0.7637 - val_loss: 0.0396 - val_accuracy: 0.7645\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 1s 494us/step - loss: 0.0394 - accuracy: 0.7630 - val_loss: 0.0397 - val_accuracy: 0.7622\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 1s 492us/step - loss: 0.0394 - accuracy: 0.7644 - val_loss: 0.0403 - val_accuracy: 0.7618\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 1s 495us/step - loss: 0.0394 - accuracy: 0.7626 - val_loss: 0.0394 - val_accuracy: 0.7667\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 1s 490us/step - loss: 0.0393 - accuracy: 0.7633 - val_loss: 0.0396 - val_accuracy: 0.7663\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 1s 497us/step - loss: 0.0392 - accuracy: 0.7641 - val_loss: 0.0392 - val_accuracy: 0.7656\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 1s 502us/step - loss: 0.0394 - accuracy: 0.7635 - val_loss: 0.0400 - val_accuracy: 0.7638\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 1s 492us/step - loss: 0.0394 - accuracy: 0.7639 - val_loss: 0.0402 - val_accuracy: 0.7643\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 1s 504us/step - loss: 0.0395 - accuracy: 0.7645 - val_loss: 0.0398 - val_accuracy: 0.7656\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 1s 500us/step - loss: 0.0394 - accuracy: 0.7648 - val_loss: 0.0395 - val_accuracy: 0.7632\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 1s 509us/step - loss: 0.0394 - accuracy: 0.7647 - val_loss: 0.0394 - val_accuracy: 0.7642\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 1s 509us/step - loss: 0.0393 - accuracy: 0.7646 - val_loss: 0.0401 - val_accuracy: 0.7596\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 1s 495us/step - loss: 0.0393 - accuracy: 0.7645 - val_loss: 0.0393 - val_accuracy: 0.7661\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 1s 497us/step - loss: 0.0393 - accuracy: 0.7648 - val_loss: 0.0393 - val_accuracy: 0.7664\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 1s 495us/step - loss: 0.0393 - accuracy: 0.7648 - val_loss: 0.0391 - val_accuracy: 0.7677\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 1s 492us/step - loss: 0.0393 - accuracy: 0.7634 - val_loss: 0.0395 - val_accuracy: 0.7660\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 1s 497us/step - loss: 0.0392 - accuracy: 0.7650 - val_loss: 0.0393 - val_accuracy: 0.7645\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 1s 496us/step - loss: 0.0393 - accuracy: 0.7635 - val_loss: 0.0395 - val_accuracy: 0.7681\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 1s 494us/step - loss: 0.0393 - accuracy: 0.7647 - val_loss: 0.0404 - val_accuracy: 0.7624\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 1s 494us/step - loss: 0.0394 - accuracy: 0.7644 - val_loss: 0.0408 - val_accuracy: 0.7611\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 1s 495us/step - loss: 0.0392 - accuracy: 0.7650 - val_loss: 0.0403 - val_accuracy: 0.7605\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 1s 502us/step - loss: 0.0394 - accuracy: 0.7649 - val_loss: 0.0403 - val_accuracy: 0.7597\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 1s 493us/step - loss: 0.0393 - accuracy: 0.7643 - val_loss: 0.0403 - val_accuracy: 0.7619\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = \"mse\",\n",
    "              optimizer = \"adam\",\n",
    "              metrics = [\"accuracy\"])\n",
    "history = model.fit(x = nF_train, y = Q_train, validation_data=(nF_val, Q_val),epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6e80a0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 0s 263us/step - loss: 0.0400 - accuracy: 0.7581\n"
     ]
    }
   ],
   "source": [
    "#nF 학습 후 nF accuracy\n",
    "result = model.evaluate(nF_test, Q_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd712eab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
